{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Exp-3: MULTI-LAYER NEURAL NETWORK WITH VARIOUS ACTIVATION AND LOSS FUNCTIONS***"
      ],
      "metadata": {
        "id": "IV0aOJK7Uycu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np_GUdKUF7bs"
      },
      "outputs": [],
      "source": [
        "import numpy \n",
        "import pandas "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset"
      ],
      "metadata": {
        "id": "58vILbkhscHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "dataset=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TsnMKJWpsfTI",
        "outputId": "d5621ee7-809b-4198-f73a-ba1e5de2ceae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62a7d90b-35f3-494e-92ad-402ab111ba15\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62a7d90b-35f3-494e-92ad-402ab111ba15\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Mobile_Price_Classification_train.csv to Mobile_Price_Classification_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the dataset as a dataframe"
      ],
      "metadata": {
        "id": "2km6qmdctisr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pandas.read_csv('Mobile_Price_Classification_train.csv')"
      ],
      "metadata": {
        "id": "BJKNLsJ8tmOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the dataframe"
      ],
      "metadata": {
        "id": "36y7e5uSt90W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7J6ah0KuAvu",
        "outputId": "6d6406d2-b52a-4fe3-9e70-2d94691f0ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0               842     0          2.2         0   1       0           7   \n",
            "1              1021     1          0.5         1   0       1          53   \n",
            "2               563     1          0.5         1   2       1          41   \n",
            "3               615     1          2.5         0   0       0          10   \n",
            "4              1821     1          1.2         0  13       1          44   \n",
            "...             ...   ...          ...       ...  ..     ...         ...   \n",
            "1995            794     1          0.5         1   0       1           2   \n",
            "1996           1965     1          2.6         1   0       0          39   \n",
            "1997           1911     0          0.9         1   1       1          36   \n",
            "1998           1512     0          0.9         0   4       1          46   \n",
            "1999            510     1          2.0         1   5       1          45   \n",
            "\n",
            "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0       0.6        188        2  ...         20       756  2549     9     7   \n",
            "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
            "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
            "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
            "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
            "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
            "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
            "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
            "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
            "1998    0.1        145        5  ...        336       670   869    18    10   \n",
            "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
            "\n",
            "      talk_time  three_g  touch_screen  wifi  price_range  \n",
            "0            19        0             0     1            1  \n",
            "1             7        1             1     0            2  \n",
            "2             9        1             1     0            2  \n",
            "3            11        1             0     0            2  \n",
            "4            15        1             1     0            1  \n",
            "...         ...      ...           ...   ...          ...  \n",
            "1995         19        1             1     0            0  \n",
            "1996         16        1             1     1            2  \n",
            "1997          5        1             1     0            3  \n",
            "1998         19        1             1     1            0  \n",
            "1999          2        1             1     1            3  \n",
            "\n",
            "[2000 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understand your data"
      ],
      "metadata": {
        "id": "zPHILQZruFcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFt3wUT4uJ1D",
        "outputId": "69d67969-a4fc-4d29-de5d-2bac33324544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate the attributes and the label"
      ],
      "metadata": {
        "id": "yTtOhNX5uNpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.drop(['price_range'],axis=1)\n",
        "label=df['price_range']\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcQKj2-DuRwR",
        "outputId": "eff3de0a-fa02-4d33-a74c-ab4c9d4c7ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0               842     0          2.2         0   1       0           7   \n",
            "1              1021     1          0.5         1   0       1          53   \n",
            "2               563     1          0.5         1   2       1          41   \n",
            "3               615     1          2.5         0   0       0          10   \n",
            "4              1821     1          1.2         0  13       1          44   \n",
            "...             ...   ...          ...       ...  ..     ...         ...   \n",
            "1995            794     1          0.5         1   0       1           2   \n",
            "1996           1965     1          2.6         1   0       0          39   \n",
            "1997           1911     0          0.9         1   1       1          36   \n",
            "1998           1512     0          0.9         0   4       1          46   \n",
            "1999            510     1          2.0         1   5       1          45   \n",
            "\n",
            "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0       0.6        188        2   2         20       756  2549     9     7   \n",
            "1       0.7        136        3   6        905      1988  2631    17     3   \n",
            "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
            "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
            "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
            "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
            "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
            "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
            "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
            "1998    0.1        145        5   5        336       670   869    18    10   \n",
            "1999    0.9        168        6  16        483       754  3919    19     4   \n",
            "\n",
            "      talk_time  three_g  touch_screen  wifi  \n",
            "0            19        0             0     1  \n",
            "1             7        1             1     0  \n",
            "2             9        1             1     0  \n",
            "3            11        1             0     0  \n",
            "4            15        1             1     0  \n",
            "...         ...      ...           ...   ...  \n",
            "1995         19        1             1     0  \n",
            "1996         16        1             1     1  \n",
            "1997          5        1             1     0  \n",
            "1998         19        1             1     1  \n",
            "1999          2        1             1     1  \n",
            "\n",
            "[2000 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "PDvQG1cf2zPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datasets=train_test_split(data,label,test_size=0.2)\n",
        "train_data,test_data,train_label,test_label=datasets\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nqXO1XOHIHI",
        "outputId": "cfcc71e3-74b5-4d21-881d-13270d118eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 20)\n",
            "(400, 20)\n",
            "(1600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing using Keras"
      ],
      "metadata": {
        "id": "4Gacg_L3uwob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ax3qnhG077H",
        "outputId": "fa49973a-57f8-424b-c519-431f44b65f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize training data"
      ],
      "metadata": {
        "id": "7AKeaOQTnV8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer=tf.keras.layers.Normalization()"
      ],
      "metadata": {
        "id": "fCI_t_io1V50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.adapt(train_data)\n",
        "normalized_train_data=layer(train_data)\n",
        "print(normalized_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MApyp_69xMv7",
        "outputId": "9d8205a2-e2b5-4d43-f4bc-160e8505f720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.3302859   1.0113134  -0.8752446  ... -1.7856317   0.99376935\n",
            "   0.9789709 ]\n",
            " [ 0.6976849   1.0113134   0.3583625  ...  0.56002617 -1.0062697\n",
            "   0.9789709 ]\n",
            " [-0.8246536  -0.98881274  0.605084   ...  0.56002617 -1.0062697\n",
            "   0.9789709 ]\n",
            " ...\n",
            " [ 0.06053273  1.0113134  -0.2584411  ... -1.7856317  -1.0062697\n",
            "  -1.0214808 ]\n",
            " [ 1.384899   -0.98881274  1.7153306  ...  0.56002617 -1.0062697\n",
            "  -1.0214808 ]\n",
            " [ 1.4986762   1.0113134  -1.2453268  ...  0.56002617 -1.0062697\n",
            "  -1.0214808 ]], shape=(1600, 20), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features mean: %.2f\" % (normalized_train_data.numpy().mean()))\n",
        "print(\"Features std: %.2f\" % (normalized_train_data.numpy().std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp3vr9u-H7vn",
        "outputId": "a82dd785-2f44-4f86-9e5e-be7d2f1cad61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features mean: -0.00\n",
            "Features std: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tensor to numpy array"
      ],
      "metadata": {
        "id": "DInbapCOmmnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_train_data=normalized_train_data.numpy()"
      ],
      "metadata": {
        "id": "KTJuFEvge-S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert NumPy array to Dataframe"
      ],
      "metadata": {
        "id": "Lk4en0Zk1uUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okT4Ozh113wu",
        "outputId": "2e33f991-8f2a-4058-c356-f0e22900e027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
              "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
              "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
              "       'touch_screen', 'wifi'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dataframe=pandas.DataFrame(norm_train_data,columns=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
        "       'touch_screen', 'wifi'])"
      ],
      "metadata": {
        "id": "SYBTV8P32Ckd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k-hOD8c20cn",
        "outputId": "1cfe2118-0710-40db-c193-22bc8eb1d04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power      blue  clock_speed  dual_sim        fc    four_g  \\\n",
            "0          1.330286  1.011313    -0.875245 -1.007528 -0.064445 -1.029175   \n",
            "1          0.697685  1.011313     0.358362  0.992528 -0.993379 -1.029175   \n",
            "2         -0.824654 -0.988813     0.605084  0.992528 -0.761145  0.971652   \n",
            "3          0.952546  1.011313    -0.875245  0.992528 -0.761145  0.971652   \n",
            "4         -1.184190 -0.988813    -0.505162 -1.007528  1.793422 -1.029175   \n",
            "...             ...       ...          ...       ...       ...       ...   \n",
            "1595      -0.972564 -0.988813     0.605084  0.992528 -0.064445 -1.029175   \n",
            "1596       0.788707  1.011313    -0.135080 -1.007528 -0.296678  0.971652   \n",
            "1597       0.060533  1.011313    -0.258441 -1.007528  2.257889 -1.029175   \n",
            "1598       1.384899 -0.988813     1.715331 -1.007528 -0.993379 -1.029175   \n",
            "1599       1.498676  1.011313    -1.245327 -1.007528  0.167788  0.971652   \n",
            "\n",
            "      int_memory     m_dep  mobile_wt   n_cores        pc  px_height  \\\n",
            "0       1.591927  1.366879  -0.281076  1.083251 -0.142453  -0.874254   \n",
            "1       1.646436  0.675226  -1.386668 -0.225154 -0.966471  -1.068725   \n",
            "2       0.992318 -0.016427   1.533229  1.083251 -1.131275   1.077238   \n",
            "3      -1.406116  1.712705  -0.876395  1.083251 -1.296079  -0.103154   \n",
            "4      -1.079057  1.712705  -1.329971  0.647116  1.670389  -1.134302   \n",
            "...          ...       ...        ...       ...       ...        ...   \n",
            "1595    1.046828 -0.708079  -1.556759  0.647116  0.351959   0.774226   \n",
            "1596   -0.315919 -1.399732  -1.131531  1.519387  1.011174   2.336776   \n",
            "1597    1.101338  1.021052  -0.621258 -1.097425  0.846370   2.164919   \n",
            "1598    1.155848  0.675226  -0.791349  0.647116 -1.296079  -1.052896   \n",
            "1599    0.501729  0.329400  -0.252727 -1.097425  1.175977  -1.439576   \n",
            "\n",
            "      px_width       ram      sc_h      sc_w  talk_time   three_g  \\\n",
            "0     1.179096  0.528603 -0.996166 -0.630362  -0.717217 -1.785632   \n",
            "1    -0.601950 -1.208128 -1.231285 -0.630362  -0.352221  0.560026   \n",
            "2     0.297777 -1.182453  0.649662  0.744348  -0.899714  0.560026   \n",
            "3     0.196529 -1.148525 -0.761048  0.515229  -1.629706  0.560026   \n",
            "4     0.274766  0.222337  0.179425  0.056993  -1.447208 -1.785632   \n",
            "...        ...       ...       ...       ...        ...       ...   \n",
            "1595  0.090679  1.240168 -1.701521 -0.401243  -0.899714  0.560026   \n",
            "1596  1.167590  1.699567  0.884780  0.515229   1.290260  0.560026   \n",
            "1597  1.538067 -1.331001  1.355017 -0.172125  -1.082212 -1.785632   \n",
            "1598 -0.176248  0.514849 -1.466403 -1.317716  -0.534719  0.560026   \n",
            "1599  0.944384 -1.603340 -1.701521 -1.088598   0.195273  0.560026   \n",
            "\n",
            "      touch_screen      wifi  \n",
            "0         0.993769  0.978971  \n",
            "1        -1.006270  0.978971  \n",
            "2        -1.006270  0.978971  \n",
            "3        -1.006270  0.978971  \n",
            "4        -1.006270 -1.021481  \n",
            "...            ...       ...  \n",
            "1595     -1.006270  0.978971  \n",
            "1596     -1.006270  0.978971  \n",
            "1597     -1.006270 -1.021481  \n",
            "1598     -1.006270 -1.021481  \n",
            "1599     -1.006270 -1.021481  \n",
            "\n",
            "[1600 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize test data"
      ],
      "metadata": {
        "id": "pRHd0-HzNW2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer=tf.keras.layers.Normalization()\n",
        "layer.adapt(test_data)\n",
        "norm_test_data=layer(test_data)"
      ],
      "metadata": {
        "id": "OwWaamUhNZ5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tensor to numpy array"
      ],
      "metadata": {
        "id": "E2wuXISYOQo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_test_data_arr=norm_test_data.numpy()"
      ],
      "metadata": {
        "id": "PNWSNScxOQLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert numpy array to dataframe"
      ],
      "metadata": {
        "id": "Nh8r4TqfOnAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_test_dataframe=pandas.DataFrame(norm_test_data_arr,columns=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
        "       'touch_screen', 'wifi'])\n",
        "print(norm_test_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ahv297POg6B",
        "outputId": "df8b587a-2c40-45b2-fd38-bb93f4e55845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     battery_power      blue  clock_speed  dual_sim        fc    four_g  \\\n",
            "0         0.812094  1.005013    -0.087807 -1.067257 -0.992104 -1.105542   \n",
            "1         0.282868 -0.995012    -0.807049  0.936982  0.796478  0.904534   \n",
            "2         0.526951  1.005013    -1.286544  0.936982 -0.768531 -1.105542   \n",
            "3        -1.400619  1.005013     1.710297 -1.067257  2.361487  0.904534   \n",
            "4        -0.533783  1.005013    -1.046797 -1.067257  1.914342  0.904534   \n",
            "..             ...       ...          ...       ...       ...       ...   \n",
            "395       0.834906  1.005013     0.751308  0.936982 -0.544958 -1.105542   \n",
            "396       0.588542  1.005013    -1.046797  0.936982 -0.097813  0.904534   \n",
            "397       1.005992  1.005013     1.590423  0.936982  1.020051  0.904534   \n",
            "398      -1.117756 -0.995012     0.631434 -1.067257  0.125760  0.904534   \n",
            "399       0.433424  1.005013    -1.286544  0.936982 -0.097813  0.904534   \n",
            "\n",
            "     int_memory     m_dep  mobile_wt   n_cores        pc  px_height  px_width  \\\n",
            "0     -0.350436 -1.017638   0.011586  0.645798  1.304205   0.365321  0.551639   \n",
            "1      1.155571  1.089637  -0.937648  0.645798  0.807365   0.655028 -0.576307   \n",
            "2      0.055027  0.738425  -1.635615 -0.237344 -1.179995  -0.929447 -0.517066   \n",
            "3      0.634261 -0.666426  -0.686380 -1.562058  0.972979  -1.357323  0.004254   \n",
            "4      1.039724 -0.315213  -0.267600 -0.678916  0.807365   0.006530 -1.059712   \n",
            "..          ...       ...        ...       ...       ...        ...       ...   \n",
            "395    1.445188 -1.368851  -0.379275 -0.237344 -1.014382   0.646114  1.563473   \n",
            "396    0.228797  0.387212  -1.272672  0.204227  0.476139  -1.228069  0.667751   \n",
            "397   -1.045516  0.035999   0.988740  1.087370  1.469819   1.138616  1.606126   \n",
            "398   -1.508903 -1.017638   0.904984  1.087370 -0.020702  -0.494887  0.373917   \n",
            "399    0.692184 -0.315213  -1.049323  0.204227 -0.683155   2.856802  1.760152   \n",
            "\n",
            "          ram      sc_h      sc_w  talk_time  three_g  touch_screen      wifi  \n",
            "0   -0.417255  0.846955 -0.423853  -0.248041   0.5581      0.995013  1.015114  \n",
            "1    1.587128  0.598945 -0.655467   0.495153   0.5581     -1.005013  1.015114  \n",
            "2    1.193427 -1.385136 -0.192239  -1.177034   0.5581      0.995013 -0.985111  \n",
            "3    0.402248  0.598945  1.197443   0.680952   0.5581     -1.005013  1.015114  \n",
            "4    0.183210 -0.641106 -1.118694   1.609945   0.5581     -1.005013  1.015114  \n",
            "..        ...       ...       ...        ...      ...           ...       ...  \n",
            "395  1.705144  0.846955  1.892284   0.495153   0.5581     -1.005013  1.015114  \n",
            "396  0.745910 -0.641106 -0.192239   0.866750   0.5581      0.995013  1.015114  \n",
            "397 -0.176502 -0.145086  0.270988  -0.433840   0.5581     -1.005013 -0.985111  \n",
            "398 -0.709934  0.598945  0.502602  -1.734430   0.5581      0.995013 -0.985111  \n",
            "399  0.772346  1.094965  0.502602   0.680952   0.5581     -1.005013  1.015114  \n",
            "\n",
            "[400 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi layer neural network using Keras"
      ],
      "metadata": {
        "id": "_yH7DQBlU8Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.api._v2.keras as keras\n",
        "from keras import layers\n",
        "callback =keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
        "model_1= keras.Sequential()"
      ],
      "metadata": {
        "id": "hAawTNirNcGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "gBt9_xnVV0rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=4,activation='softmax'))"
      ],
      "metadata": {
        "id": "I49_L-SuV3L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the learning process of the model"
      ],
      "metadata": {
        "id": "GJYe0VLTXIya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "0N2wjmoBXahy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPP0nFqM8aLE",
        "outputId": "1651afde-f4ab-452b-bee2-1f73ce022e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 17)                357       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                216       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate on your training data in batches"
      ],
      "metadata": {
        "id": "gJilqP1FakMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = tf.one_hot(train_label, 4)\n",
        "Y_test=tf.one_hot(test_label,4)\n",
        "history_1=model_1.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6UHprvwbx7r",
        "outputId": "153211e7-6d18-42da-9fae-dd06679438fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 3s 11ms/step - loss: 1.3662 - accuracy: 0.2975 - val_loss: 1.3552 - val_accuracy: 0.2950\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.3476 - accuracy: 0.3006 - val_loss: 1.3392 - val_accuracy: 0.2950\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.3330 - accuracy: 0.3113 - val_loss: 1.3267 - val_accuracy: 0.2875\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3210 - accuracy: 0.3237 - val_loss: 1.3161 - val_accuracy: 0.3000\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3103 - accuracy: 0.3375 - val_loss: 1.3065 - val_accuracy: 0.3000\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3006 - accuracy: 0.3438 - val_loss: 1.2974 - val_accuracy: 0.3175\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.3587 - val_loss: 1.2887 - val_accuracy: 0.3250\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2820 - accuracy: 0.3719 - val_loss: 1.2800 - val_accuracy: 0.3425\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2728 - accuracy: 0.3825 - val_loss: 1.2712 - val_accuracy: 0.3550\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2635 - accuracy: 0.3856 - val_loss: 1.2622 - val_accuracy: 0.3700\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2538 - accuracy: 0.3969 - val_loss: 1.2530 - val_accuracy: 0.3750\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2438 - accuracy: 0.4081 - val_loss: 1.2435 - val_accuracy: 0.3825\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2333 - accuracy: 0.4144 - val_loss: 1.2337 - val_accuracy: 0.3850\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2226 - accuracy: 0.4250 - val_loss: 1.2240 - val_accuracy: 0.3900\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2117 - accuracy: 0.4281 - val_loss: 1.2142 - val_accuracy: 0.3925\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2007 - accuracy: 0.4375 - val_loss: 1.2043 - val_accuracy: 0.4025\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1895 - accuracy: 0.4425 - val_loss: 1.1941 - val_accuracy: 0.4075\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1778 - accuracy: 0.4500 - val_loss: 1.1836 - val_accuracy: 0.4100\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1658 - accuracy: 0.4519 - val_loss: 1.1729 - val_accuracy: 0.4125\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1536 - accuracy: 0.4606 - val_loss: 1.1622 - val_accuracy: 0.4175\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1414 - accuracy: 0.4619 - val_loss: 1.1513 - val_accuracy: 0.4225\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1290 - accuracy: 0.4712 - val_loss: 1.1401 - val_accuracy: 0.4325\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1166 - accuracy: 0.4744 - val_loss: 1.1288 - val_accuracy: 0.4400\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1040 - accuracy: 0.4825 - val_loss: 1.1175 - val_accuracy: 0.4475\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0913 - accuracy: 0.4856 - val_loss: 1.1061 - val_accuracy: 0.4475\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0786 - accuracy: 0.4919 - val_loss: 1.0945 - val_accuracy: 0.4475\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0656 - accuracy: 0.4981 - val_loss: 1.0827 - val_accuracy: 0.4475\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0526 - accuracy: 0.5100 - val_loss: 1.0709 - val_accuracy: 0.4550\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0395 - accuracy: 0.5119 - val_loss: 1.0587 - val_accuracy: 0.4550\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.5144 - val_loss: 1.0466 - val_accuracy: 0.4625\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0130 - accuracy: 0.5206 - val_loss: 1.0344 - val_accuracy: 0.4675\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9995 - accuracy: 0.5250 - val_loss: 1.0220 - val_accuracy: 0.4750\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5350 - val_loss: 1.0095 - val_accuracy: 0.4875\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5437 - val_loss: 0.9970 - val_accuracy: 0.4900\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9585 - accuracy: 0.5531 - val_loss: 0.9844 - val_accuracy: 0.4950\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9448 - accuracy: 0.5631 - val_loss: 0.9720 - val_accuracy: 0.5100\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9311 - accuracy: 0.5725 - val_loss: 0.9593 - val_accuracy: 0.5150\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9172 - accuracy: 0.5844 - val_loss: 0.9466 - val_accuracy: 0.5225\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9032 - accuracy: 0.5944 - val_loss: 0.9337 - val_accuracy: 0.5325\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8892 - accuracy: 0.6006 - val_loss: 0.9204 - val_accuracy: 0.5475\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6169 - val_loss: 0.9073 - val_accuracy: 0.5550\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.6256 - val_loss: 0.8942 - val_accuracy: 0.5575\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8472 - accuracy: 0.6344 - val_loss: 0.8808 - val_accuracy: 0.5675\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8335 - accuracy: 0.6488 - val_loss: 0.8675 - val_accuracy: 0.5825\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8199 - accuracy: 0.6581 - val_loss: 0.8544 - val_accuracy: 0.6050\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8064 - accuracy: 0.6681 - val_loss: 0.8410 - val_accuracy: 0.6200\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7930 - accuracy: 0.6744 - val_loss: 0.8270 - val_accuracy: 0.6350\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.6919 - val_loss: 0.8140 - val_accuracy: 0.6450\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.6981 - val_loss: 0.8003 - val_accuracy: 0.6450\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7056 - val_loss: 0.7874 - val_accuracy: 0.6550\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7411 - accuracy: 0.7081 - val_loss: 0.7739 - val_accuracy: 0.6675\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.7225 - val_loss: 0.7608 - val_accuracy: 0.6750\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.7275 - val_loss: 0.7481 - val_accuracy: 0.6700\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.7300 - val_loss: 0.7351 - val_accuracy: 0.6775\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7400 - val_loss: 0.7229 - val_accuracy: 0.6850\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.7469 - val_loss: 0.7098 - val_accuracy: 0.6875\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.7581 - val_loss: 0.6970 - val_accuracy: 0.7000\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7694 - val_loss: 0.6847 - val_accuracy: 0.7225\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7750 - val_loss: 0.6728 - val_accuracy: 0.7250\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.7781 - val_loss: 0.6599 - val_accuracy: 0.7375\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7881 - val_loss: 0.6490 - val_accuracy: 0.7450\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7881 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.7894 - val_loss: 0.6264 - val_accuracy: 0.7625\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7981 - val_loss: 0.6153 - val_accuracy: 0.7625\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.8062 - val_loss: 0.6053 - val_accuracy: 0.7625\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.8087 - val_loss: 0.5951 - val_accuracy: 0.7650\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.8106 - val_loss: 0.5839 - val_accuracy: 0.7725\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8219 - val_loss: 0.5756 - val_accuracy: 0.7800\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.8213 - val_loss: 0.5648 - val_accuracy: 0.7825\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8275 - val_loss: 0.5547 - val_accuracy: 0.7950\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8294 - val_loss: 0.5460 - val_accuracy: 0.8025\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8313 - val_loss: 0.5380 - val_accuracy: 0.8025\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8344 - val_loss: 0.5289 - val_accuracy: 0.8050\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8344 - val_loss: 0.5214 - val_accuracy: 0.8100\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8388 - val_loss: 0.5135 - val_accuracy: 0.8050\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8413 - val_loss: 0.5055 - val_accuracy: 0.8075\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.8450 - val_loss: 0.4972 - val_accuracy: 0.8075\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8475 - val_loss: 0.4897 - val_accuracy: 0.8100\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8506 - val_loss: 0.4818 - val_accuracy: 0.8150\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8544 - val_loss: 0.4747 - val_accuracy: 0.8150\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8569 - val_loss: 0.4678 - val_accuracy: 0.8150\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8587 - val_loss: 0.4612 - val_accuracy: 0.8200\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8625 - val_loss: 0.4554 - val_accuracy: 0.8200\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8675 - val_loss: 0.4504 - val_accuracy: 0.8225\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8750 - val_loss: 0.4438 - val_accuracy: 0.8225\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8756 - val_loss: 0.4395 - val_accuracy: 0.8250\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8763 - val_loss: 0.4334 - val_accuracy: 0.8275\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8775 - val_loss: 0.4283 - val_accuracy: 0.8250\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8781 - val_loss: 0.4211 - val_accuracy: 0.8250\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8825 - val_loss: 0.4142 - val_accuracy: 0.8275\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8844 - val_loss: 0.4113 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8844 - val_loss: 0.4057 - val_accuracy: 0.8350\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8875 - val_loss: 0.4023 - val_accuracy: 0.8300\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8863 - val_loss: 0.3935 - val_accuracy: 0.8375\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8900 - val_loss: 0.3921 - val_accuracy: 0.8350\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8900 - val_loss: 0.3886 - val_accuracy: 0.8350\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8919 - val_loss: 0.3812 - val_accuracy: 0.8375\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8981 - val_loss: 0.3811 - val_accuracy: 0.8375\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8988 - val_loss: 0.3753 - val_accuracy: 0.8400\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.9013 - val_loss: 0.3709 - val_accuracy: 0.8400\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.9006 - val_loss: 0.3683 - val_accuracy: 0.8425\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8994 - val_loss: 0.3618 - val_accuracy: 0.8450\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.9038 - val_loss: 0.3611 - val_accuracy: 0.8425\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.9038 - val_loss: 0.3563 - val_accuracy: 0.8450\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.9062 - val_loss: 0.3541 - val_accuracy: 0.8450\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.9025 - val_loss: 0.3490 - val_accuracy: 0.8425\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.9106 - val_loss: 0.3445 - val_accuracy: 0.8450\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9094 - val_loss: 0.3444 - val_accuracy: 0.8450\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.9094 - val_loss: 0.3421 - val_accuracy: 0.8450\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9137 - val_loss: 0.3377 - val_accuracy: 0.8450\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.9125 - val_loss: 0.3345 - val_accuracy: 0.8475\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2748 - accuracy: 0.9169 - val_loss: 0.3307 - val_accuracy: 0.8475\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9181 - val_loss: 0.3311 - val_accuracy: 0.8450\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.9181 - val_loss: 0.3280 - val_accuracy: 0.8450\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9144 - val_loss: 0.3228 - val_accuracy: 0.8500\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9169 - val_loss: 0.3187 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9237 - val_loss: 0.3207 - val_accuracy: 0.8525\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9200 - val_loss: 0.3142 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9231 - val_loss: 0.3130 - val_accuracy: 0.8475\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9269 - val_loss: 0.3076 - val_accuracy: 0.8500\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9269 - val_loss: 0.3050 - val_accuracy: 0.8525\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9287 - val_loss: 0.3050 - val_accuracy: 0.8500\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9262 - val_loss: 0.3035 - val_accuracy: 0.8475\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9281 - val_loss: 0.2976 - val_accuracy: 0.8550\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9287 - val_loss: 0.2972 - val_accuracy: 0.8600\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.9319 - val_loss: 0.2957 - val_accuracy: 0.8625\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9312 - val_loss: 0.2942 - val_accuracy: 0.8600\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9306 - val_loss: 0.2899 - val_accuracy: 0.8625\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.9319 - val_loss: 0.2885 - val_accuracy: 0.8625\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9325 - val_loss: 0.2878 - val_accuracy: 0.8625\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9350 - val_loss: 0.2857 - val_accuracy: 0.8625\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9369 - val_loss: 0.2840 - val_accuracy: 0.8650\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9344 - val_loss: 0.2807 - val_accuracy: 0.8600\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9356 - val_loss: 0.2778 - val_accuracy: 0.8675\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9369 - val_loss: 0.2775 - val_accuracy: 0.8625\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9350 - val_loss: 0.2763 - val_accuracy: 0.8675\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9381 - val_loss: 0.2755 - val_accuracy: 0.8625\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9362 - val_loss: 0.2718 - val_accuracy: 0.8675\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9375 - val_loss: 0.2712 - val_accuracy: 0.8650\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9356 - val_loss: 0.2665 - val_accuracy: 0.8725\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9400 - val_loss: 0.2685 - val_accuracy: 0.8650\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9394 - val_loss: 0.2639 - val_accuracy: 0.8725\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9388 - val_loss: 0.2620 - val_accuracy: 0.8750\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9406 - val_loss: 0.2657 - val_accuracy: 0.8650\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9413 - val_loss: 0.2641 - val_accuracy: 0.8675\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9406 - val_loss: 0.2610 - val_accuracy: 0.8725\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9400 - val_loss: 0.2564 - val_accuracy: 0.8775\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9431 - val_loss: 0.2611 - val_accuracy: 0.8725\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9425 - val_loss: 0.2597 - val_accuracy: 0.8750\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9450 - val_loss: 0.2580 - val_accuracy: 0.8750\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9469 - val_loss: 0.2589 - val_accuracy: 0.8700\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9438 - val_loss: 0.2582 - val_accuracy: 0.8750\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9463 - val_loss: 0.2502 - val_accuracy: 0.8825\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9513 - val_loss: 0.2533 - val_accuracy: 0.8800\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1738 - accuracy: 0.9481 - val_loss: 0.2539 - val_accuracy: 0.8750\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9475 - val_loss: 0.2511 - val_accuracy: 0.8800\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9475 - val_loss: 0.2555 - val_accuracy: 0.8750\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9475 - val_loss: 0.2435 - val_accuracy: 0.9000\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9500 - val_loss: 0.2482 - val_accuracy: 0.8825\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9506 - val_loss: 0.2441 - val_accuracy: 0.8875\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9506 - val_loss: 0.2523 - val_accuracy: 0.8875\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9488 - val_loss: 0.2426 - val_accuracy: 0.8900\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9513 - val_loss: 0.2407 - val_accuracy: 0.8925\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9500 - val_loss: 0.2426 - val_accuracy: 0.8900\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9500 - val_loss: 0.2416 - val_accuracy: 0.8925\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9525 - val_loss: 0.2415 - val_accuracy: 0.8900\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9506 - val_loss: 0.2348 - val_accuracy: 0.9050\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.9531 - val_loss: 0.2408 - val_accuracy: 0.8875\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9550 - val_loss: 0.2423 - val_accuracy: 0.8925\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9538 - val_loss: 0.2375 - val_accuracy: 0.8925\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9513 - val_loss: 0.2318 - val_accuracy: 0.9000\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9538 - val_loss: 0.2336 - val_accuracy: 0.8975\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9519 - val_loss: 0.2326 - val_accuracy: 0.8950\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9544 - val_loss: 0.2304 - val_accuracy: 0.9025\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9544 - val_loss: 0.2298 - val_accuracy: 0.9050\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9531 - val_loss: 0.2292 - val_accuracy: 0.9050\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9538 - val_loss: 0.2315 - val_accuracy: 0.8950\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9544 - val_loss: 0.2337 - val_accuracy: 0.8975\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9544 - val_loss: 0.2311 - val_accuracy: 0.8975\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9544 - val_loss: 0.2288 - val_accuracy: 0.9000\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 0.2248 - val_accuracy: 0.9050\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1422 - accuracy: 0.9588 - val_loss: 0.2258 - val_accuracy: 0.9000\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9563 - val_loss: 0.2250 - val_accuracy: 0.9000\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9575 - val_loss: 0.2272 - val_accuracy: 0.9025\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9575 - val_loss: 0.2271 - val_accuracy: 0.9025\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9556 - val_loss: 0.2243 - val_accuracy: 0.9025\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9575 - val_loss: 0.2203 - val_accuracy: 0.9100\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9600 - val_loss: 0.2237 - val_accuracy: 0.9050\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9600 - val_loss: 0.2237 - val_accuracy: 0.9050\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9581 - val_loss: 0.2221 - val_accuracy: 0.9050\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9588 - val_loss: 0.2204 - val_accuracy: 0.9050\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9613 - val_loss: 0.2195 - val_accuracy: 0.9050\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9600 - val_loss: 0.2197 - val_accuracy: 0.9050\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9625 - val_loss: 0.2211 - val_accuracy: 0.9050\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9600 - val_loss: 0.2153 - val_accuracy: 0.9075\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9619 - val_loss: 0.2187 - val_accuracy: 0.9050\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9625 - val_loss: 0.2138 - val_accuracy: 0.9100\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9644 - val_loss: 0.2159 - val_accuracy: 0.9050\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9613 - val_loss: 0.2133 - val_accuracy: 0.9075\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9613 - val_loss: 0.2118 - val_accuracy: 0.9075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate your test loss and metrics "
      ],
      "metadata": {
        "id": "MlY8sV31-cdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=tf.one_hot(test_label,4)\n",
        "history_test=model_1.evaluate(norm_test_dataframe,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLOJ6OH__yqS",
        "outputId": "134accf5-2615-469d-e9f2-2e228b371fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_1.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu-QVJQRpplc",
        "outputId": "272424d8-c00a-4fe1-afe2-b4c32a322fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict for the given input"
      ],
      "metadata": {
        "id": "jZ7x77HyJGJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.predict(norm_test_data_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSJ3iJnhJMFa",
        "outputId": "e7e08394-9b5d-4741-d060-702a790275d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2414217e-05, 1.5167384e-01, 8.4815592e-01, 1.4782989e-04],\n",
              "       [3.2122600e-17, 8.0259667e-08, 6.8477648e-03, 9.9315214e-01],\n",
              "       [1.9356408e-17, 5.1034846e-08, 7.6031815e-03, 9.9239677e-01],\n",
              "       ...,\n",
              "       [6.8245081e-09, 2.6454946e-03, 9.8469573e-01, 1.2658727e-02],\n",
              "       [9.5838022e-01, 4.1619778e-02, 8.0049950e-10, 5.1753437e-23],\n",
              "       [1.5354150e-17, 5.6971192e-08, 6.2864362e-03, 9.9371344e-01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop"
      ],
      "metadata": {
        "id": "5Zk2nDKaWVv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2= keras.Sequential()\n",
        "model_2.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtVqmzURwYL-",
        "outputId": "59d05ef2-ec8f-4395-f330-c932b7c5619a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_2=model_2.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vuo33CUKwsOb",
        "outputId": "a4ea7778-e77a-4392-e00f-d4828d030dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.3756 - accuracy: 0.3194 - val_loss: 1.3205 - val_accuracy: 0.3825\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2427 - accuracy: 0.4187 - val_loss: 1.1228 - val_accuracy: 0.4975\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.5450 - val_loss: 0.8704 - val_accuracy: 0.6125\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7537 - accuracy: 0.6700 - val_loss: 0.6670 - val_accuracy: 0.7150\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7788 - val_loss: 0.5179 - val_accuracy: 0.8075\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8413 - val_loss: 0.4232 - val_accuracy: 0.8375\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8775 - val_loss: 0.3629 - val_accuracy: 0.8575\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.9006 - val_loss: 0.3338 - val_accuracy: 0.8575\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9081 - val_loss: 0.2903 - val_accuracy: 0.8950\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9194 - val_loss: 0.2868 - val_accuracy: 0.8975\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9206 - val_loss: 0.2520 - val_accuracy: 0.9050\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9312 - val_loss: 0.2551 - val_accuracy: 0.9075\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9431 - val_loss: 0.2615 - val_accuracy: 0.8900\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9456 - val_loss: 0.2429 - val_accuracy: 0.9025\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9481 - val_loss: 0.2430 - val_accuracy: 0.8975\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9519 - val_loss: 0.2283 - val_accuracy: 0.9100\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9550 - val_loss: 0.2600 - val_accuracy: 0.8925\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9581 - val_loss: 0.2215 - val_accuracy: 0.9100\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9638 - val_loss: 0.2154 - val_accuracy: 0.9175\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9669 - val_loss: 0.2303 - val_accuracy: 0.9100\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9681 - val_loss: 0.2242 - val_accuracy: 0.9100\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9731 - val_loss: 0.2298 - val_accuracy: 0.9100\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9719 - val_loss: 0.2171 - val_accuracy: 0.9125\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9706 - val_loss: 0.2071 - val_accuracy: 0.9175\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9725 - val_loss: 0.2241 - val_accuracy: 0.9125\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9769 - val_loss: 0.2466 - val_accuracy: 0.9100\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9744 - val_loss: 0.2340 - val_accuracy: 0.9125\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0730 - accuracy: 0.9775 - val_loss: 0.2207 - val_accuracy: 0.9175\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9750 - val_loss: 0.2516 - val_accuracy: 0.8975\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.2179 - val_accuracy: 0.9150\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 0.2145 - val_accuracy: 0.9150\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9844 - val_loss: 0.2604 - val_accuracy: 0.9050\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.2131 - val_accuracy: 0.9075\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9806 - val_loss: 0.2744 - val_accuracy: 0.9025\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9856 - val_loss: 0.2249 - val_accuracy: 0.9150\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.2263 - val_accuracy: 0.9200\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9825 - val_loss: 0.2216 - val_accuracy: 0.9250\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9881 - val_loss: 0.2308 - val_accuracy: 0.9100\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9881 - val_loss: 0.2463 - val_accuracy: 0.9150\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9894 - val_loss: 0.2454 - val_accuracy: 0.9250\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9894 - val_loss: 0.2266 - val_accuracy: 0.9200\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 0.2425 - val_accuracy: 0.9175\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.2528 - val_accuracy: 0.9125\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9894 - val_loss: 0.2681 - val_accuracy: 0.9150\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.2305 - val_accuracy: 0.9175\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.2969 - val_accuracy: 0.9150\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9925 - val_loss: 0.2462 - val_accuracy: 0.9200\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.2416 - val_accuracy: 0.9100\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9931 - val_loss: 0.2898 - val_accuracy: 0.9100\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 0.2682 - val_accuracy: 0.9175\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.2985 - val_accuracy: 0.9175\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.3113 - val_accuracy: 0.9175\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.2771 - val_accuracy: 0.9150\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.2766 - val_accuracy: 0.9200\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.2794 - val_accuracy: 0.9200\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.2618 - val_accuracy: 0.9250\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.2915 - val_accuracy: 0.9250\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.2978 - val_accuracy: 0.9125\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.2832 - val_accuracy: 0.9200\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.3370 - val_accuracy: 0.9125\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.2743 - val_accuracy: 0.9300\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.2766 - val_accuracy: 0.9275\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.2802 - val_accuracy: 0.9300\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.3543 - val_accuracy: 0.9175\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.3212 - val_accuracy: 0.9200\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.2874 - val_accuracy: 0.9325\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.3575 - val_accuracy: 0.9150\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.3010 - val_accuracy: 0.9300\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.3244 - val_accuracy: 0.9225\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.3017 - val_accuracy: 0.9275\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.3273 - val_accuracy: 0.9225\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.3221 - val_accuracy: 0.9200\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.3475 - val_accuracy: 0.9300\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.3336 - val_accuracy: 0.9275\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.3154 - val_accuracy: 0.9350\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.3638 - val_accuracy: 0.9200\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.3407 - val_accuracy: 0.9225\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.4261 - val_accuracy: 0.9200\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.3543 - val_accuracy: 0.9250\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.4076 - val_accuracy: 0.9175\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9962 - val_loss: 0.3662 - val_accuracy: 0.9300\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.3535 - val_accuracy: 0.9275\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.3968 - val_accuracy: 0.9175\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.3628 - val_accuracy: 0.9300\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.3872 - val_accuracy: 0.9225\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.4056 - val_accuracy: 0.9250\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.4136 - val_accuracy: 0.9200\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.4499 - val_accuracy: 0.9100\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.4334 - val_accuracy: 0.9150\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.4007 - val_accuracy: 0.9250\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9125\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4151 - val_accuracy: 0.9300\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4135 - val_accuracy: 0.9200\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4536 - val_accuracy: 0.9250\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4868 - val_accuracy: 0.9175\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4638 - val_accuracy: 0.9175\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9200\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.4708 - val_accuracy: 0.9200\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4944 - val_accuracy: 0.9200\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.4942 - val_accuracy: 0.9150\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9225\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9200\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4691 - val_accuracy: 0.9150\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.9225\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9200\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9225\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9125\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.9200\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.5106 - val_accuracy: 0.9275\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.9150\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5832 - val_accuracy: 0.9225\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9175\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.5656 - val_accuracy: 0.9200\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9200\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.9125\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9122e-04 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.9200\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9225\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.3475e-04 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 0.9275\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9826e-04 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.9200\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4099e-04 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.9250\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9799e-04 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.9250\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6185e-04 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.9225\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.2343e-04 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.9250\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8135e-04 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.9275\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2727e-04 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.9200\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.0227e-04 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.9200\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7444e-04 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9225\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3262e-04 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.9225\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3714e-04 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.9250\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.6568 - val_accuracy: 0.9200\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0426e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.9200\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6426e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.9150\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8717e-04 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.9200\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1220e-04 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.9225\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9966e-04 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.9200\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.4351e-04 - accuracy: 0.9994 - val_loss: 0.6602 - val_accuracy: 0.9225\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4405e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.9200\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9148e-04 - accuracy: 1.0000 - val_loss: 0.6832 - val_accuracy: 0.9200\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4036e-04 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.9175\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0556e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.9275\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1636e-04 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.9125\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7150e-04 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.9150\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0454e-04 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.9225\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4043e-04 - accuracy: 1.0000 - val_loss: 0.7521 - val_accuracy: 0.9175\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0706e-04 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.9175\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0031e-04 - accuracy: 1.0000 - val_loss: 0.7502 - val_accuracy: 0.9225\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6657e-04 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.9150\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2613e-04 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.9200\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0763e-04 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.9200\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2782e-05 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.9225\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9710e-04 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.9225\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0170e-05 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.9225\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2409e-04 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.9250\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.8527e-05 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.9225\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3985e-05 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.9175\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5947e-05 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.9125\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5924e-04 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.9275\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9138e-05 - accuracy: 1.0000 - val_loss: 0.8468 - val_accuracy: 0.9275\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7152e-05 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.9250\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.5730e-05 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.9200\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2673e-05 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.9150\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9047e-05 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.9150\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6816e-05 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.9150\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5340e-05 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.9175\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5980e-05 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.9175\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.5473e-05 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.9100\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8296e-05 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.9150\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3577e-04 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.9125\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.9703 - val_accuracy: 0.9125\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.6232e-05 - accuracy: 1.0000 - val_loss: 0.9449 - val_accuracy: 0.9175\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8091e-05 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.9150\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1848e-05 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.9100\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1651e-05 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.9150\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.6736e-06 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.9100\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5535e-05 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.9150\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0528e-05 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.9150\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2929e-04 - accuracy: 0.9994 - val_loss: 1.0132 - val_accuracy: 0.9125\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1058e-05 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.9125\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.3831e-05 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.9100\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.4281e-06 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.9125\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.8558e-06 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.9175\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2214e-05 - accuracy: 1.0000 - val_loss: 1.0526 - val_accuracy: 0.9125\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1401e-04 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.9150\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7056e-04 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.9175\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.6154e-06 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.9075\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1873e-06 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.9125\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5513e-05 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.9200\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0310e-05 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.9125\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8876e-06 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9200\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2129e-06 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.9175\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7318e-05 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.9150\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6052e-06 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.9100\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2360e-06 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.9200\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7961e-05 - accuracy: 1.0000 - val_loss: 1.1728 - val_accuracy: 0.9125\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3303e-06 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 0.9125\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8900e-06 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.9125\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5187e-05 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.9150\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7875e-06 - accuracy: 1.0000 - val_loss: 1.2162 - val_accuracy: 0.9175\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4982e-06 - accuracy: 1.0000 - val_loss: 1.1555 - val_accuracy: 0.9175\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2776e-06 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.9050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam"
      ],
      "metadata": {
        "id": "4hyYHN8eWhgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3= keras.Sequential()\n",
        "model_3.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_3.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwNS3TUew1wZ",
        "outputId": "702b290b-c65a-481d-da72-6883bb2ff2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_3=model_3.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkPBUnYZ4IY8",
        "outputId": "eff8da8c-5b6e-4ad1-9223-57880d838baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.3340 - accuracy: 0.3406 - val_loss: 1.2579 - val_accuracy: 0.3850\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.4931 - val_loss: 0.9116 - val_accuracy: 0.5275\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7433 - accuracy: 0.6356 - val_loss: 0.6495 - val_accuracy: 0.7150\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8087 - val_loss: 0.4535 - val_accuracy: 0.8050\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8756 - val_loss: 0.3601 - val_accuracy: 0.8450\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9119 - val_loss: 0.3019 - val_accuracy: 0.8650\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9200 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9319 - val_loss: 0.2384 - val_accuracy: 0.9025\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.9450 - val_loss: 0.2409 - val_accuracy: 0.8875\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9463 - val_loss: 0.2163 - val_accuracy: 0.9050\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9525 - val_loss: 0.2125 - val_accuracy: 0.9200\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9575 - val_loss: 0.2024 - val_accuracy: 0.9100\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9606 - val_loss: 0.2144 - val_accuracy: 0.8950\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9613 - val_loss: 0.2059 - val_accuracy: 0.9200\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9688 - val_loss: 0.2231 - val_accuracy: 0.9025\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9744 - val_loss: 0.2050 - val_accuracy: 0.9000\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9744 - val_loss: 0.1865 - val_accuracy: 0.9150\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9769 - val_loss: 0.1921 - val_accuracy: 0.9200\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9781 - val_loss: 0.2112 - val_accuracy: 0.9100\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9762 - val_loss: 0.2044 - val_accuracy: 0.9175\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9819 - val_loss: 0.1960 - val_accuracy: 0.9125\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.2057 - val_accuracy: 0.9050\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9856 - val_loss: 0.2275 - val_accuracy: 0.8900\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9894 - val_loss: 0.2155 - val_accuracy: 0.9075\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9881 - val_loss: 0.2234 - val_accuracy: 0.9125\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9925 - val_loss: 0.2047 - val_accuracy: 0.9200\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9906 - val_loss: 0.2366 - val_accuracy: 0.9025\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9931 - val_loss: 0.2178 - val_accuracy: 0.9250\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9950 - val_loss: 0.2346 - val_accuracy: 0.9075\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9944 - val_loss: 0.2248 - val_accuracy: 0.9150\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9969 - val_loss: 0.2502 - val_accuracy: 0.9075\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9944 - val_loss: 0.2568 - val_accuracy: 0.9100\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.2420 - val_accuracy: 0.9100\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9962 - val_loss: 0.2404 - val_accuracy: 0.9100\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.2297 - val_accuracy: 0.9200\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9981 - val_loss: 0.2491 - val_accuracy: 0.9300\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9969 - val_loss: 0.2709 - val_accuracy: 0.9075\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.2681 - val_accuracy: 0.9100\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.2723 - val_accuracy: 0.9025\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9994 - val_loss: 0.2510 - val_accuracy: 0.9200\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.2810 - val_accuracy: 0.9175\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.3029 - val_accuracy: 0.9150\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9975 - val_loss: 0.3059 - val_accuracy: 0.9150\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3142 - val_accuracy: 0.9100\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.3446 - val_accuracy: 0.8975\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.2967 - val_accuracy: 0.9250\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.2997 - val_accuracy: 0.9225\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9987 - val_loss: 0.2716 - val_accuracy: 0.9250\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9175\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.3548 - val_accuracy: 0.9100\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.2814 - val_accuracy: 0.9250\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.3203 - val_accuracy: 0.9175\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.3505 - val_accuracy: 0.9050\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.3605 - val_accuracy: 0.9150\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.3578 - val_accuracy: 0.9100\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.4515 - val_accuracy: 0.8825\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9875 - val_loss: 0.4085 - val_accuracy: 0.9050\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.3279 - val_accuracy: 0.9175\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.3265 - val_accuracy: 0.9200\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9050\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9200\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9150\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9225\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9250\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9150\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9175\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.4414 - val_accuracy: 0.9075\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.3971 - val_accuracy: 0.9175\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.4000 - val_accuracy: 0.9100\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.3362 - val_accuracy: 0.9100\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9894 - val_loss: 0.5034 - val_accuracy: 0.9075\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 0.3955 - val_accuracy: 0.9075\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9150\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9150\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9150\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9150\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9125\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9125\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9125\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9150\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9125\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9100\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9125\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9100\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9175\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9125\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9125\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9125\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9075\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9125\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9125\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9125\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9125\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.8264e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9125\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.3747e-04 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9075\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3975e-04 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9100\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8008e-04 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9150\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6268e-04 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9125\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.1326e-04 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9075\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5147e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9100\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6677e-04 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9125\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.6121 - val_accuracy: 0.9025\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9725 - val_loss: 0.4175 - val_accuracy: 0.9125\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.4266 - val_accuracy: 0.9150\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9150\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9125\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9125\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9125\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.1486e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9125\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.3059e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9125\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6335e-04 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9125\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3711e-04 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9125\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9777e-04 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9125\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6031e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9150\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3054e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9150\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9824e-04 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9125\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5897e-04 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9125\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3528e-04 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9150\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0915e-04 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9125\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8313e-04 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9125\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.6918e-04 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9175\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3713e-04 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9150\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3552e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9150\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1580e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9175\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9409e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9175\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7088e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9175\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5728e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9150\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5202e-04 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.9150\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2726e-04 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.9150\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0881e-04 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9175\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0931e-04 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9175\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0039e-04 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9150\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8249e-04 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.9150\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6219e-04 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9150\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5306e-04 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.9125\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5057e-04 - accuracy: 1.0000 - val_loss: 0.5162 - val_accuracy: 0.9150\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3683e-04 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9125\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1829e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9150\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1258e-04 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.9125\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0216e-04 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.9125\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9077e-04 - accuracy: 1.0000 - val_loss: 0.5369 - val_accuracy: 0.9150\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8575e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9125\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8055e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9150\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0032e-04 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9125\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8802e-04 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.9125\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.9075\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5783e-04 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.9125\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3422e-04 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.9125\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2292e-04 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9125\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.2188e-04 - accuracy: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.9150\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2506e-04 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.9125\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 1.1257 - val_accuracy: 0.8700\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9737 - val_loss: 0.6842 - val_accuracy: 0.9000\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9937 - val_loss: 0.5624 - val_accuracy: 0.9100\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5995 - val_accuracy: 0.9125\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.5439e-04 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.9175\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7503e-04 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.9150\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0830e-04 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.9150\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7510e-04 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9100\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3721e-04 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9150\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1815e-04 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.9150\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9664e-04 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.9150\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8048e-04 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.9150\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6722e-04 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.9150\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5213e-04 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.9150\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4027e-04 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.9150\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2820e-04 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.9125\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1889e-04 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.9150\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0887e-04 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9150\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0324e-04 - accuracy: 1.0000 - val_loss: 0.5471 - val_accuracy: 0.9150\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9407e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9150\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8417e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9150\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7817e-04 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.9150\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.6966e-04 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.9150\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6356e-04 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.9125\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5903e-04 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9125\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4961e-04 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.9150\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4708e-04 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.9150\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4007e-04 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.9100\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3366e-04 - accuracy: 1.0000 - val_loss: 0.5674 - val_accuracy: 0.9125\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2822e-04 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.9100\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2356e-04 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9075\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1924e-04 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.9075\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1619e-04 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.9100\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0991e-04 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.9100\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0569e-04 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 0.9100\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0181e-04 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.9100\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.8421e-05 - accuracy: 1.0000 - val_loss: 0.5889 - val_accuracy: 0.9075\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.5716e-05 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.9125\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.0998e-05 - accuracy: 1.0000 - val_loss: 0.5966 - val_accuracy: 0.9075\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.7957e-05 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9075\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4720e-05 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.9075\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9505e-05 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9075\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7401e-05 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9075\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5107e-05 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.9100\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3151e-05 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9075\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.8627e-05 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.9100\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6848e-05 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.9075\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5642e-05 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9075\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0749e-05 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.9075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adagrad"
      ],
      "metadata": {
        "id": "Fff0b2RKWl9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4= keras.Sequential()\n",
        "model_4.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adagrad(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_4.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc5TFqYi4dc7",
        "outputId": "048a6bf2-912d-4610-b8de-ceaeb5db3184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_4=model_4.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "146OE9QQ4jim",
        "outputId": "dd8a66f0-fa32-4d18-fd4f-d3dcf44b7968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.4347 - accuracy: 0.2188 - val_loss: 1.4066 - val_accuracy: 0.2600\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4199 - accuracy: 0.2412 - val_loss: 1.3990 - val_accuracy: 0.2750\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4114 - accuracy: 0.2537 - val_loss: 1.3938 - val_accuracy: 0.2725\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4053 - accuracy: 0.2669 - val_loss: 1.3899 - val_accuracy: 0.2800\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4006 - accuracy: 0.2725 - val_loss: 1.3868 - val_accuracy: 0.2850\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.2794 - val_loss: 1.3843 - val_accuracy: 0.2950\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3934 - accuracy: 0.2844 - val_loss: 1.3822 - val_accuracy: 0.2950\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3905 - accuracy: 0.2894 - val_loss: 1.3803 - val_accuracy: 0.3050\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3879 - accuracy: 0.2944 - val_loss: 1.3786 - val_accuracy: 0.3025\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3856 - accuracy: 0.2988 - val_loss: 1.3771 - val_accuracy: 0.3050\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3834 - accuracy: 0.3025 - val_loss: 1.3757 - val_accuracy: 0.3075\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.3056 - val_loss: 1.3744 - val_accuracy: 0.3075\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3796 - accuracy: 0.3106 - val_loss: 1.3732 - val_accuracy: 0.3125\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3778 - accuracy: 0.3187 - val_loss: 1.3720 - val_accuracy: 0.3200\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3761 - accuracy: 0.3206 - val_loss: 1.3708 - val_accuracy: 0.3200\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3745 - accuracy: 0.3250 - val_loss: 1.3697 - val_accuracy: 0.3200\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3730 - accuracy: 0.3275 - val_loss: 1.3687 - val_accuracy: 0.3200\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3715 - accuracy: 0.3319 - val_loss: 1.3676 - val_accuracy: 0.3225\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3701 - accuracy: 0.3319 - val_loss: 1.3666 - val_accuracy: 0.3300\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3687 - accuracy: 0.3350 - val_loss: 1.3656 - val_accuracy: 0.3325\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3673 - accuracy: 0.3381 - val_loss: 1.3646 - val_accuracy: 0.3350\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3660 - accuracy: 0.3431 - val_loss: 1.3636 - val_accuracy: 0.3375\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3647 - accuracy: 0.3487 - val_loss: 1.3627 - val_accuracy: 0.3375\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3635 - accuracy: 0.3506 - val_loss: 1.3617 - val_accuracy: 0.3375\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3622 - accuracy: 0.3556 - val_loss: 1.3608 - val_accuracy: 0.3425\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3610 - accuracy: 0.3594 - val_loss: 1.3598 - val_accuracy: 0.3475\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3598 - accuracy: 0.3600 - val_loss: 1.3589 - val_accuracy: 0.3475\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3586 - accuracy: 0.3613 - val_loss: 1.3580 - val_accuracy: 0.3525\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3574 - accuracy: 0.3644 - val_loss: 1.3570 - val_accuracy: 0.3525\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3562 - accuracy: 0.3669 - val_loss: 1.3561 - val_accuracy: 0.3550\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3550 - accuracy: 0.3694 - val_loss: 1.3551 - val_accuracy: 0.3525\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3538 - accuracy: 0.3731 - val_loss: 1.3541 - val_accuracy: 0.3525\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3526 - accuracy: 0.3738 - val_loss: 1.3531 - val_accuracy: 0.3550\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3515 - accuracy: 0.3750 - val_loss: 1.3521 - val_accuracy: 0.3550\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3503 - accuracy: 0.3769 - val_loss: 1.3511 - val_accuracy: 0.3575\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3491 - accuracy: 0.3775 - val_loss: 1.3501 - val_accuracy: 0.3625\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3479 - accuracy: 0.3781 - val_loss: 1.3491 - val_accuracy: 0.3625\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3468 - accuracy: 0.3794 - val_loss: 1.3480 - val_accuracy: 0.3650\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3456 - accuracy: 0.3819 - val_loss: 1.3470 - val_accuracy: 0.3675\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3444 - accuracy: 0.3844 - val_loss: 1.3459 - val_accuracy: 0.3700\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3432 - accuracy: 0.3875 - val_loss: 1.3449 - val_accuracy: 0.3700\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3420 - accuracy: 0.3894 - val_loss: 1.3438 - val_accuracy: 0.3775\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3407 - accuracy: 0.3925 - val_loss: 1.3427 - val_accuracy: 0.3800\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3395 - accuracy: 0.3919 - val_loss: 1.3416 - val_accuracy: 0.3825\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3383 - accuracy: 0.3944 - val_loss: 1.3405 - val_accuracy: 0.3825\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3370 - accuracy: 0.3969 - val_loss: 1.3393 - val_accuracy: 0.3825\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3358 - accuracy: 0.4000 - val_loss: 1.3382 - val_accuracy: 0.3850\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3345 - accuracy: 0.4069 - val_loss: 1.3370 - val_accuracy: 0.3850\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3332 - accuracy: 0.4075 - val_loss: 1.3358 - val_accuracy: 0.3850\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3319 - accuracy: 0.4100 - val_loss: 1.3346 - val_accuracy: 0.3900\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3306 - accuracy: 0.4131 - val_loss: 1.3334 - val_accuracy: 0.3950\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3294 - accuracy: 0.4162 - val_loss: 1.3321 - val_accuracy: 0.3950\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3280 - accuracy: 0.4162 - val_loss: 1.3309 - val_accuracy: 0.3950\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3267 - accuracy: 0.4194 - val_loss: 1.3296 - val_accuracy: 0.3950\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3254 - accuracy: 0.4200 - val_loss: 1.3284 - val_accuracy: 0.3950\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3241 - accuracy: 0.4231 - val_loss: 1.3271 - val_accuracy: 0.3950\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3227 - accuracy: 0.4250 - val_loss: 1.3258 - val_accuracy: 0.3950\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3213 - accuracy: 0.4263 - val_loss: 1.3244 - val_accuracy: 0.4000\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3199 - accuracy: 0.4281 - val_loss: 1.3231 - val_accuracy: 0.4050\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3185 - accuracy: 0.4306 - val_loss: 1.3217 - val_accuracy: 0.4050\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3171 - accuracy: 0.4306 - val_loss: 1.3203 - val_accuracy: 0.4075\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3156 - accuracy: 0.4300 - val_loss: 1.3189 - val_accuracy: 0.4100\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3142 - accuracy: 0.4300 - val_loss: 1.3175 - val_accuracy: 0.4125\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3127 - accuracy: 0.4300 - val_loss: 1.3160 - val_accuracy: 0.4150\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3112 - accuracy: 0.4338 - val_loss: 1.3145 - val_accuracy: 0.4150\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3097 - accuracy: 0.4350 - val_loss: 1.3130 - val_accuracy: 0.4125\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3081 - accuracy: 0.4369 - val_loss: 1.3114 - val_accuracy: 0.4150\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3066 - accuracy: 0.4400 - val_loss: 1.3098 - val_accuracy: 0.4200\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3050 - accuracy: 0.4381 - val_loss: 1.3081 - val_accuracy: 0.4175\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3034 - accuracy: 0.4394 - val_loss: 1.3065 - val_accuracy: 0.4225\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3018 - accuracy: 0.4406 - val_loss: 1.3048 - val_accuracy: 0.4200\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3001 - accuracy: 0.4444 - val_loss: 1.3031 - val_accuracy: 0.4250\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2985 - accuracy: 0.4469 - val_loss: 1.3013 - val_accuracy: 0.4250\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2968 - accuracy: 0.4487 - val_loss: 1.2996 - val_accuracy: 0.4300\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2951 - accuracy: 0.4494 - val_loss: 1.2978 - val_accuracy: 0.4300\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2934 - accuracy: 0.4538 - val_loss: 1.2960 - val_accuracy: 0.4325\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2916 - accuracy: 0.4531 - val_loss: 1.2942 - val_accuracy: 0.4325\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2899 - accuracy: 0.4556 - val_loss: 1.2924 - val_accuracy: 0.4325\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2882 - accuracy: 0.4556 - val_loss: 1.2906 - val_accuracy: 0.4375\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2864 - accuracy: 0.4569 - val_loss: 1.2887 - val_accuracy: 0.4400\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2846 - accuracy: 0.4588 - val_loss: 1.2868 - val_accuracy: 0.4400\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2828 - accuracy: 0.4575 - val_loss: 1.2849 - val_accuracy: 0.4425\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2810 - accuracy: 0.4588 - val_loss: 1.2830 - val_accuracy: 0.4425\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2792 - accuracy: 0.4631 - val_loss: 1.2810 - val_accuracy: 0.4450\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2774 - accuracy: 0.4631 - val_loss: 1.2791 - val_accuracy: 0.4450\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2755 - accuracy: 0.4619 - val_loss: 1.2771 - val_accuracy: 0.4475\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2736 - accuracy: 0.4638 - val_loss: 1.2751 - val_accuracy: 0.4475\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2717 - accuracy: 0.4644 - val_loss: 1.2731 - val_accuracy: 0.4500\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2698 - accuracy: 0.4663 - val_loss: 1.2711 - val_accuracy: 0.4525\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2679 - accuracy: 0.4656 - val_loss: 1.2691 - val_accuracy: 0.4550\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2659 - accuracy: 0.4656 - val_loss: 1.2670 - val_accuracy: 0.4525\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2640 - accuracy: 0.4675 - val_loss: 1.2650 - val_accuracy: 0.4550\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2620 - accuracy: 0.4675 - val_loss: 1.2629 - val_accuracy: 0.4550\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2600 - accuracy: 0.4706 - val_loss: 1.2608 - val_accuracy: 0.4575\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2580 - accuracy: 0.4719 - val_loss: 1.2587 - val_accuracy: 0.4575\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2560 - accuracy: 0.4712 - val_loss: 1.2567 - val_accuracy: 0.4575\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2540 - accuracy: 0.4712 - val_loss: 1.2546 - val_accuracy: 0.4600\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2519 - accuracy: 0.4719 - val_loss: 1.2525 - val_accuracy: 0.4625\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2499 - accuracy: 0.4731 - val_loss: 1.2505 - val_accuracy: 0.4600\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2478 - accuracy: 0.4744 - val_loss: 1.2483 - val_accuracy: 0.4600\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2457 - accuracy: 0.4756 - val_loss: 1.2462 - val_accuracy: 0.4600\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2436 - accuracy: 0.4762 - val_loss: 1.2440 - val_accuracy: 0.4650\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2415 - accuracy: 0.4756 - val_loss: 1.2418 - val_accuracy: 0.4650\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2394 - accuracy: 0.4775 - val_loss: 1.2396 - val_accuracy: 0.4700\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2372 - accuracy: 0.4769 - val_loss: 1.2374 - val_accuracy: 0.4725\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2351 - accuracy: 0.4787 - val_loss: 1.2351 - val_accuracy: 0.4750\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2329 - accuracy: 0.4794 - val_loss: 1.2329 - val_accuracy: 0.4775\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2307 - accuracy: 0.4806 - val_loss: 1.2307 - val_accuracy: 0.4775\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2285 - accuracy: 0.4825 - val_loss: 1.2284 - val_accuracy: 0.4800\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2263 - accuracy: 0.4850 - val_loss: 1.2262 - val_accuracy: 0.4800\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2241 - accuracy: 0.4856 - val_loss: 1.2239 - val_accuracy: 0.4800\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2219 - accuracy: 0.4869 - val_loss: 1.2217 - val_accuracy: 0.4825\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2196 - accuracy: 0.4869 - val_loss: 1.2194 - val_accuracy: 0.4850\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2174 - accuracy: 0.4881 - val_loss: 1.2171 - val_accuracy: 0.4850\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2151 - accuracy: 0.4869 - val_loss: 1.2149 - val_accuracy: 0.4850\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2129 - accuracy: 0.4881 - val_loss: 1.2126 - val_accuracy: 0.4875\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2106 - accuracy: 0.4888 - val_loss: 1.2103 - val_accuracy: 0.4900\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2084 - accuracy: 0.4888 - val_loss: 1.2080 - val_accuracy: 0.4900\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2061 - accuracy: 0.4875 - val_loss: 1.2057 - val_accuracy: 0.4975\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2038 - accuracy: 0.4900 - val_loss: 1.2034 - val_accuracy: 0.4925\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2015 - accuracy: 0.4900 - val_loss: 1.2011 - val_accuracy: 0.4900\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1992 - accuracy: 0.4913 - val_loss: 1.1988 - val_accuracy: 0.4900\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1969 - accuracy: 0.4919 - val_loss: 1.1964 - val_accuracy: 0.4900\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1946 - accuracy: 0.4931 - val_loss: 1.1941 - val_accuracy: 0.4900\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1923 - accuracy: 0.4944 - val_loss: 1.1918 - val_accuracy: 0.4900\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1900 - accuracy: 0.4950 - val_loss: 1.1894 - val_accuracy: 0.4925\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1877 - accuracy: 0.4963 - val_loss: 1.1871 - val_accuracy: 0.4950\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1854 - accuracy: 0.4969 - val_loss: 1.1848 - val_accuracy: 0.4975\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1830 - accuracy: 0.4981 - val_loss: 1.1825 - val_accuracy: 0.4975\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1807 - accuracy: 0.4988 - val_loss: 1.1801 - val_accuracy: 0.5000\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1783 - accuracy: 0.4988 - val_loss: 1.1777 - val_accuracy: 0.5025\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1760 - accuracy: 0.4994 - val_loss: 1.1754 - val_accuracy: 0.5050\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1736 - accuracy: 0.5013 - val_loss: 1.1730 - val_accuracy: 0.5050\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1713 - accuracy: 0.5000 - val_loss: 1.1706 - val_accuracy: 0.5075\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1689 - accuracy: 0.5006 - val_loss: 1.1683 - val_accuracy: 0.5050\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1665 - accuracy: 0.5006 - val_loss: 1.1659 - val_accuracy: 0.5050\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1641 - accuracy: 0.5000 - val_loss: 1.1636 - val_accuracy: 0.5050\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1617 - accuracy: 0.5006 - val_loss: 1.1613 - val_accuracy: 0.5050\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1593 - accuracy: 0.5031 - val_loss: 1.1589 - val_accuracy: 0.5050\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1569 - accuracy: 0.5031 - val_loss: 1.1566 - val_accuracy: 0.5050\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1544 - accuracy: 0.5044 - val_loss: 1.1542 - val_accuracy: 0.5050\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1520 - accuracy: 0.5044 - val_loss: 1.1519 - val_accuracy: 0.5050\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1495 - accuracy: 0.5069 - val_loss: 1.1495 - val_accuracy: 0.5050\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1471 - accuracy: 0.5069 - val_loss: 1.1472 - val_accuracy: 0.5050\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1447 - accuracy: 0.5075 - val_loss: 1.1449 - val_accuracy: 0.5075\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1423 - accuracy: 0.5094 - val_loss: 1.1426 - val_accuracy: 0.5075\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1399 - accuracy: 0.5100 - val_loss: 1.1403 - val_accuracy: 0.5075\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1375 - accuracy: 0.5113 - val_loss: 1.1380 - val_accuracy: 0.5050\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1351 - accuracy: 0.5125 - val_loss: 1.1357 - val_accuracy: 0.5075\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1327 - accuracy: 0.5144 - val_loss: 1.1334 - val_accuracy: 0.5075\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1303 - accuracy: 0.5144 - val_loss: 1.1311 - val_accuracy: 0.5125\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1279 - accuracy: 0.5144 - val_loss: 1.1288 - val_accuracy: 0.5125\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.5156 - val_loss: 1.1265 - val_accuracy: 0.5125\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1232 - accuracy: 0.5169 - val_loss: 1.1243 - val_accuracy: 0.5150\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1208 - accuracy: 0.5194 - val_loss: 1.1220 - val_accuracy: 0.5175\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1185 - accuracy: 0.5200 - val_loss: 1.1197 - val_accuracy: 0.5175\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1161 - accuracy: 0.5219 - val_loss: 1.1175 - val_accuracy: 0.5175\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1137 - accuracy: 0.5238 - val_loss: 1.1152 - val_accuracy: 0.5200\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1114 - accuracy: 0.5256 - val_loss: 1.1130 - val_accuracy: 0.5200\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.5256 - val_loss: 1.1107 - val_accuracy: 0.5225\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.5288 - val_loss: 1.1084 - val_accuracy: 0.5225\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1043 - accuracy: 0.5288 - val_loss: 1.1062 - val_accuracy: 0.5225\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1019 - accuracy: 0.5275 - val_loss: 1.1039 - val_accuracy: 0.5250\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.5294 - val_loss: 1.1016 - val_accuracy: 0.5250\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.5300 - val_loss: 1.0993 - val_accuracy: 0.5250\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0949 - accuracy: 0.5319 - val_loss: 1.0971 - val_accuracy: 0.5275\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0926 - accuracy: 0.5337 - val_loss: 1.0948 - val_accuracy: 0.5300\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0903 - accuracy: 0.5350 - val_loss: 1.0926 - val_accuracy: 0.5300\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.5369 - val_loss: 1.0903 - val_accuracy: 0.5300\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.5375 - val_loss: 1.0881 - val_accuracy: 0.5300\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0833 - accuracy: 0.5381 - val_loss: 1.0859 - val_accuracy: 0.5300\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0810 - accuracy: 0.5369 - val_loss: 1.0837 - val_accuracy: 0.5300\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0788 - accuracy: 0.5394 - val_loss: 1.0815 - val_accuracy: 0.5300\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0765 - accuracy: 0.5387 - val_loss: 1.0793 - val_accuracy: 0.5300\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0742 - accuracy: 0.5394 - val_loss: 1.0771 - val_accuracy: 0.5300\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0720 - accuracy: 0.5394 - val_loss: 1.0749 - val_accuracy: 0.5300\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0697 - accuracy: 0.5406 - val_loss: 1.0728 - val_accuracy: 0.5300\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0675 - accuracy: 0.5412 - val_loss: 1.0706 - val_accuracy: 0.5300\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0653 - accuracy: 0.5412 - val_loss: 1.0685 - val_accuracy: 0.5300\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5431 - val_loss: 1.0663 - val_accuracy: 0.5300\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0608 - accuracy: 0.5431 - val_loss: 1.0642 - val_accuracy: 0.5300\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0586 - accuracy: 0.5444 - val_loss: 1.0621 - val_accuracy: 0.5350\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0564 - accuracy: 0.5456 - val_loss: 1.0599 - val_accuracy: 0.5350\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.5456 - val_loss: 1.0578 - val_accuracy: 0.5350\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0520 - accuracy: 0.5456 - val_loss: 1.0557 - val_accuracy: 0.5350\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0498 - accuracy: 0.5450 - val_loss: 1.0536 - val_accuracy: 0.5350\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.5456 - val_loss: 1.0515 - val_accuracy: 0.5350\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0454 - accuracy: 0.5456 - val_loss: 1.0494 - val_accuracy: 0.5350\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5456 - val_loss: 1.0473 - val_accuracy: 0.5350\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.5462 - val_loss: 1.0452 - val_accuracy: 0.5350\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0388 - accuracy: 0.5475 - val_loss: 1.0432 - val_accuracy: 0.5350\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.5500 - val_loss: 1.0411 - val_accuracy: 0.5350\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0345 - accuracy: 0.5512 - val_loss: 1.0391 - val_accuracy: 0.5350\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0324 - accuracy: 0.5506 - val_loss: 1.0370 - val_accuracy: 0.5350\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0302 - accuracy: 0.5519 - val_loss: 1.0350 - val_accuracy: 0.5350\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5519 - val_loss: 1.0330 - val_accuracy: 0.5400\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.5531 - val_loss: 1.0309 - val_accuracy: 0.5400\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5544 - val_loss: 1.0289 - val_accuracy: 0.5400\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0217 - accuracy: 0.5544 - val_loss: 1.0269 - val_accuracy: 0.5425\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5550 - val_loss: 1.0248 - val_accuracy: 0.5425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy for various optimizers"
      ],
      "metadata": {
        "id": "Q8FExXiIMFaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_1.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 0].plot(history_1.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 0].set_title('SGD')\n",
        "axs[0, 1].plot(history_2.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 1].plot(history_2.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 1].set_title('RMSprop')\n",
        "axs[1, 0].plot(history_3.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 0].plot(history_3.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 0].set_title('Adam')\n",
        "axs[1, 1].plot(history_4.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 1].plot(history_4.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 1].set_title('Adagrad')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ME7tPRBY4ttd",
        "outputId": "c3841541-6ea7-40dc-f128-be5995af93bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss for various optimizers"
      ],
      "metadata": {
        "id": "f3EIZyeUOEBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_1.history['loss'],label='train_loss')\n",
        "axs[0, 0].plot(history_1.history['val_loss'],label='test_loss')\n",
        "axs[0, 0].set_title('SGD')\n",
        "axs[0, 1].plot(history_2.history['loss'],label='train_loss')\n",
        "axs[0, 1].plot(history_2.history['val_loss'],label='test_loss')\n",
        "axs[0, 1].set_title('RMSprop')\n",
        "axs[1, 0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[1, 0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[1, 0].set_title('Adam')\n",
        "axs[1, 1].plot(history_4.history['loss'],label='train_loss')\n",
        "axs[1, 1].plot(history_4.history['val_loss'],label='test_loss')\n",
        "axs[1, 1].set_title('Adagrad')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "tJoHJC8qMJKy",
        "outputId": "e7f677a8-b559-4698-c34d-3c839a522d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xT5f7A8c83SfcuLbtQhuxdpgxFceFCEcXBUNzzXse9zuu+en/ugQMXiIKIAxVUEAVRAdkge4+W1dJNZ5Ln98eT0gIFCzQ9Sfq8X6+8kpxzcvJte5pvni1KKQzDMAwDwGZ1AIZhGIbvMEnBMAzDOMQkBcMwDOMQkxQMwzCMQ0xSMAzDMA4xScEwDMM4xCQFwzAM4xCTFPyQiPQTkfkikiMimSLyh4j08OxrICLvichuEckXka0iMl5E2nj2J4uI8uzLF5F9IjJdRM6x9qcyAoWIbBeRQs/1tddz/UV69o33XH+XHvGaVzzbR3ueB4vISyKS6jnPdhF51YIfp9YxScHPiEg0MB14A4gHGgFPAsUiUgeYD4QD/YEooBvwK3Dkh36sUioS6Az8BHxd9g9pGNXgYs/11QXoCjxUYd9GYGTZExFxAFcCWyoc8xDQHeiJvo7PBJadTCCe8xtVZJKC/2kFoJSarJRyKaUKlVKzlFKrgH8CucAIpdQWpWUrpT5SSr1R2cmUUnuVUq8BTwD/ExFzTRjVRim1F5iJTg5lvgP6iUic5/n5wCpgb4VjegBfK6V2e67j7Uqpj8t2ekoOD4nIWhHJEpGPRCTUs+9MTwnj3yKyF/hIREJE5FVPCXq353HIEcc/LCIZnnNf673fim8zHwD+ZyPgEpEJInJBhX8sgEHofyT3SZz3K6Au0Lo6gjQMABFpDFwAbK6wuQj4BhjueT4S+PiIly4E7hWR20Wko4hIJae/FjgPaIH+svRohX310SXppsDNwCNAb3Ry6owugRx5fAK65D0KGCcitfJ/wSQFP6OUygX6AQp4D0gXkW9FpB76oj70bUtELhGRbBHJE5FZf3Pq3Z77eG/EbdQ600QkD9gF7AceP2L/x8BIEYkFzgCmHbH/OeB/6A/+JUCaiIw64pg3lVK7lFKZwLPA1RX2uYHHlVLFSqlCz3meUkrtV0qlo6tcRxxxvsc8x/8KzEBXadU6Jin4IaXUOqXUaKVUY6AD0BB4FTgANKhw3LdKqVh0tVLw35y2kec+0wshG7XPEKVUWVtAG/QXlkOUUr8Diehv8NM9H9wV97uUUmOVUn2BWPSH/oci0rbCYbsqPN6B/j8ok66UKqrwvKHnmGMdn6WUOnic/bWGSQp+Tim1HhiPTg4/A0NOsl3gMvQ3ug3VF51R23m+dY8HXqxk9yfAfRxddXTkOQqVUmOBLKBdhV1JFR43oby0C7okXdFudFXSsY6PE5GI4+yvNUxS8DMi0kZE7vPU1SIiSehi80LgZSAOmCgiLUSL4vBGviPPV09E7kQX7x86yfYIwzieV4FzRKTzEdtfR/eKm3fkC0TkH54G4DARcXiqjqKA5RUOu0NEGotIPLrEMeU4MUwGHhWRRBFJAP6DTkoVPenpCtsfuAiYeiI/ZKAwXbX8Tx7QC90IFwtko7uoPqCUyhWR3sDTwO/of6J9nse3HXGebE/j3UF0ne0wpdSPNfQzGLWIUipdRD5GfxDnVdieiS7dVqYAeAloif7WvxEYqpTaWuGYScAsdDXPN8AzxwnjGSAa3csJ9Ad+xeP3oksiuz3vfaunFF7riFlkxzAMfyMi24EblVKzq+FcZwKfeNroaj1TfWQYhmEcYpKCYRiGcYipPjIMwzAOMSUFwzAM4xC/632UkJCgkpOTrQ7DCFBLly7NUEolWvHe5to2vKmq17bfJYXk5GSWLFlidRhGgBKRHX9/lHeYa9vwpqpe26b6yDAMwzgkoJJCUanL6hAMwzD8WkAkBaUUt3/0G/+d/JPVoRhGtdqecZBe/53Nj6v3/v3BhlEN/K5NoTIC/CfjflLz3KxN6027RrFWh2QY1SIixMG+3GLS84r+/mDDqAYBUVJAhOgBt9PdtpG5nz5HsdNUIxmBITY8CIDMg6UWR2LUFoGRFIDwHiNIr38GNx18j88+/9TqcAyjWgQ5C7g4dBXOrF1/f7BhVIOASQrYbCSOnkh2WBKXb/gXX02rlbPeGoEmfx9v8DyJBxZbHYlRSwROUgAIjSH+1u8pCEnkguW388O0SVZHZBinJiQaAHdRjsWBGLVFYCUFwB7biDp3zuZASGPOWn4XP331gdUhGcbJC4kEQBXl/c2BhlE9Ai4pADii61Hv7p9JC2vFwJX388vnr1sdkmGcHEcoLuxISb7VkRi1REAmBYCgyHiS7pnJlvDOnLX2MeZ9+rzVIRnGiROhxBGBozQfM6OxcVxb5kDqqU+TErBJASAoLJoW//ievyJOZ8Cm51g46WmrQzKME1bqiCSMAg6WmK7WxnH89Bj8+r9TPk1AJwUAR0g4be+ZxrKIAfTe+CJ/ffOK1SEZxglxOSKIopCCYqfVoRi+SClY+Rkc2AIxSad8uoBPCgCO4BDa3fU5S4J70n7Zk2yd/Z7VIRlGlbmCI4mgiAJTUjAqs2kWfH0LlBZArEkKVRYaGkaLO75kmaMTTX9/gD3zJ1sdkmFUiQqOIlIKTVIwDrf3Lxh3JuxZWb7NlBROTFxMNPVu+opVtCZx1h3krZpudUiG8bdUcBSRFFJQYqqPDI/cPfBOP9i9XFcdlTFJ4cQl1U/Adt1U1rmbEvz1DbhSl1kdkmEcl4REEmVKCkYZtxsmDy9/nrml/LGpPjo5nVs2YfM5H5DujqJwwlDI3ml1SIZxTBIaTQQmKRgem2bBnhUw5B1whJZvj6ynb6eoViYFgMv6d+Pz1q/gKiki74PLoDDb6pAMo1L2sGgipJjCkmKrQzF8QeoisDmgw+UQ6lkmoN+9cP9GsNlP+fS1NikA3HHlhbwQ+x9Cc7dR8MnV4CyxOiTDOIojTM9/VFqQa3Ekhk/YuxoSWoEjBPI9iy8l962209fqpBDisHPHDaN50nYH4WnzcX5zl+7zaxg+xBEaAYCz8KDFkRg+Yd9qqNdBP/ZMmEhSr2o7fa1OCgANYsI49+q7ecU5FMdfn8HCt6wOyTAOExyqJ8UrLTZJoVYqyNT3+fthzn8hNw0adNbbrv8ehrwNIVHV9na1PikADGiViKvfA/zg6oGa+Shs+cXqkAzjELsnKTiLzKR4tc6PD8P/NdOfSb+/Wj6NRYeh+r5+R+hyTbW+pUkKHv84pzWTGj7MJtUI1+ej9ZBxw/AFQWEAKFNSqD2ydsC7A2DhWP188QeQtV0/7ncvRDfw2lubpODhsNt44ZrTuc/+IAdL3LgnXw3FZg57wwcE6TYFd4lJCrXG+hnlI5Wbnwnrp8OGGdD+Mhj0uFff2iSFCurHhHL/8PO4tfguVMZm+PpW0/BsWC84XN+XFFgbh+FdBZlQtsJeTqq+73ETDJ8ELc7Sz6Maej0MryUFEflQRPaLyOpj7BcReV1ENovIKhHp5q1YTsQZrRLpesalPFt6jc7Of7xmdUhGbecpKSiTFAJT6hJdNfTeWfB8E/jqZtj3F9TrCBe+CMERcMVH0PYSSBnl9XC8WVIYD5x/nP0XAKd5bjcDb3sxlhPyz0GtWN5wODPpjfr5Kdj+u9UhGQFKRG4WkSUisiQ9Pb3ygzwlBXGapOCXclJh3XfH3v/+2fBaZ8japp+vmgLb5kFCy/JjwmLhqomQ2Nq7seLFpKCUmgdkHueQS4GPlbYQiBUR77WenACH3cZrw7vxmPsW9tjqo764AfL2WR2WEYCUUuOUUt2VUt0TExMrP8jT0GwzScE/fXgBTLmufHBsaZFuM1AKCrMOP3bQE+WP67arqQgPY2WbQiNgV4XnqZ5tR6nSt6lq1qROOP++tCfXF9yFsyAbvrgBXGaWSsMCnuojW2mhxYEYJyXHM7da3h59v+AN+OwaWDsNtv9RflxINJx+j25MDq8DPW+q+Vjxk4bmKn2b8oLLuzXitI69eKhkDOz4HeY8U2PvbRiHOIJxYcfuMknBr5UlhfSN+n7qaJhyrX7cfCDcMg9sNrj8PfjnGgiLsyRMK5NCGlBxntfGnm0+Q0R4dkhH5kcM4jvHefD7K7DhB6vDMmqhEnsYQSYp+Ldcz8fb7uX63h5cvu/aqRDfzLM96FCVoRWsTArfAiM9vZB6AzlKqT0WxlOpmPAgXr6qC/cfvJq00NP0sndlg0gMo4Y4bWEEuYusDsM4URXHluTugaJcOLAJBj4K/9oGt/4Ol43TicBHeLNL6mRgAdBaRFJFZIyI3Coit3oO+R7YCmwG3gNu91Ysp6p38zqMOaMtw3Nup9Tl9rQvlFodllGLuOyhhKgiXG4zbsavvF1h9tKFb8PznsqReu0hJFJPU9H5KmtiOwaHt06slLr6b/Yr4A5vvX91+8egVvy2KYOHM2/ihbSXYc6zh/cUMAwvcjnCCKOYghInUaG+863SOI7i/PJupmHxkJtavq8GupaeLL9oaPYFwQ4brw7vwnRnL+ZEXID6/VXYOtfqsIxawuUIJ5xiCs3qa/7jwCZ9f+XH0P36w/fFJdd4OFVlksIJaJEYyaMXteX2A8PICU+Gr26BgxlWh2XUAioonAgp4qBJCv4hbakeqQyQ0Br63gNtLirfXw0rpHmL16qPAtU1PZswZ306IzfeyrSQx7BNux2umQIiVodmBDAVHEUEOygoMWNlfNbvr0BwJHS+Wk9ZASB2iG8OjmAY/qme5M7t24ndlBROkIjwv6Ed2R3WkreDR8OmmfDnu1aHZQQ4FRJFpBSa6iNflZMKPz8N817QtzLth+iEUKZBZ2jkE9O8HZNJCiehTmQILwzrxAvZZ7Ahpi/89BjsWWV1WEYAk5AoIiikwCQF37TwbVAuyN8Hf7yqt90wC4Z+YG1cJ8EkhZM0sHVdRvVJZvi+ERQHx+puqma+e8NL7KFRRFJEQbGpPvIJq7+Cuc/rrumfj4QFb+q2gzKOMGjSyy+rlauUFETkHhGJ9gw0+0BElonIud4Oztc9NLgtCXUb8s+S21AHNsPMh60OyQhQ9rBobKIoKcq1OpTaq+Rg+foqX1wPc5+DHx+Etd/oyeuGfQTdRsLIb+CupdbGegqqWlK4QSmVC5wLxAEjgOe9FpWfCA2y89rwrswuasusmGGwdPzxp8g1jJPkCIsGoLTArAZYo5zF8MszsPcv+G9DWPw+5O4u37/4fUjuD7cv0APSLnlDr5QWU+ncnn6hqkmhrAw0GJiolFpTYVut1q5hNA+c15o7911EZnRb+Pauwy8aw6gGQeE6KTgLciyOpJbZ+KNuOH6nn37+/f3wctvDj2l7cc3H5UVVTQpLRWQWOinMFJEowO29sPzLmH7N6NmyHtdm3Yy7tEgv4+k2vx6j+oSExwDgLDTVRzWmOB/2VrpwpHbfRuhzJ3QeXnMx1YCqJoUxwINAD6VUARAEXH/8l9QeNpvw4rDO7HY05q3QG2HbrzD/davDMgKIzVN9ZJJCDZo8HOb9X+X7Ln4NourBec9CaEzNxuVlVU0KfYANSqlsEbkOeBQw5dgKGsSE8dzlHXkxozcb4s+Cn5+CnQutDssIFMGRALiKTJtCtVMKNs8uXxmtzPbfyh9f8gbcsViXDB47ACmjazTEmlTVpPA2UCAinYH7gC3Ax16Lyk8N7tiAK1KSuHLPNRRFNoap18PBA1aHZQSCkCh9X2ySQrXbPBs+GQpz/wvzXoT96yH/iBUeu42ExFa6ZGAP7IkgqpoUnJ5ZTS8F3lRKjQWivBeW/3rikvbExCVwW/FdqIIMvf6CaV8wTtWhpJBvbRyBaNXn+v73V+CXp+GtXvBiS73NHgxXfGhdbBaoalLIE5GH0F1RZ4iIDd2uYBwhMsTBq8O78Ft+Iz6NvQ02/1Q+wtEwTlaIblNwlJg2hWqTsQkmXQV/fX7sY0ZNhw5Day4mH1DVpHAVUIwer7AXvXTmC8d/Se3VrUkcDw9uy6NpPdmUeK7u57xjvtVhGf4sKJQSCSHYaZLCSdu3Br65Q49CVkonhI0/6n3nPQcXvABJvcqPbzkIGvewJlYLValyTCm1V0Q+BXqIyEXAIqWUaVM4juv7JrNsZxZD/7qSPxM2EvbFDXDLbxCZaHVohp8qcMQQapLCyZtyHWRu1R/0cc0gc0v5vq7X6l5EddvAF2Pgxp8gtqlfTlNxqqo6zcWVwCJgGHAl8KeIXOHNwPydnk21E/US63LDwTtQBVl6jpQjezgYRhUVB0UT6TJJ4aQ4i3VCAPjuHvj4EhCbXiN5xLTybqXNBsADm/QiOLUwIUDVq48eQY9RGKWUGgn0BB7zXliBISLEwdvXpbDK2YSXI+6GnfNhxr3l86cYxgkoDYohinyKSs1MqcfkLIGNs6DI02M+bRnsXlG+4E2ZXrfBwIf1GsktBtZ8nD6sqn2rbEqp/RWeH8DMsFolLetG8sKwztz+qYsuSSM5e/nHevKsPrdbHZrhZ1whscSyj7wiJ6FBvrtyl6VWfwHTboPwOnDLPPhoMDgLoW57QGD0dN2jKKmn1ZH6rKomhR9FZCYw2fP8KuB774QUeAZ3bMCdA1ty45xzmZOUSvKsRyChFZw2yOrQDD+iwuKJlXxyi0pJjAqxOhzflLFR3xflwivty7fvXwP1O0FyP2vi8iNV+ravlHoAGAd08tzGKaX+7c3AAs2957Ti/A4NuTD1OvJiWumpd9M3WB2W4UdsEXHEkk9mfrHVofiebb/B+4Pgj9egTku4YWb5vkvfgh43wrnPWBefH6lyFZBS6kul1L2e29feDCoQ2WzCS1d2plnDulyWeRdOWwh8PAQyt1kdmuEngiPrECJOsnPMDDNH+WsqpC4G5daNxI1Tyvd1vAIufAman2FZeP7kuElBRPJEJLeSW56ImG4QJyg82MF7I7uTG1Kf650P4S4thAmXQPYuq0Mz/EBYdAIA+dn7/+bIWmTDD/DuAFg2oXxbYZa+v/UPvRymw1S1nYjjJgWlVJRSKrqSW5RSKrqmggwkDWLC+HB0D5aXNOZ226O4i7J197jcPVaHZvi48DoNASjJquXXyq5FOhlMvkbPZLpnpd7e8Up93+UafV+/gy4lGCcksGd28lEdGsXw/qjujPrQzb/rPM7/5f8H+fgSGP29GdxWy4jIzcDNAE2aNDnusUFxSfo1ualej8vn/Py0bkTO3Ab7/jp8X/MzweWE0++CIW+B3czAcypMt1KL9G5ehzev6cZX6Q15OvpJVPYu+PhSOJhhdWhGDVJKjVNKdVdKdU9M/JsvBNF6iUdbfi0pKSwYC+/01zPD/vYirPu2PCGc9ajuWgp6aorrZ0CDTiYhVAOTFCx0Trt6/N/QTnyY2pD/xT2OytwC750F+9dZHZrhi8LiKCaEsIIATwoHtsDOP2Hmw7B3Faz8rHxfw25w8esw4AH45xo47byAXtvACl6tPhKR84HXADvwvlLq+SP2j0ZPrJfm2fSmUup9b8bka4amNMblVvz7K8hv9DxPFT6H7f1BMPR9aH2B1eEZvkSErKBEIov3WR2Jd024GHLTyp//8RqExcOdSyA8vnz6ici6cO1xZjg1TorXSgoiYgfGAhcA7YCrRaRdJYdOUUp18dxqVUIoc2WPJF65sguTd9fjlrAXcMW3gMlX6/ndzZQYRgUFofWJKd2P8vfrYvknMO2Oo7cX5RyeEABydunupBF1au18RDXJm9VHPYHNSqmtSqkS4DP0Ij1GJYZ0bcSbV3dlzu4grix5jKLWl8DsJ/QiPaVFVodn+IiSqCY0YQ85BX4+seI3d8CKT+D7B6AgU29TSl/zlWl+Zg0FZngzKTQCKnbAT/VsO9JQEVklIl+ISFJlJxKRm0VkiYgsSU9Pr+yQgHBBxwa8N6o76zJcnLVtJOk97odVU2D8hZC31+rwDB/grtuOeMlnb9p2q0OpHovGwY8Pwetd4fv7YcmH0PMWuPg1vf+853QbQqerrI2zFrG6ofk7IFkp1Qn4CZhQ2UEn1EPDzw1sXZept/bBBQxc1JM1/d/SDc9v9YHVX1kdnmGxsEYdAcjfudLiSE7BkVVfqz7T01ovfl9PXHf+c9BtFNy+UE8cmTIKgsKsibUW8mZSSAMqfvNvTHmDMgBKqQNKqbKJXN4HUjBo3zCGaXf0JSk+nEt+jmNqt49Rccl6vqTJ1+jeGUatFN+8CwCuvWssjuQYlNLdqt1u2PTT0QmgbMWzY+n3D7DZddtB3bbejdWolDeTwmLgNBFpJiLBwHDg24oHiEiDCk8vAUxfTI8GMWFMvbUPg9rW5YFfi7kt5HkKz/wPbPsVxvaEmY9AyUGrwzRqWHR8PTbTmHp7frE6lMptng0vtYafn4RPr4AVk/R2ZzHMuF/PUbRpZuWv7XodtBtSc7EalfJal1SllFNE7gRmorukfqiUWiMiTwFLlFLfAneLyCWAE8gERnsrHn8UGeLgnetS+PCP7Tz3/TrO3deVcVfMpe36N2DBm7B+OlzyJjTrb3WoRg0REf6MHMS1+eMha7ue/M1qeXt1Ihg2ATI2gdsJf76r9237Va9mNvMhWPcdLH6v/HXDJ0PT03Vvo5BoiK20SdGoYV5tU1BKfa+UaqWUaqGUetaz7T+ehIBS6iGlVHulVGel1ECl1HpvxuOPRIQx/Zox5ZY+OF2KSyds5oP4f+IeNUMvJzjhIvh0GOyYb7qv1hJ7G54LgNoyt+bfPCft6OrLXYv0/aJx5eseOwv1/aop8GoHnRAquncdtBkMYbFQr71JCD7E6oZmo4pSmsYx4+7+9D8tgaenr+XqWXZSr/pJj+zcsxI+ugAmDoFdi3V9rhGw6jRpS7qKoXjzPO+/WerS8rWNc3fDK+3gjW7lX0B2r4Cfn9KPbfZjt3dFJMIdi/X0FH3/AdENvR+7cVLMhHh+JD4imPdHdWfq0lSe/m4t545dwj8HXcPoO+4maNl43cd76yCo11H32Og4TH8TMwJK24Yx/Oluy0Xrv4Q1l0B7L9bDv3+Wvk8ZDUvHl29fMQlCouDzEeXbMrdDST40Hwhb50B4gh5fIDa9HnJ8M0h8wHuxGtVC/G1kZPfu3dWSJUv+/sAAl5ZdyGPTVvPL+v20rhfFU5e2p1dCiW7om/04FByAsDjofA30uQNiKhsiYhxJRJYqpbpb8d5VvbZLnG4GP/UJ04L/Q2SdxnCTp9HZEXxib5iTCm+fDiOmQaNuh+8rztMj6n976fDtEYl6vQK3s3xbw666xIDns2Twi/r1yf0hqceJxWR4TVWvbZMU/JhSitnr9vPEt2tIyy7k8q6NeOD81jSIDNITic17ETbNAnep/sftMBS6jYTQGKtD91n+kBQAxoxfTMruT7i9ZLze0HwgDJ+k1yUe9IQuKVZUWgQ2B2Rs0FNJrP0W/nxb72t/GQwbD26XHl0ckaB7Dm2effQbX/uFbhTeNg/mPAONe8CNsyFvnx5v0LgHJPUGm6mZ9jUmKdQihSUu3pq7mXd/1XW/w3smcduZLWgQEwYZm2HNV7Bmml68PCQa6rbTPZa6XucbvVd8iL8khc8W7eSNr35hbtwzBBUeMcpfbPDIPj2NtHLr5x9doBez31/J+IYWZ8M1U2D8RbBrITjCyhuKK7pzKSS0LH++dzVE1jNrgPgJkxRqodSsAsbO2cLUJbuwiXB1zyRuO7Ml9WNC9QG7l+uugpnbIHWRbixMaKV7f/S6BRql1Pr56P0lKeQUlNL92Z+4tldTnriwtV5vYO5z5QeITSeEqIZw5r/hu3uOf8KIunCwwjKfXa7TpYGcnbrbc84uOPMhMyGdHzNJoRbblVnAW3M3M3VJ6qHkcPMZLWgUW2GqgJw0WD5RJ4pdi6DQMylZq/N1A3X7y3RvklrGX5ICwD+nrOCH1Xv47V9nkRgVoj/Edy6EOc/qA2KS9Ic5QEwT3bb06//K/9Zlmp2hp1LpfRt0Hq7nH+p7jx5wlrUDGpuJBgKBSQoGuzILGDtnM18sTcWtFGe2rsvwHkmc1aYuDnuFOt+Sg7Bysu5+uPEH3ZDoCIXwOjo5ND0d4prpaQcC/JuiPyWFren5DHr5V8b0a8YjF1aYlT5jM5Tk6XakXYtg+r1w3rN6+mmlIGub/lsHR+geQWY6iVrBJAXjkNSsAqYs3sWUxbvYn1dMvegQhqUkcVWPJJLiww8/2O2GDd/DzgV6xOz66eX74ptD/Y5Q5zTdW6XFWQE3UZk/JQWAe6esYMZfe5hxdz9a1o3yUmRGIDBJwTiK0+Xml/X7+WzxLuZu2I8C+p+WyNU9kjirbV1CHJVUF+Wn6yqIPSth40y9eHrWNl1fbQ/WXRQjEiG5n26TiG2qE4azyC8Thr8lhf25RZz/2m/Uiw7l69tPJzSo9lX5GVVjkoJxXLuzC/l8iS497MkpIiYsiMEd63N+hwb0bh5feYIo4yzW02psnatnxMzcArv+1IkCdJfXohxdoqjXTh8f20RXXbQYqBegtzn0WIpmAzzn9I0k4m9JAeDndfsYM2EJA1snMvbaboQHmzGpxtFMUjCqxOVW/LYpnW9X7Gbmmr0cLHERGeKgX8sEBrZJ5MzWdakXHVqFE5XC1l8hewekLtalh71/6QnR4ppB/n49XsJ5xCpywZG6/cJVCuc8qXvNhERB/U56rEWjbjXabdYfkwLApD938ui0v2hVL4rnh3aiS5IZyW4cziQF44QVlbqYvyWDn9buZ+6G/ezJ0R/g7RpEM7BNIme0qkvnpJjjlyKO5HaXD2RyFuseT2FxesTr0vF6rhxXaeX94gFsQZDUU4+viGmsk036OkCg9QV6zIVy6cFTia11j5uyUsdJNIr7a1IA+GX9Ph766i/25xUzondT7j+vNdGhtbuLsVHOJAXjlCil2LAvjznr05mzYT9Ld2ThciuCHTa6NI6lR7M4uifHk9I07uQ/eMquPRGdMDI26aqnzK2wfoaeRXPN15C2VCeX3FRdLRXdGFwlh/erLxMUDqUFEBKje9Yoly6NxDfXYzIiEnXpI6FVpV1u/TkpAOQVlfLSrI1MWLCdxMgQHh7clos6NTi8t5lRK4LKgp8AACAASURBVJmkYFSrnMJSFm49wJLtmSzansWatBycboVNoE39aHokx9GjWTydG8fSOC4M8VbX1dIiCArVSSJtqa6uEhtENdCjcdM36lG3ubt1crEFwZ4VkL/v8PP8Y3Wl0zX7e1Iosyo1m4e//ovVabk0iAllWEpjhnWvpLeZUWuYpGB4VUGJkxU7s1m0PZPF2zNZtiObwlIXANGhDto3jKFdw2jaNoimbYMoWiRGWtczRik9gVv+Pj0mY88q6HhFpdVLgZIUQLcX/bxuH5/8uZPfNqWjlK4K7H9aAhd2akDHRjHeS96GzzFJwahRpS436/bksjotlzW7c1i9O5cNe3MpKtU9kkSgSXw4p9WNpGXdKE6rG8lp9SJpnhhJZIjv9JYJpKRQ0e7sQqatSOPXDeks25lFqUvRKDaMetEhtKwbSYvESAZ3bED9mFCCTFVTQDJJwbCcy63YlnGQ9Xtz2bw/n03789m8L5+tGfmUusqvuzoRwSTFh5MUH06T+DAax4VTPyaUhjFh1I8JJTrUUWPfaAM1KVSUW1TKNyt2s2R7JntzitiSfpCM/GIA7DahSXw4zRIiaJYQQZP4cOpGhdCkTjgtEiMJstuw20zpwh9V9dr2na9oRsCx24SWdSNpWTfysO1Ol5udmQVs2p/P1vSD7MoqYFdmAatSs/nhrz043Yd/UYkItlM/JpQGMWE0iAnVt1idMOpHh1I3KoS48GBs5sOqSqJDgxjRuykjejc9tG1bxkHmbthPRn4x2zIOsjX9IPO3ZBwq6ZUJttto1zCaqFAHCZEh1I0OIcRhp1FsKCJCaJCddg2iSIoPxy5CqUsRFmwG1PkTkxSMGuew22ieqKuOjuR0udmfV8yenEL25BSxJ7tI33uez9uUzv684qOWo3bY5NCHVN2oEBKjQkiIDCE+Ipj4iGDiwj33EcHEhwebD6oj6JJBs8O2ud2KjPxi0vOLWZWaQ3peMXlFpaxKzSG3yMnW9IPszyvC6VaVLg9utwkCJCdEEGS3UeLUY2AiQhxEem4KvWhQnchgbCKev1UQdpsNuw3iI0JQSmG3CQ67jSC7HKresgkE2W3YRLDb9M0mHHpecXtFUuGBeJ6JlG8vK5XKoe3lOysedzJOpcRblVfabXLKbXcmKRg+xWG30TA2jIaxxx7dXOpJHHtzCtmbU0x6XhH784pJzytmf14xadlFrNiVQ+bBYtzHqB1d+NDZ5VOKG5Wy2YS60aHUjQ6lfcNjL8xU4nSzL7eIEpebvCIn6/bkciC/mIMlLtxuxa6sAopK3YQG2cgvdnGw2EnmwQLyi52I54M9NbMQm42jSibGiRnYOpGPru95SucwScHwO0F2G41iww6fCrwSbrcip7CUzIISsg6WkFl2KyghLsI3BnWJyM3AzQBNmjSxOJqTE+ywHdbV9WRGU5e1bTrdiqyDJYdKEFkFJdhEcLkVTrebUpei1KUTh1tBqdONSyncbqXvlf67u8qee+7LSgTKs2SoUocWDwWlDj0uK/Eoz7aKx51q++upvLw8wuNLijv1LscmKRgBy2YT4jxVRvjo4mBKqXHAONANzRaHY5myapUguy6dlDHjKmqe6XtmGIZhHGKSgmEYhnGI341TEJF0YMcxdicAGTUYzvGYWI7mK3HAsWNpqpSypLLJT65tX4kDTCzHckrXtt8lheMRkSVWDTw6konFd+MA34qlKnwlXl+JA0wsx3KqsZjqI8MwDOMQkxQMwzCMQwItKYyzOoAKTCxH85U4wLdiqQpfiddX4gATy7GcUiwB1aZQ24nIeCBVKfWo1bEYRlX50nUrIqOBG5VS/ayOxSqBVlIIWCIyV0SyRCTE6lgMo6rMdet/TFLwAyKSDPRHj7i/xNJgDKOKrL5uRcTM2HASTFLwDyOBhcB4YFTZRhHpKiLLRCRPRKYAoRX2xYnIdBFJ93xTmy4ijSvsnysiz4jIfBHJF5HvRKSOiHwqIrkistjzT20YJ8sb120zEZnnee1sERkrIp949iWLiBKRMSKyE/jFs32qiOwVkRzPa9tXOF8dEfnWc80vAlp4+Xfi80xS8A8jgU89t/NEpJ6IBAPTgIlAPDAVGFrhNTbgI6Ap0AQoBN484rzDgRFAI/Q/wwLPa+KBdcDjXvp5jNrBG9ftJGARUAd4An39HukMoC1wnuf5D8BpQF1gmSeeMmOBIqABcIPnVrsppczNh29AP6AUSPA8Xw/8ExgA7MbTWcCzbz7wzDHO0wXIqvB8LvBIhecvAT9UeH4xsMLqn9/c/PPmjesWnSScQHiF/Z8An3geJ6OrqpofJ65YzzExgN0TY5sK+/8L/G7178/Kmykp+L5RwCylVNmw9UmebQ2BNOW5kj0OTZEgIuEi8q6I7BCRXGAeECsiFVfg2FfhcWElz49eBccwqsYb121DIFMpVVDhtbsqee9D20TELiLPi8gWz/m2e3YloOfOdRxxjmNNM1JrmIYYHyYiYcCVgF1E9no2h6C/7ewBGomIVPgHawJs8Ty+D2gN9FJK7RWRLsByTm3hKMP4W168bvcA8SISXiExJFUSQsWEcw1wKTAInRBigCzP+dLRJY8kdEmmLJZazZQUfNsQwAW0Qxeju6DrSn/z7HMCd4tIkIhcDlRccikK/W0/W0TiMe0DRs3xynWrlNoBLAGeEJFgEemDruY8niigGDgAhKOrh8rO5wK+8pwvXETaUaFBvLYyScG3jQI+UkrtVErtLbuhG96uBi4HRgOZwFXoC7zMq0AYerbEhcCPNRm4Uat587q9FuiD/pB/BpiC/tA/lo/RVUJpwFrPOSu6E11NuhfdS+qjE/g5A5IZ0WwYht/ydGldr5QyJeFqYkoKhmH4DRHpISItRMQmIuej2wumWR1XIDENzYZh+JP66OqmOkAqcJtSarm1IQUWU31kGIZhHGKqjwzDMIxD/K76KCEhQSUnJ1sdhhGgli5dmqEsWqPZXNuGN1X12va7pJCcnMySJUusDsMIUCJi2YhWc20b3lTVa9tUHxmGYRiHBExSWLoji6U7Mq0OwzCqVUGJkznr97M/t8jqUIxaImCSwvM/rOOFmRusDsMwqtXenCKuH7+YORv2Wx2KUUsETFIIC3ZQWOq2OgzDqFbNEiKICQtixa5sq0MxaomASQrhQXYKS5xWh2EY1UpE6JIUy/KdJikYNSNwkkKwnYISl9VhGEa169oklg378sg8WGJ1KEYtEDBJoT77iSvebXUYhlHtzmtfH6Xg2xVpVodi1AIBkxSu3vU0j7jetjoMw6heStG2aCU9Gjr4eOEOnC7TbmZ4V8AkBbc9BIcqwczlZASUPSthwkU80WQ1W9MPMmnRTqsjMgJcwCQFZQ8hmFKKTA8kI5A06AwNutAu7XMGtIznmRnrWLs71+qojAAWMEkBRwghlFJgeiAZfkREbhaRJSKyJD09vbIDoM8dSPp6xrZfR2xYEDdPXMKuzIKjjzWMahAwSUEcoYRQSmGp6YFk+A+l1DilVHelVPfExGPMVdbhCmjal6hfHuWTC4LJLSzlqncXmBKD4RUBlBRCCJZSCk23VCPQ2GxwxYcQXodWPwxn+rm5ON2Ky976g4kLd+B2m3Y0o/oETFKwBYV6qo9MUjACUFR9GDMLElrSZNaNzGvxKRclFfHYtNUMfWc+q9NyrI7QCBABlRSCcZqkYASu6AZwwyw440FCN83gxb038FuLT4jPWMpFb/zGbZ8sZeO+PKujNPyc362ncCy24BBCKKHItCn4roJMEBuExVodif8KCoWBD0H365EFY0la8iEfuL8nKzaJiZtO57a1PWjRpis39GtGr2bxiIjVERt+JmCSgiM4jGBxUVBcanUoxrH8XzN9/4Sp6jhlUfXh3KfhjH/Dum+JW/4pd++Ywt3BU9iytTHTN/ZgYtxABvQ/k4s6NyIiJGD+1Q0vC5grxREcBkBRkemqZ9QiIZHQ5Rp9y0mF9TNIXvstd+34Blve1+ycnsiXM7pT2Ow8UgZcSEqzRFN6MI4rgJJCKAClxYUWR2IYFolpDL1uwd7rFjiYgVo/g+jl07g67WeCtv9A9rZHmB3UHXerwXQ96wrqJiRYHbHhgwInKYTokkJpsSkpGAYRCUjKKGJTRkHJQYrW/0TWoq/olTaH6LW/UrzmEVaFdUXaDOa0/sMIrZNkdcSGjwi4pOAuLbY4EsPwMcERhHYaQrNOQ8DtYvdfc0lb+AX1984hacWTsOJJUsPa4Gh3IfV6XIbU66BHUhu1UsAkBbsjBAB3iVnL1jCOyWanYeezadj5bFwuN0uW/8nuhV+SlD6XzkteRpa+RG5oI+ydhhKRcjXUa2d1xEYN81pSEJEPgYuA/UqpDpXsF+A1YDBQAIxWSi076fcL0m0KrlKTFAyjKux2G92794HufcgpLGXa4r/Yu/hr2mX/Sr8/34RFr5Mb05rwlOE4Og2DWFPFVBt4s6QwHngT+PgY+y8ATvPcegFve+5Pjl2XFJTTVB8ZxomKCQvi8gHdYEA3Nu/P5+0/V1G04gvOyppHyi9Pwi9PcrBBHyL6jIG2F+vxEkZA8lpSUErNE5Hk4xxyKfCx0gsgLBSRWBFpoJTac1Jv6Kk+UqWm95FhnIqWdSO56+LTcV3Yh982pfP4gkXEbvmGy9PmEvHVjZQExWDrOhxH9+uhblurwzWqmZVtCo2AXRWep3q2HZUURORm4GaAJk2aVH42h/7mokxDs2FUC7tNOLN1Xc5sfRHZBefyxZKdrJs/nYEHf+C8RR/AoncpbtCdkJ43QPvLIDjc6pCNauAXcx9VaXphR7A+1mWSgmFUt9jwYG4c0JIX/nUP0SM+4YEmU3jWeS1paWnwze2UvtgW9fPTkLfP6lCNU2RlSSENqNhy1diz7eR4SgqYkoJvMsukBgSbTRjQKpEBrQaRmnU6kxbuYNPimVxR+B3n/PYS7j9eQzpdhe30O03Vkp+ysqTwLTBStN5Azkm3J8ChNgVMScE3uSusiGcSREBoHBfOvy5oy5sP30X+kAmMiXyHSSVnULLic3irN85Ph8Pe1VaHaZwgb3ZJnQycCSSISCrwOBAEoJR6B/ge3R11M7pL6vWn9Iae3kdikoJvcpUe/thT3Wf4vxCHnaEpjbm821XM2TCQO35ZToe0z7lx0w9EbfqBktaXEnz2w1C3jdWhGlXgzd5HV//NfgXcUW1v6Kk+spmk4JvcFZNCiUkKAUhEOKtNPc5qcz5Ld/Ti0V9G0GLLeMZs+JGgDd/i7HAlQec8DjGNrA7VOI6AGdFc1m/a5jKD13ySq0L1kavEujiMGpHSNI6U6weyZnc3HvlxMW23fsj1q7/EufYbOP0uHP3/oWd4NXyOX/Q+qhKHnvvIYZKCb6rYpuAya17UFu0bxvDqDYPoefNYHmzwAT+UdsHx+wsUvNwF19KJ4DaLYvmawEkKNhulEozDbZKCTzqy+sioVbo2iePlW4ZQ9/pJPBL/MhsKY7B/dyd5r/dFbZtndXhGBYGTFIBSWyhBJin4poqlA7cpKdRWvZrX4Zm7bmD/ldN5KuQ+crLSkQkXkz1xpBnj4CMCLikEu01Ds08y1UeGh4hwXocGPPSvR5k7aAbvyjDCNs+g8JWuZM9901QpWSygkoLTHmZKCr7KZaqPjMMF2W1c178NV//7bSZ0mcxSZ3Ni5z7C/pf7UrJzsdXh1VoBlhRCCVHFKDM4yveYNgXjGKJDg7j5snNJ/sdM3qv3GCpvD44PzyFt0p1QnGd1eLVOQCUFlz2UUIpxuk1S8DkuU31kHF/j+Ahuuu1+Nl05h2lBg2mw4RMOvNCNjBUzrA6tVgmopOC2hxEmJRQ73VaHYhzJlBSMKurXvjkX/nsiX3X9kKzSIBKmXcOGt66mJDfd6tBqhcBKCo4wwimmuNQ0VPkc06ZgnIAQh50rhlxO6J1/MCNuBM33zaTglRS2z/3YzJ3lZVVKCiJyj4hEeyav+0BElonIud4O7kS5Hbr6qMRlSgo+x33E3EeGUQWNE+O48J43WXLeNNJIJHnuXWx89UIK0ndYHVrAqmpJ4QalVC5wLhAHjACe91pUJysonDApoajUJAWfY6a5ME5Bn9MH0OSBP/ih4V0kZS9Gje3FhhmvmVKDF1Q1KYjnfjAwUSm1psI2nyHB4YRRTEGJ8+8PNmqWKSkYpygqPJQLbn6GTVf8xAZ7K1ov/g9rXzyP7H07rQ4toFQ1KSwVkVnopDBTRKIAn/s6LsFhhFJCYYlpU/A5pk3BqCadOnah/YO/8EvzB2ievwzePp1Vsz62OqyAUdWkMAZ4EOihlCpAr4twausfeIE9OIIQcVJQZEY1+xy3qT4yqk9IkIOzRj5K6lWz2G+vR6f5d7Hk1SvJyz5gdWh+r6pJoQ+wQSmVLSLXAY8COd4L6+TYQ/TC4cWFBy2OxDhKxZJCifn7GNWjZbtuJP9rPgsajaFr1izyX+3F6j/MuIZTUdWk8DZQICKdgfuALYDPldccoREAlBblWxyJcZSKbQoHM6yLwwg4wSEh9LnpZTZf/CUucdBu1rX88dbtFBYUWB2aX6pqUnB6Vkq7FHhTKTUWiPJeWCcn6FBSMN9EfU7FksJBMwjJqH6tu59Nnfv+ZFnipfTd/ym7X+zNuhXzrQ7L71Q1KeSJyEPorqgzRMSGZ71lXxIUFg2AqzDX4kiMo5S1KUQ1hIIarvdVCkoKIG0ZbJ4NC8aC2+f6SRjVICwyhu53TmDdwPeJdefQ/OuLmffxU7jM2KUqq+pynFcB16DHK+wVkSbAC94L6+SERMQA4DLVR+V2L4edC6H3bdbGUVZSiKpfcyWFwmyY/zqsmgo5R3RbbHsxxDapmTiMGtf2jGHkdujHpg+vZ8DWl1j2v1+pP+ojGjYyf/O/U6WSglJqL/ApECMiFwFFSimfa1Owh+mkoIpNSeGQcWfCjw9aN8inIFPfl7UpRDWA1MXw6/9V/3spBZnbYNNP8Okw+F9T+O0lnRDqtod+98I1n8O/tpmEUAtE12lA+/u+Z0XHR2hfvJLgcf2YP3OK1WH5vCqVFETkSnTJYC560NobIvKAUuoLL8Z24oI9C4Gb6XaP5iyCoLCafc8/34Uf/gX1OsK+vyAoAmIa6X1zntUf0vaqFlaPozALdiyAxe/Bll/0tohEaNQdul4Lna+BoNBTfx/D74jNRpeh/2Jvx7MpmXI9py+4mTkbZpNywytER0ZaHZ5Pqup/5CPoMQr7AUQkEZgN+FZSCNFt31Jsqo+OUpxfc0lBKd1uMOtR/bzgACBw3jO6KqvMvtXQsMuJndtVCptmQdZ2fa6MjZC+AVDgCIPT74Lk/tD8THCEVMuP400icjNwM0CTJqb04i31W6XgfGABKyfcw8A9n7PhpSXsGDKOjp17WB2az6lqUrCVJQSPA/jiDKshOvPbSk1SOEpxLkQmev999v4Fn14Jebv189sWQL12Oil5/j6s8hThf3kazvg3NOwGYgMRfQOdWAqzdJtIcR5s+xWyduj2iL2r9DHRjaB+J2h/OST3g0YpflciUEqNA8YBdO/e3Uzk40WO0Ag63/I+m387l3o/30vwVxcya9X9nHX1fTgcdqvD8xlVTQo/ishMYLLn+VXA93/3IhE5H3gNsAPvK6WeP2L/aHS1VJpn05tKqferGNPRPNVH9lLTJfUoJV5OlD8+BPvXwp5VYHPAaedBWKxOCFCeELqNhnZDdNXSgrHwwTnl5xAbhMaW91Sq2DbkCIPgcHCEwpC3oflAiKwLNvPPbJyYlv2vJL9Nb1LHj+bcLc8y/4VfSRr5HkmNGlodmk+oUlJQSj0gIkOBvp5N45RSXx/vNSJiB8YC5wCpwGIR+VYptfaIQ6cope48wbgrZ7NTJKE4nKakABw+NqC621mK8/Q3fnsw/PEaHNist0c1gNEzoE6Lyl9ns0F4PAx8CE6/E9Z+A7l7QLl1u0fBAQgK11NhxDWFeh10+0B88/LEYhinKDKxCa3um82aL5+lx5pXyBjXjz8GvErfsy+xOjTLVbmVTyn1JfDlCZy7J7BZKbUVQEQ+Qw9+OzIpVKtCWzhBTj8tKexernvJOIKr53wVxwNUVzuLUrBsAvz+iq7Xr+i856DzcP2hXxUhUdD1uuqJK0CVlpaSmppKUVGR1aH4tdDQUBo3bkxQUIXhVTYb7Yc9xr6OZ6OmjqH3vJHM3jCafmP+R2iI77dHectxk4KI5AGV1XMKoJRS0cd5eSNgV4XnqUCvSo4bKiIDgI3AP5VSuyo5pspKbOEEufwwKeSk6u6jKaPh4tdO/XylRZC+vvz5yZQUlNLf4IvzYOsc+OVZ/W0+Z5fu0jn4RajbFkJjIHsntLnw1OM2DpOamkpUVBTJycmI+Nxs9X5BKcWBAwdITU2lWbNmR+2v1+Z0Su9byNoPb2PQ/o9Y/X8Libj6I5q1bGtBtNY7blJQSnl7KovvgMlKqWIRuQWYAJx15EEn0kOj1BFJcJEfznlS5Kk/3/bbyZ+jOE/30d+9DOa/ccS+Ko7dOLAFVn8J4XXgz3d07x6x6br80gJocxGc+aDu5mmr0NegfseTj9s4pqKiIpMQTpGIUKdOHdLTjz1oMig8ho53TmLdrA9Inv8IrolnMz/lafpcfEOt+91XQyfxY0oDkio8b0x5gzIASqmK8x28D1Q6oulEemi4giIIOZiPUsq//phlDcHOU6gmmPUoLB1/+LaOw+CvqeXnVwry9kD+PpjzX2hxtt6evw/2rIDtvx89tXWr83Xp4KJXoXH3k4/POCl+dR37qKr+DtueO4aMNn3JnjiS05fdy/wtv9DppreJjDxepUhg8WZSWAycJiLN0MlgOHqqjENEpIFSao/n6SXAulN9U3dwFJGkU1DiIiLEmz9eFW2cBas+g6EflHe3rKg4XzfWFnlmIj+RpJCxGfauhNQlsH4GZHvWrR3wADTtqz/Ag8L1N//MbTBpOGz84fBzbJql78WuewqljIb+98GeleAshnrtdSOv+WAyaomEJm2I+9fvLJnwAL13TWDnS33Ye9n7tOzUx+rQaoTXPjWVUk4RuROYie6S+qFSao2IPAUsUUp9C9wtIpcATiATGH2q7+sOTyBBlpFdWOobSeHzEfqDfuAjlffIea4RNDkdeozRz0tPIClMHg4HNunHrQfr+Xx63wYxjQ8/LjgKln50+LbT79Z9+wuzoOU5utG3YgN3VP2qx2EYAcYeFEz3G19j3e9nkTj7bqK+vJhFa++lx5UPIjbfG6JVnbz6qamU+p4jxjMopf5T4fFDwEPV+Z6uqEYkSi5r8/JoFFvD0zpUJrKe/ga/Y/7RSaEsAeycDx2H6sfOwsrPc/CA7vWzcyEknKbbDsoSQsr1cPGrx46h2FMKOeNBaNpHD/IK8bmZzw0flJ2dzaRJk7j99ttP6HWDBw9m0qRJxMbGntDrRo8ezUUXXcQVV1xxQq/zlrb9LiWrdQ/WfTianuv/x6qX5tFszHii4gP3S5MPfJWuXnbP3DqFGamQVNfiaCj/8N25ELqNOHxfxS6dyybqe+XW1UGNu+vqoZBIve2LMTp5AGyaCWHxOuGM/AYS2xw/hk7D9YCw/vf6xdQPRuWe/G4Na3dX72SP7RpG8/jF7Y+5Pzs7m7feeuuopOB0OnE4jv3x8f33fzu21W/EJTYk5v4f+eOz/9J94yvkvdGb9AveonnPwVaH5hUBVw4KitdVJyVZqRZH4pHrme6h7Ft9RZlbyh/vWVH++P2z4csb4c0UeKk1vNxWJ4QLXoA7l0Kv2+Du5XD/Rt0l9O/q+y9/F674wCQE44Q9+OCDbNmyhS5dutCjRw/69+/PJZdcQrt2eqT6kCFDSElJoX379owbN+7Q65KTk8nIyGD79u20bduWm266ifbt23PuuedSWHiM0vARfv75Z7p27UrHjh254YYbKC4uPhRTu3bt6NSpE/fffz8AU6dOpUOHDnTu3JkBAwZU828BbHYbfa99lC2XfsNBwkmecQ2rJtyHcgbgeuNKKb+6paSkqOPZt3WlUo9Hqz++Gnvc42pE8UGlHo/WtxdaKVWYo1Rhdvn+31/T+769u/y4eS+VP348WqnJ1yj15zilUpda93PUIuj2Lp+5tteuXeuVn7Oqtm3bptq3b6+UUmrOnDkqPDxcbd269dD+AwcOKKWUKigoUO3bt1cZGRlKKaWaNm2q0tPT1bZt25TdblfLly9XSik1bNgwNXHixGO+36hRo9TUqVNVYWGhaty4sdqwYYNSSqkRI0aoV155RWVkZKhWrVopt9utlFIqKytLKaVUhw4dVGpq6mHbjlRdv8vMzEz16wtXKfV4tNry314qZ/emajmvt1X12g64kkJUYlMAbGXf0Gta3l5dLeQsga9v0dvim0P+XhjbE15srbdl7dDjAGKbQJ+7yl/f/164axmc/Tj0uBGGfwo9b4JG3Wr8RzGMI/Xs2fOwAWCvv/46nTt3pnfv3uzatYtNm44uETdr1owuXfRsuCkpKWzfvv1v32fDhg00a9aMVq1aATBq1CjmzZtHTEwMoaGhjBkzhq+++orw8HAA+vbty+jRo3nvvfdwuVzV8JMeW1xcHP3unczs9s+TULQD27v92fnrBK++Z00KuKQQGhHNARVNSN62mnnD0iL46XHI9wyMeak1vNYZfn4S1n2rJ3jr4GlEztujG5KfiIF3+uvuqMMnQVzy4ees00InhwtfqpmfwTCqKCIi4tDjuXPnMnv2bBYsWMDKlSvp2rVrpdNxhFSYMsJut+N0Ok/6/R0OB4sWLeKKK65g+vTpnH/++QC88847PPPMM+zatYuUlBQOHPDukq82mzBo2G3sGDaTbZJEkzl3s2ncCFSR/y/wFXBJQUTY4WhGbF4ldfjesHIS/PEq/P7yEdsnQ7tL4cEd5QPEyjQ7A9oMhmun6pHA1bHQjGF4QVRUFHl5lU+RkpOTQ1xcHOHhzjVoXgAAE31JREFU4axfv56FCxdWetzJaN26Ndu3b2fzZj3R4sSJEznjjDPIz88nJyeHwYMH88orr7By5UoAtmzZQq9evXjqqadITExk165Tmi2nyjp26ETSfXP5LvZamqd9R8aLPcnf+HuNvLe3BOSnUUZEC9rlzgC3y7tTK7vdsO47/Thvj+42WqbgQHkJoW4b3VvI7YJ//qXnCjrS7X+CPejo7YZhoTp16tC3b186dOhAWFgY9erVO7Tv/PPP55133qFt27a0bt2a3r17V9v7hoaG8tFHHzFs2DCcTic9evTg1ltvJTMzk0svvZSioiKUUrz8sv4y9sADD7Bp0yaUUpx99tl07ty52mL5O7GR4Vx0z1imTx9E5yX/Jn7SxezpdCsNLnmy+ia3rEGirFq79yR1795dLVmy5LjHfPPh/7h0539Rdy5BEk7zTiCZ2+CTyyFza/m23rfDwrfKnz+UVj7ds9sNymU++H2ciCxVSlkyl0dl1/a6deto27Z2TsxW3Wrid7lqSyq7Jt3Nha6f2R/ZhjojJmCv9zddxmtIVa/tgKs+AnA20I1aBVsWeO9N5r2oG5QvG8f/t3fe8VFV2x7/rpk0UujNGJCqCAklKogKGgtFUMQLwlOsFEWxXc0Drt4PXtT3vPIeF1SKBSyAlQuIPjVYEZ4IYl5oSgmI3lBDEVIggZn9/jgnk0nIhGAymcL6fj7zmTPn7Nn7N3tWsmaXsxY32sHnvB0ClI3/73CoQ1CUMKdz2yR6p7/Ha4lP48zbhWtWL45+85L1ozBECEunkNAihUMmnuPZy2u24qx3YNG98MZAyJoPF98DXYZB6h0wZK5Vpp4dxfWyB33XoyhnOQ888ABdu3Yt83j99ddP/8YQICEmkpGjH+R/r/uIVaYTdb95ggMv31B6z1KQE5ZrCslJDVjtvpDev31bvXWFnB+tbaNpE634QR89DK6i0utdveL7dRgInYdZU0jNOlkpKRVFqZAZM2YEWoJfERFuvKIb28//iJfe+A/u2TuHY9O74xw0najOfwq0vEoJy5FCYv06LI9OI65oP8y6DPL2Vf3Nh3+FfT/B/p9h3mDY8D68PgBeuxrcJ2DcWmjVC+KaWgnnS4iIhptfgcSu1jSRRhVVlLOetk0TGP3nZ5ib/BZbTjQhatE9HH37ntKoyEFIWDoFgLxW17FZ2lrZx1Z5JZzZmlF2lxBYsYYW3QtrXrXuMZjVE2ZeagWS651ujTR+/81KON+4PYxYBA9n6T9+RVFOS3SEk3FD+3F4+Ee8LEOJ3bKYguk9MDuDc+tq2DqFy9o3o9+xp8lrM8DKQvZKmnXT2Nu3wPzBUHgIPpsIuVtg8X1WzoNPHqdM9tGOg6yQ1+N+gGufgn7PWecjoiAqroJWFUVRKiatYxI3PfoSf2v6D/YXuDFvDKTo0yesvCVBRNg6hWsvtPZTL2xyP7Tva6WoLGHPOng1zdotNKO7Fayuw8DSReKbZsOE3+CWt6zRQGQduOJRSGhWQUuKoihVo1ndGJ4aeyfLev+Td11XE736JQpnXGlNWQcJYesUmtWNoXurhszdUIxr+DswbAE8tgXSd0BCorWdNOUWuGAAXP4I3DLPmhK6/3vo+m8V32CmKGcZJaGz/wjTpk2jsLDyfOkl0VTPJpwO4d5rU+gweg7jo/9C4aFdnJzdm5MrXwyKrathvUXm7stbMXZBJp9s3McNXQaWXrjtA2utoeNNp4aYaKo3CilByqcTYO+Gmq2zeQr0f87nZV/5FKrCtGnTGDFihCdonVKW1JYNaP/on5m6pAc9N02mzxdPcmzjh9QZMhsatwuYrrAdKQD06dScDs0TmJKxhfwiryBczZMhZYjGHFKU0+CdTyE9PZ0pU6ZwySWX0LlzZyZNmgRAQUEBAwYMoEuXLiQnJ/Pee+/xwgsvsHv3btLS0khLS6tSW1OnTiU5OZnk5GSmTZvms+4SXeVzKoQiCTGRTBp+FWbYAv4qD1K05ydOzrwM98oXrO30gaAq8bWD6XG6fArlWbX9gGk94WMzdv5aTwx2RfEFmk+hDN75FDIyMszo0aON2+02LpfLDBgwwCxfvtwsXLjQjBo1yvOe33+3coaU5FSojJIya9euNcnJySY/P9/k5eWZjh07mszMzArr9pVT4XQEui9Px76jx8wjr35qMp5MM2ZSXVM06ypj9m+usfqratthPVIAuLRNI8b368AnG/by2opaCqcdZHy7NZdNu4N3X7QSGixbtoxly5bRrVs3UlNT2bx5M9u2bSMlJYXPP/+c8ePHs2LFCurVO/P1uJUrVzJ48GDi4uKIj4/n5ptvZsWKFRXW7SunQqjTNCGGqSP7kjtgLo+5H6Jg7zZcs66AFVPB9cfDjZ8pYe8UAMb0bkO/Ts159pOf+feF6yg+GfjFnNrkjrlrGPBCcO6JVkIHYwwTJ04kKyuLrKwssrOzGTlyJOeffz6ZmZmkpKTw5JNPMnny5Bprs6K6feVUCAdEhNsubcW4hybwSKPZfHaiK3z5N06+ek2t7VA6K5yCiDB1WBfG9G7D+2tz6D/9W3YeKAi0rFrBhFgUXCW48M6n0LdvX+bOnUt+fj4Au3btYv/+/ezevZvY2FhGjBhBeno6mZmZp7z3dPTq1YslS5ZQWFhIQUEBixcvplevXhXW7SunQjjRunEcc+6/nu1XzeTBEw9zdO8O3C/3huVTwHXCr22fNSutsVER/OX6C+nRuiHpC9cz8MWVDLkoiT4dm3FZu8aBluc3yiywB5jik24e+2Ad913Zhk6JuuU3FPDOp9C/f39uvfVWevbsCUB8fDzz588nOzub9PR0HA4HkZGRzJo1C4AxY8bQr18/EhMT+frrryttJzU1lbvuuovu3bsDMGrUKLp160ZGRsYpdefl5VWYUyHciHA6eOia9my68DHGvnsJtx2ewY1fP4Nr0xKcg170W4resMyncDp25OYz/ctt/M/6PZx0G/6UmsTw7i24+LwGSJiFrth5oICr/usbALKf7U+EM3CDwx92HmLo7FV0TqrH0nFXBExHZWg+hfAllPuy+KSbF7/axrbl7/J05Os0liNIj/usiAveIfor4azOp3A62jSJZ/rwbqyb1Ie7L2/Fpxv3MHT2Kq6c8g3Pf7aZj9fvZtu+qg17a5JPN+zh6PGaHRoeLCi9hT43P7C302/aZS12O8LM8SqKv4mKcPBYnwsYe9/DjEqYyfwTV8P3M3HP6AFbl9VoW36dPhKRfsB0wAm8Zox5rtz1aOAt4CLgIDDMGLPTn5q8iYuOYNINnXi8zwVkbNrLosxdzFq+nZLBU5cW9WndKJYO59SlW4v6tG0aT6O4qDMeTXy1eR/1Y6NIbdnAZ5mNu44wdkEm16c0Z+ZtF1XnY5UhN6/Yc7z3yHHOqVenxuo+U9blWE4hmKa0lNqhR48eFBWV/VEyb948UlJSAqQoNOnSoj7vPdSXaV+0YeiKy3k+bw6t3x5qpf7t9xzEN612G35zCiLiBGYA1wE5wA8istQY472EPhI4bIxpJyLDgb8Dw/ylyRdx0RHcnJrEzalJHCt28cuBAr7bfoBPNuzhh52HWZJVmhwjNspJy4axJDWIJTrSQYdmCTSIi+L4CReJ9euQcm49RKztZVERDrbn5nPPG9aUwMrxaSQ1KLt97lixi6378pj3/a8AfL05F5fb4HTUzK9p75HCzoMFdKvEMfkTt9uwarsVnXbngQJOuNxEBnAqK5QwxoT8tObq1asD2n6oTZNXRkykkwn9O/Bjx2bc934KfX9/l4c2fYgz+0ukzzOQenu16vfbmoKI9ASeMsb0tV9PBDDG/KdXmQy7zCoRiQD2Ak1MJaJqYk3hTDmYX8T6nCPsPFjAb4cK+dehY+QcLqSw2MVvh3zHdomOcFDktf01LsrJBc0TiIl0Eh3hIDrCyZqdhzhUUFzmfd1bNaRV41ginA4cYk23lD7A4RDEPu8U8UTwFvCE8xb78J01v7HvaBGJ9WIQEfonN6dOlLNMeSl9G4JVX5lzJXWWK+NNRf+yvMscyC/mlW93cFPXRJZk7ebaC5uRcm49nA6rfoecWqevesvXXVq24tIVlb21R0tio079TRRsawq//PILCQkJNGrUKOQdQ6AwxnDw4EHy8vJo3bp1oOXUKMdPuJiSsYVvvlvJ1JjXSWzVgSZ3VJzBrqq27c/po3OBf3m9zgF6+CpjjDkpIkeARkCZCFkiMgYYA9CyZUt/6fVJo/ho0jpUPCzLO36CY8UuoiOcbNufx89784h0CHuPHqew2EXdmAiu69gcp0N49dsd7Pr9GEUnXeQXnaTohJtOiXW55eIWuI2hZ5tGLMzM4cP/283yrbm43JZBu43B5TYYA25jcHuerfNgBfyuyJWKQK/2jbn/qnZMWrqR+at/9Tiq2v7x1Dg+imcHp9CsXgxvffcrX/x8BsmPaphBXc+t0CkEG0lJSeTk5JCbmxtoKSFNTEwMSUlJgZZR48REOvnrwI707dSch95vS7uiCOZUs05/jhSGAP2MMaPs17cDPYwx47zKbLTL5Nivt9tlfIZNDMRIIdQo+U5LvlrHaaaivMsb+7XxXAODKeNAyhxT1n7KXitLdITDM2VkvJxbicM7RdcpNZzahq+2SstWfCUuKqLCfgm2kYKiVJXC4pMUFLlokhBd4fVgGCnsAlp4vU6yz1VUJseePqqHteCsVIPy0z1nXt7/0xQiglPAiRD5B1NoK4pSSmxURI2Mfv250vcD0F5EWotIFDAcWFquzFLgTvt4CPBVZesJiqIoin/x20jBXiMYB2RgbUmda4zZJCKTsaL1LQXmAPNEJBs4hOU4FEVRlAARcnc0i0gu8KuPy40pt0gdQFTLqQSLDvCt5TxjTJPaEuG9iQK4ANjio2iw9F2w6ADV4otq2XbIOYXKEJG1gVokLI9qCV4dEFxaqkKw6A0WHaBafFFdLXr3kKIoiuJBnYKiKIriIdycwiuBFuCFajmVYNEBwaWlKgSL3mDRAarFF9XSElZrCoqiKEr1CLeRgqIoilIN1CkoiqIoHsLCKYhIPxHZIiLZIjIhAO3vFJENIpIlImvtcw1F5HMR2WY/+yVmtYjMFZH9dhypknMVti0WL9j9tF5EajSfnw8tT4nILrtvskTkeq9rE20tW0Skbw3qaCEiX4vITyKySUQets8HpF+qg9q22nY5Hf63bWNMSD+w7pbeDrQBooB1QMda1rATaFzu3PPABPt4AvB3P7XdG0gFNp6ubeB64FOs4EaXAqtrQctTwOMVlO1of1fRQGv7O3TWkI5zgFT7OAHYarcXkH6pxudQ21bbrnXbDoeRQncg2xizwxhTDLwLDAqwJrA0vGkfvwnc5I9GjDHfYoUIqUrbg4C3jMX3QH0ROcfPWnwxCHjXGFNkjPkFyMb6LmtCxx5jTKZ9nAf8jBWmPSD9Ug3UttW2y+vwu22Hg1OoKG/DubWswQDLRORHscIWADQzxuyxj/cCzWpRj6+2A9VX4+yh61yvqYZa0SIirYBuwGqCr19ORzDoUtuunLCz7XBwCsHAFcaYVKA/8ICI9Pa+aKxxXED2/gaybZtZQFugK7AH+O/aalhE4oF/Ao8YY456XwuCfgkV1LZ9E5a2HQ5OoSp5G/yKMWaX/bwfWIw1VNxXMkyzn/fXoiRfbdd6Xxlj9hljXMYYN/AqpcNov2oRkUisP5oFxphF9umg6ZcqEnBdatu+CVfbDgenUJW8DX5DROJEJKHkGOgDbKRsrog7gQ9rS1MlbS8F7rB3JFwKHPEacvqFcvOXg7H6pkTLcBGJFpHWQHtgTQ21KVhh2X82xkz1uhQ0/VJF1LZPJWi+w7C17ZpYEQ/0A2uFfSvWKv8Ttdx2G6ydBuuATSXtY+Wa/hLYBnwBNPRT++9gDV1PYM0XjvTVNtYOhBl2P20ALq4FLfPsttbbBnqOV/knbC1bgP41qOMKrOHzeiDLflwfqH5R21bbDiXb1jAXiqIoiodwmD5SFEVRagh1CoqiKIoHdQqKoiiKB3UKiqIoigd1CoqiKIoHdQoKInKViHwcaB2KUpOoXf8x1CkoiqIoHtQphBAiMkJE1tix218WEaeI5IvIP+zY6l+KSBO7bFcR+d4O1rXYK756OxH5QkTWiUimiLS1q48XkYUisllEFth3TiqK31G7Di7UKYQIInIhMAy43BjTFXABtwFxwFpjTCdgOTDJfstbwHhjTGesOxlLzi8AZhhjugCXYd2lCVa0xUewYrO3AS73+4dSznrUroOPiEALUKrMNcBFwA/2j506WEGv3MB7dpn5wCIRqQfUN8Yst8+/CXxgx7E51xizGMAYcxzArm+NMSbHfp0FtAJW+v9jKWc5atdBhjqF0EGAN40xE8ucFPlruXJ/NG5JkdexC7UNpXZQuw4ydPoodPgSGCIiTcGTk/U8rO9wiF3mVmClMeYIcFhEetnnbweWGytTU46I3GTXES0isbX6KRSlLGrXQYZ6zRDBGPOTiDyJlQXLgRWt8QGgAOhuX9uPNT8LVvjc2fYfxw7gbvv87cDLIjLZrmNoLX4MRSmD2nXwoVFSQxwRyTfGxAdah6LUJGrXgUOnjxRFURQPOlJQFEVRPOhIQVEURfGgTkFRFEXxoE5BURRF8aBOQVEURfGgTkFRFEXx8P9F97Ga8i4IrgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Varying the activation functions for \"Adam\"optimizer"
      ],
      "metadata": {
        "id": "Wj9C325TXqq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam_tanh= keras.Sequential()\n",
        "model_adam_tanh.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='tanh'))\n",
        "model_adam_tanh.add(tf.keras.layers.Dense(units=12,activation='tanh'))\n",
        "model_adam_tanh.add(tf.keras.layers.Dense(units=7,activation='tanh'))\n",
        "model_adam_tanh.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_adam_tanh.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_adam_tanh.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OIh2dt5XqVV",
        "outputId": "24acfa0e-9940-477e-8471-45993d9c134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam_tanh=model_adam_tanh.fit(norm_train_data,Y_train,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkVRwe9fYroR",
        "outputId": "aed3831d-33a5-4723-c3b9-50ffd46ee9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.3781 - accuracy: 0.3063 - val_loss: 1.2885 - val_accuracy: 0.3275\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1034 - accuracy: 0.4913 - val_loss: 0.9618 - val_accuracy: 0.5775\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7949 - accuracy: 0.6581 - val_loss: 0.7489 - val_accuracy: 0.6600\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7588 - val_loss: 0.6192 - val_accuracy: 0.7825\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8469 - val_loss: 0.5102 - val_accuracy: 0.8475\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8819 - val_loss: 0.4312 - val_accuracy: 0.8800\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.9106 - val_loss: 0.3639 - val_accuracy: 0.8900\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.9250 - val_loss: 0.3146 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9356 - val_loss: 0.2775 - val_accuracy: 0.9250\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9463 - val_loss: 0.2611 - val_accuracy: 0.8975\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9469 - val_loss: 0.2278 - val_accuracy: 0.9300\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9569 - val_loss: 0.2025 - val_accuracy: 0.9275\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9650 - val_loss: 0.2059 - val_accuracy: 0.9125\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9688 - val_loss: 0.1863 - val_accuracy: 0.9300\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9744 - val_loss: 0.1832 - val_accuracy: 0.9275\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9756 - val_loss: 0.1606 - val_accuracy: 0.9350\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9744 - val_loss: 0.1855 - val_accuracy: 0.9125\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9806 - val_loss: 0.1656 - val_accuracy: 0.9325\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9825 - val_loss: 0.1710 - val_accuracy: 0.9275\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9819 - val_loss: 0.1676 - val_accuracy: 0.9175\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9881 - val_loss: 0.1618 - val_accuracy: 0.9250\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9900 - val_loss: 0.1825 - val_accuracy: 0.9300\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9869 - val_loss: 0.1569 - val_accuracy: 0.9350\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9906 - val_loss: 0.1697 - val_accuracy: 0.9350\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9919 - val_loss: 0.1833 - val_accuracy: 0.9275\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9925 - val_loss: 0.1701 - val_accuracy: 0.9300\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9944 - val_loss: 0.1647 - val_accuracy: 0.9325\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9956 - val_loss: 0.1790 - val_accuracy: 0.9300\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9969 - val_loss: 0.1557 - val_accuracy: 0.9350\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9944 - val_loss: 0.1823 - val_accuracy: 0.9300\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.1808 - val_accuracy: 0.9325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam_elu= keras.Sequential()\n",
        "model_adam_elu.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='elu'))\n",
        "model_adam_elu.add(tf.keras.layers.Dense(units=12,activation='elu'))\n",
        "model_adam_elu.add(tf.keras.layers.Dense(units=7,activation='elu'))\n",
        "model_adam_elu.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_adam_elu.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_adam_elu.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWQ4UmgNZg-c",
        "outputId": "b72dd33f-6428-4752-c093-6e69a4ebc09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam_elu=model_adam_elu.fit(norm_train_data,Y_train,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1l1bj8KaKfs",
        "outputId": "50571a0e-7b1a-49fa-fb16-f8c532d06c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9425\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9350\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9400\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9425\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9375\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9450\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.2227 - val_accuracy: 0.9350\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9781 - val_loss: 0.3125 - val_accuracy: 0.9375\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.2219 - val_accuracy: 0.9350\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.2774 - val_accuracy: 0.9325\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9350\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9350\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9375\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9400\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.7691e-04 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9400\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.5634e-04 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9375\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.4254e-04 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9375\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9400\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.7796e-04 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9375\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.2736e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9400\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8201e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam_softplus= keras.Sequential()\n",
        "model_adam_softplus.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='softplus'))\n",
        "model_adam_softplus.add(tf.keras.layers.Dense(units=12,activation='softplus'))\n",
        "model_adam_softplus.add(tf.keras.layers.Dense(units=7,activation='softplus'))\n",
        "model_adam_softplus.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_adam_softplus.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_adam_softplus.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXsm06-YFbvw",
        "outputId": "46d82428-8993-4739-dc5e-47928f8637bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam_softplus=model_adam_softplus.fit(norm_train_data,Y_train,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCRyQRHnGT_J",
        "outputId": "8da78f04-8a26-449a-a914-84e21dd66801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.1806 - val_accuracy: 0.9600\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1787 - val_accuracy: 0.9575\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.1849 - val_accuracy: 0.9575\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.1847 - val_accuracy: 0.9500\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.2445 - val_accuracy: 0.9425\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.2156 - val_accuracy: 0.9500\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.2295 - val_accuracy: 0.9525\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.2116 - val_accuracy: 0.9525\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.2149 - val_accuracy: 0.9550\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.1902 - val_accuracy: 0.9550\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.2144 - val_accuracy: 0.9475\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.2311 - val_accuracy: 0.9525\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.2244 - val_accuracy: 0.9525\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.2090 - val_accuracy: 0.9475\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9869 - val_loss: 0.2369 - val_accuracy: 0.9500\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.2247 - val_accuracy: 0.9525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam_sigmoid= keras.Sequential()\n",
        "model_adam_sigmoid.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='sigmoid'))\n",
        "model_adam_sigmoid.add(tf.keras.layers.Dense(units=12,activation='sigmoid'))\n",
        "model_adam_sigmoid.add(tf.keras.layers.Dense(units=7,activation='sigmoid'))\n",
        "model_adam_sigmoid.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_adam_sigmoid.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_adam_sigmoid.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4k4R3nAIbbR",
        "outputId": "924d6ecc-7079-4c1f-d1bc-be8203226548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam_sigmoid=model_adam_sigmoid.fit(norm_train_data,Y_train,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dp229yqIphY",
        "outputId": "8ca1a835-6058-4df8-bc31-99fb013e79c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 6ms/step - loss: 1.4654 - accuracy: 0.2406 - val_loss: 1.3983 - val_accuracy: 0.2275\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3915 - accuracy: 0.2556 - val_loss: 1.3860 - val_accuracy: 0.2275\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3800 - accuracy: 0.2556 - val_loss: 1.3805 - val_accuracy: 0.2275\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3707 - accuracy: 0.1806 - val_loss: 1.3678 - val_accuracy: 0.2200\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3457 - accuracy: 0.3137 - val_loss: 1.3313 - val_accuracy: 0.2600\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2774 - accuracy: 0.4087 - val_loss: 1.2329 - val_accuracy: 0.3850\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1367 - accuracy: 0.5094 - val_loss: 1.0690 - val_accuracy: 0.4800\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9753 - accuracy: 0.5856 - val_loss: 0.9332 - val_accuracy: 0.5525\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8642 - accuracy: 0.6175 - val_loss: 0.8444 - val_accuracy: 0.6175\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7912 - accuracy: 0.7131 - val_loss: 0.7761 - val_accuracy: 0.6700\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7338 - accuracy: 0.7400 - val_loss: 0.7190 - val_accuracy: 0.7375\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.7950 - val_loss: 0.6715 - val_accuracy: 0.8250\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.8450 - val_loss: 0.6216 - val_accuracy: 0.8275\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.8562 - val_loss: 0.5848 - val_accuracy: 0.8225\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.8694 - val_loss: 0.5412 - val_accuracy: 0.8825\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8850 - val_loss: 0.5000 - val_accuracy: 0.9100\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.9056 - val_loss: 0.4655 - val_accuracy: 0.9050\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.9162 - val_loss: 0.4351 - val_accuracy: 0.9150\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.9262 - val_loss: 0.4010 - val_accuracy: 0.9125\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.9269 - val_loss: 0.3728 - val_accuracy: 0.9525\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.9475 - val_loss: 0.3461 - val_accuracy: 0.9475\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.9494 - val_loss: 0.3164 - val_accuracy: 0.9625\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.9556 - val_loss: 0.2948 - val_accuracy: 0.9450\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9663 - val_loss: 0.2743 - val_accuracy: 0.9500\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9656 - val_loss: 0.2519 - val_accuracy: 0.9650\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9669 - val_loss: 0.2335 - val_accuracy: 0.9675\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9694 - val_loss: 0.2259 - val_accuracy: 0.9625\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9712 - val_loss: 0.2111 - val_accuracy: 0.9575\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9762 - val_loss: 0.1989 - val_accuracy: 0.9675\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9737 - val_loss: 0.1821 - val_accuracy: 0.9650\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9769 - val_loss: 0.1718 - val_accuracy: 0.9675\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9750 - val_loss: 0.1570 - val_accuracy: 0.9750\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9762 - val_loss: 0.1517 - val_accuracy: 0.9650\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9812 - val_loss: 0.1481 - val_accuracy: 0.9625\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9806 - val_loss: 0.1323 - val_accuracy: 0.9725\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9794 - val_loss: 0.1272 - val_accuracy: 0.9700\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9837 - val_loss: 0.1243 - val_accuracy: 0.9675\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9844 - val_loss: 0.1352 - val_accuracy: 0.9575\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9825 - val_loss: 0.1202 - val_accuracy: 0.9675\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9831 - val_loss: 0.1138 - val_accuracy: 0.9700\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9862 - val_loss: 0.1112 - val_accuracy: 0.9675\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9844 - val_loss: 0.1114 - val_accuracy: 0.9675\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9875 - val_loss: 0.1148 - val_accuracy: 0.9575\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9831 - val_loss: 0.1045 - val_accuracy: 0.9625\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9869 - val_loss: 0.1069 - val_accuracy: 0.9650\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9862 - val_loss: 0.0950 - val_accuracy: 0.9700\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9875 - val_loss: 0.0902 - val_accuracy: 0.9675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam_softsign= keras.Sequential()\n",
        "model_adam_softsign.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='softsign'))\n",
        "model_adam_softsign.add(tf.keras.layers.Dense(units=12,activation='softsign'))\n",
        "model_adam_softsign.add(tf.keras.layers.Dense(units=7,activation='softsign'))\n",
        "model_adam_softsign.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_adam_softsign.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_adam_softsign.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGgGTonwJC2k",
        "outputId": "922a0027-21de-4dd5-f896-9cefd2a424d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam_softsign=model_adam_softsign.fit(norm_train_data,Y_train,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYGpAgDnJWds",
        "outputId": "6706969d-f756-4bf6-c025-c4294512364a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.2392 - accuracy: 0.4644 - val_loss: 1.0832 - val_accuracy: 0.5125\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.5581 - val_loss: 0.8399 - val_accuracy: 0.5475\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.6269 - val_loss: 0.7279 - val_accuracy: 0.6625\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.7750 - val_loss: 0.6281 - val_accuracy: 0.7775\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.8625 - val_loss: 0.5220 - val_accuracy: 0.8525\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.9025 - val_loss: 0.4377 - val_accuracy: 0.8825\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.9200 - val_loss: 0.3640 - val_accuracy: 0.9075\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9325 - val_loss: 0.3218 - val_accuracy: 0.9150\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.9488 - val_loss: 0.2861 - val_accuracy: 0.9100\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9600 - val_loss: 0.2604 - val_accuracy: 0.9175\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9606 - val_loss: 0.2440 - val_accuracy: 0.9075\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9669 - val_loss: 0.2127 - val_accuracy: 0.9325\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9725 - val_loss: 0.1985 - val_accuracy: 0.9325\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9731 - val_loss: 0.1911 - val_accuracy: 0.9325\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9769 - val_loss: 0.1799 - val_accuracy: 0.9325\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9806 - val_loss: 0.1579 - val_accuracy: 0.9500\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9837 - val_loss: 0.1600 - val_accuracy: 0.9425\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9831 - val_loss: 0.1560 - val_accuracy: 0.9375\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9844 - val_loss: 0.1567 - val_accuracy: 0.9450\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9919 - val_loss: 0.1520 - val_accuracy: 0.9325\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9894 - val_loss: 0.1602 - val_accuracy: 0.9375\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9912 - val_loss: 0.1555 - val_accuracy: 0.9350\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9912 - val_loss: 0.1576 - val_accuracy: 0.9400\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9931 - val_loss: 0.1498 - val_accuracy: 0.9425\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9962 - val_loss: 0.1510 - val_accuracy: 0.9325\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9925 - val_loss: 0.1550 - val_accuracy: 0.9375\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9956 - val_loss: 0.1584 - val_accuracy: 0.9350\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9956 - val_loss: 0.1708 - val_accuracy: 0.9325\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9950 - val_loss: 0.1621 - val_accuracy: 0.9350\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9981 - val_loss: 0.1376 - val_accuracy: 0.9425\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9994 - val_loss: 0.1558 - val_accuracy: 0.9300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the graph for varying activation functions with \"Adam\" optimizer"
      ],
      "metadata": {
        "id": "shP3BEuVGpqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2, 3)\n",
        "axs[0, 0].plot(history_3.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 0].plot(history_3.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 0].set_title('relu')\n",
        "axs[0, 1].plot(history_adam_tanh.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 1].plot(history_adam_tanh.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 1].set_title('tanh')\n",
        "axs[0, 2].plot(history_adam_sigmoid.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 2].plot(history_adam_sigmoid.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 2].set_title('sigmoid')\n",
        "axs[1, 0].plot(history_adam_elu.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 0].plot(history_adam_elu.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 0].set_title('elu')\n",
        "axs[1, 1].plot(history_adam_softplus.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 1].plot(history_adam_softplus.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 1].set_title('softplus')\n",
        "axs[1, 2].plot(history_adam_softsign.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 2].plot(history_adam_softsign.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 2].set_title('softsign')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NhPy68lIG47m",
        "outputId": "8a1ad51c-6068-4e27-f173-c14da37b66c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss for various activation functions with \"Adam\" optimizer"
      ],
      "metadata": {
        "id": "fYcRNTt1OOik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 3)\n",
        "axs[0, 0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[0, 0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[0, 0].set_title('relu')\n",
        "axs[0, 1].plot(history_adam_tanh.history['loss'],label='train_loss')\n",
        "axs[0, 1].plot(history_adam_tanh.history['val_loss'],label='test_loss')\n",
        "axs[0, 1].set_title('tanh')\n",
        "axs[0, 2].plot(history_adam_sigmoid.history['loss'],label='train_loss')\n",
        "axs[0, 2].plot(history_adam_sigmoid.history['val_loss'],label='test_loss')\n",
        "axs[0, 2].set_title('sigmoid')\n",
        "axs[1, 0].plot(history_adam_elu.history['loss'],label='train_loss')\n",
        "axs[1, 0].plot(history_adam_elu.history['val_loss'],label='test_loss')\n",
        "axs[1, 0].set_title('elu')\n",
        "axs[1, 1].plot(history_adam_softplus.history['loss'],label='train_loss')\n",
        "axs[1, 1].plot(history_adam_softplus.history['val_loss'],label='test_loss')\n",
        "axs[1, 1].set_title('softplus')\n",
        "axs[1, 2].plot(history_adam_softsign.history['loss'],label='train_loss')\n",
        "axs[1, 2].plot(history_adam_softsign.history['val_loss'],label='test_loss')\n",
        "axs[1, 2].set_title('softsign')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bhDhveVVN7Rf",
        "outputId": "8976554f-fa18-4bb8-bdcb-6df26c96e819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse categorical cross entropy as loss function"
      ],
      "metadata": {
        "id": "45b9leXwihrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5= keras.Sequential()\n",
        "model_5.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_5.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_5.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR5A2Lc8ipKQ",
        "outputId": "c6da5e01-f13b-4e4d-c915-95aab0feadde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_5=model_5.fit(norm_train_data,train_label,epochs=100,batch_size=10,validation_data=(norm_test_data_arr,test_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPlVrIp6jAjb",
        "outputId": "a6de7e74-fb88-4d80-b321-6aa752680552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.2923 - accuracy: 0.3881 - val_loss: 1.2179 - val_accuracy: 0.4325\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5469 - val_loss: 0.9133 - val_accuracy: 0.5975\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7194 - val_loss: 0.6178 - val_accuracy: 0.7725\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8269 - val_loss: 0.4570 - val_accuracy: 0.8150\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8775 - val_loss: 0.3891 - val_accuracy: 0.8175\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8988 - val_loss: 0.3438 - val_accuracy: 0.8375\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9162 - val_loss: 0.3086 - val_accuracy: 0.8575\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9256 - val_loss: 0.2950 - val_accuracy: 0.8700\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9325 - val_loss: 0.2816 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9419 - val_loss: 0.2821 - val_accuracy: 0.8725\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9469 - val_loss: 0.2939 - val_accuracy: 0.8875\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9500 - val_loss: 0.2698 - val_accuracy: 0.8900\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9538 - val_loss: 0.2805 - val_accuracy: 0.8775\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9625 - val_loss: 0.2742 - val_accuracy: 0.8975\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9644 - val_loss: 0.2821 - val_accuracy: 0.8800\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9656 - val_loss: 0.2674 - val_accuracy: 0.8875\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9694 - val_loss: 0.2441 - val_accuracy: 0.8925\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9706 - val_loss: 0.2599 - val_accuracy: 0.8850\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9756 - val_loss: 0.2821 - val_accuracy: 0.8900\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9744 - val_loss: 0.2746 - val_accuracy: 0.8950\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.2720 - val_accuracy: 0.8950\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9781 - val_loss: 0.2487 - val_accuracy: 0.9075\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 0.2472 - val_accuracy: 0.9075\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9812 - val_loss: 0.2875 - val_accuracy: 0.8900\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.2908 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9850 - val_loss: 0.2819 - val_accuracy: 0.9025\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9856 - val_loss: 0.2523 - val_accuracy: 0.9100\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.2596 - val_accuracy: 0.9050\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9862 - val_loss: 0.2599 - val_accuracy: 0.9050\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.2965 - val_accuracy: 0.8925\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.3008 - val_accuracy: 0.8925\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.2965 - val_accuracy: 0.8975\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9919 - val_loss: 0.2981 - val_accuracy: 0.9000\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9912 - val_loss: 0.2735 - val_accuracy: 0.9125\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9937 - val_loss: 0.3007 - val_accuracy: 0.9025\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.2911 - val_accuracy: 0.9025\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9956 - val_loss: 0.2861 - val_accuracy: 0.9050\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9931 - val_loss: 0.3231 - val_accuracy: 0.8925\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9944 - val_loss: 0.3163 - val_accuracy: 0.8950\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9969 - val_loss: 0.3201 - val_accuracy: 0.8975\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9956 - val_loss: 0.3367 - val_accuracy: 0.8975\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.3023 - val_accuracy: 0.9075\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9975 - val_loss: 0.2988 - val_accuracy: 0.9050\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9975 - val_loss: 0.2992 - val_accuracy: 0.9025\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9981 - val_loss: 0.3085 - val_accuracy: 0.9100\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9975 - val_loss: 0.2948 - val_accuracy: 0.9150\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.3183 - val_accuracy: 0.9075\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9981 - val_loss: 0.3334 - val_accuracy: 0.9100\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9987 - val_loss: 0.3116 - val_accuracy: 0.9175\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 0.3406 - val_accuracy: 0.9075\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.3407 - val_accuracy: 0.9100\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.3362 - val_accuracy: 0.9100\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3523 - val_accuracy: 0.9150\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.3685 - val_accuracy: 0.9025\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.3588 - val_accuracy: 0.9150\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.3612 - val_accuracy: 0.9150\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.3980 - val_accuracy: 0.9000\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9075\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.3832 - val_accuracy: 0.9050\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.3527 - val_accuracy: 0.9175\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9000\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9050\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.3827 - val_accuracy: 0.9125\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9075\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.4785 - val_accuracy: 0.8850\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9812 - val_loss: 0.4614 - val_accuracy: 0.9050\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.4254 - val_accuracy: 0.9100\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9100\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9050\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9025\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9225\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9075\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9100\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9100\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9050\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9125\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9125\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.9075\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9025\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.4648 - val_accuracy: 0.9150\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9100\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9125\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9125\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9125\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9100\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9812 - val_loss: 0.5148 - val_accuracy: 0.9075\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.4909 - val_accuracy: 0.9100\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9200\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9150\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9175\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9125\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9175\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9125\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9150\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9125\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9175\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9175\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9150\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy for Categorical vs Sparse Categorical_cross_entropy"
      ],
      "metadata": {
        "id": "Baja6nTzjzWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].plot(history_3.history['accuracy'],label='train_accuracy')\n",
        "axs[0].plot(history_3.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0].set_title('Categorical_cross_entropy')\n",
        "axs[1].plot(history_5.history['accuracy'],label='train_accuracy')\n",
        "axs[1].plot(history_5.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1].set_title('Sparse_Categorical_cross_entropy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eO5neXxTj6Rn",
        "outputId": "521de98d-216f-4f45-81ed-74d6309a209d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot loss for Categorical vs Sparse Categorical_cross_entropy"
      ],
      "metadata": {
        "id": "V1UTwWjTklec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "axs[0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[0].set_title('Categorical_cross_entropy')\n",
        "axs[1].plot(history_5.history['loss'],label='train_loss')\n",
        "axs[1].plot(history_5.history['val_loss'],label='test_loss')\n",
        "axs[1].set_title('Sparse_Categorical_cross_entropy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bENVg8OVkZum",
        "outputId": "74987f91-f2ac-418e-a925-0ed2a913ee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}