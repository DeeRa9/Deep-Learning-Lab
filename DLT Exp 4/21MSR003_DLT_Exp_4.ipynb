{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Exp-4: Tuning the Neural Network performance with hyper parameters***"
      ],
      "metadata": {
        "id": "Fh4JYNB2ETOT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RUHwZgOHOrP"
      },
      "outputs": [],
      "source": [
        "import numpy \n",
        "import pandas \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset"
      ],
      "metadata": {
        "id": "MlNTRWM8RrdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "dataset=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7NDb4xJmRr5S",
        "outputId": "d59156e1-a40b-4870-e094-a4c3743aee26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c493fc96-f712-4cfa-8a9c-795b128297b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c493fc96-f712-4cfa-8a9c-795b128297b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Mobile_Price_Classification_train.csv to Mobile_Price_Classification_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the dataset as a dataframe"
      ],
      "metadata": {
        "id": "1OfOQpZUR28t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pandas.read_csv('Mobile_Price_Classification_train.csv')"
      ],
      "metadata": {
        "id": "i8wJVnxpRwMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the dataframe"
      ],
      "metadata": {
        "id": "J9lIqrs2R99C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmMURhxIR67s",
        "outputId": "1dac662d-6289-4c9f-ec50-07744fa380f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0               842     0          2.2         0   1       0           7   \n",
            "1              1021     1          0.5         1   0       1          53   \n",
            "2               563     1          0.5         1   2       1          41   \n",
            "3               615     1          2.5         0   0       0          10   \n",
            "4              1821     1          1.2         0  13       1          44   \n",
            "...             ...   ...          ...       ...  ..     ...         ...   \n",
            "1995            794     1          0.5         1   0       1           2   \n",
            "1996           1965     1          2.6         1   0       0          39   \n",
            "1997           1911     0          0.9         1   1       1          36   \n",
            "1998           1512     0          0.9         0   4       1          46   \n",
            "1999            510     1          2.0         1   5       1          45   \n",
            "\n",
            "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0       0.6        188        2  ...         20       756  2549     9     7   \n",
            "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
            "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
            "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
            "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
            "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
            "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
            "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
            "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
            "1998    0.1        145        5  ...        336       670   869    18    10   \n",
            "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
            "\n",
            "      talk_time  three_g  touch_screen  wifi  price_range  \n",
            "0            19        0             0     1            1  \n",
            "1             7        1             1     0            2  \n",
            "2             9        1             1     0            2  \n",
            "3            11        1             0     0            2  \n",
            "4            15        1             1     0            1  \n",
            "...         ...      ...           ...   ...          ...  \n",
            "1995         19        1             1     0            0  \n",
            "1996         16        1             1     1            2  \n",
            "1997          5        1             1     0            3  \n",
            "1998         19        1             1     1            0  \n",
            "1999          2        1             1     1            3  \n",
            "\n",
            "[2000 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understand your data"
      ],
      "metadata": {
        "id": "b8CucSJISLt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgMcZZVGSIG5",
        "outputId": "d59737a4-e58a-4d08-9b48-539446a69312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separate the attributes and the label"
      ],
      "metadata": {
        "id": "r_uGqGmOSPvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.drop(['price_range'],axis=1)\n",
        "label=df['price_range']\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2JFk1AJSTKD",
        "outputId": "19c573ae-0397-4363-f4f6-0c855bd88401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "0               842     0          2.2         0   1       0           7   \n",
            "1              1021     1          0.5         1   0       1          53   \n",
            "2               563     1          0.5         1   2       1          41   \n",
            "3               615     1          2.5         0   0       0          10   \n",
            "4              1821     1          1.2         0  13       1          44   \n",
            "...             ...   ...          ...       ...  ..     ...         ...   \n",
            "1995            794     1          0.5         1   0       1           2   \n",
            "1996           1965     1          2.6         1   0       0          39   \n",
            "1997           1911     0          0.9         1   1       1          36   \n",
            "1998           1512     0          0.9         0   4       1          46   \n",
            "1999            510     1          2.0         1   5       1          45   \n",
            "\n",
            "      m_dep  mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "0       0.6        188        2   2         20       756  2549     9     7   \n",
            "1       0.7        136        3   6        905      1988  2631    17     3   \n",
            "2       0.9        145        5   6       1263      1716  2603    11     2   \n",
            "3       0.8        131        6   9       1216      1786  2769    16     8   \n",
            "4       0.6        141        2  14       1208      1212  1411     8     2   \n",
            "...     ...        ...      ...  ..        ...       ...   ...   ...   ...   \n",
            "1995    0.8        106        6  14       1222      1890   668    13     4   \n",
            "1996    0.2        187        4   3        915      1965  2032    11    10   \n",
            "1997    0.7        108        8   3        868      1632  3057     9     1   \n",
            "1998    0.1        145        5   5        336       670   869    18    10   \n",
            "1999    0.9        168        6  16        483       754  3919    19     4   \n",
            "\n",
            "      talk_time  three_g  touch_screen  wifi  \n",
            "0            19        0             0     1  \n",
            "1             7        1             1     0  \n",
            "2             9        1             1     0  \n",
            "3            11        1             0     0  \n",
            "4            15        1             1     0  \n",
            "...         ...      ...           ...   ...  \n",
            "1995         19        1             1     0  \n",
            "1996         16        1             1     1  \n",
            "1997          5        1             1     0  \n",
            "1998         19        1             1     1  \n",
            "1999          2        1             1     1  \n",
            "\n",
            "[2000 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "R6LYRlCOSYEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "datasets=train_test_split(data,label,test_size=0.2)\n",
        "train_data,test_data,train_label,test_label=datasets\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97aEWenfScX_",
        "outputId": "27225db9-4b03-444e-ea73-3b3a8cb9d128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 20)\n",
            "(400, 20)\n",
            "(1600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing using Keras"
      ],
      "metadata": {
        "id": "pYQxxEqhSljS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IncyPOlESg5U",
        "outputId": "b0ea4551-fd97-4926-98a1-9255e172781a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize training data"
      ],
      "metadata": {
        "id": "wHmkM_43Ss5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer=tf.keras.layers.Normalization()\n",
        "layer.adapt(train_data)\n",
        "normalized_train_data=layer(train_data)\n",
        "print(normalized_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7E1QmXxSqW8",
        "outputId": "c5b167ac-33bb-40ff-eb15-64f4ceddba18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-1.1522574  -0.97897094  0.70332086 ...  0.5465355   0.9851106\n",
            "   0.9900496 ]\n",
            " [-1.6109338  -0.97897094  0.2120787  ...  0.5465355   0.9851106\n",
            "  -1.0100505 ]\n",
            " [-1.218107    1.0214807  -1.0160272  ...  0.5465355   0.9851106\n",
            "   0.9900496 ]\n",
            " ...\n",
            " [ 0.80279404  1.0214807   0.8261316  ...  0.5465355   0.9851106\n",
            "  -1.0100505 ]\n",
            " [-1.211295   -0.97897094  0.8261316  ...  0.5465355   0.9851106\n",
            "   0.9900496 ]\n",
            " [-0.4438067  -0.97897094  0.8261316  ...  0.5465355  -1.0151144\n",
            "  -1.0100505 ]], shape=(1600, 20), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features mean: %.2f\" % (normalized_train_data.numpy().mean()))\n",
        "print(\"Features std: %.2f\" % (normalized_train_data.numpy().std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsnwwsoKS_aA",
        "outputId": "e14e4697-9237-4b82-f6c5-a633c69be30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features mean: -0.00\n",
            "Features std: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tensor to numpy array"
      ],
      "metadata": {
        "id": "GHdTvDyRTFgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_train_data=normalized_train_data.numpy()"
      ],
      "metadata": {
        "id": "agxHHDxsTBLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert NumPy array to Dataframe"
      ],
      "metadata": {
        "id": "w5q2xeVgTLT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJg4feClTTkF",
        "outputId": "96cb2ce8-2b36-4efb-fb3a-2cd5ecfff61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
              "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
              "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
              "       'touch_screen', 'wifi'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_dataframe=pandas.DataFrame(norm_train_data,columns=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
        "       'touch_screen', 'wifi'])"
      ],
      "metadata": {
        "id": "w2BkrWJETgTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROHhueWwTjsr",
        "outputId": "f22ed1f0-a94f-492a-8d76-870ac7a5d916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      battery_power      blue  clock_speed  dual_sim        fc    four_g  \\\n",
            "0         -1.152257 -0.978971     0.703321  0.968011 -0.981654  0.948809   \n",
            "1         -1.610934 -0.978971     0.212079 -1.033046  1.764233  0.948809   \n",
            "2         -1.218107  1.021481    -1.016027 -1.033046  0.620113 -1.053953   \n",
            "3         -1.472423  1.021481     0.948942  0.968011 -0.752830 -1.053953   \n",
            "4         -0.845716 -0.978971     1.685806 -1.033046  0.162465 -1.053953   \n",
            "...             ...       ...          ...       ...       ...       ...   \n",
            "1595      -1.649535 -0.978971    -1.016027  0.968011 -0.752830  0.948809   \n",
            "1596      -0.736724 -0.978971     0.212079  0.968011 -0.752830  0.948809   \n",
            "1597       0.802794  1.021481     0.826132 -1.033046 -0.295183  0.948809   \n",
            "1598      -1.211295 -0.978971     0.826132  0.968011 -0.066359 -1.053953   \n",
            "1599      -0.443807 -0.978971     0.826132 -1.033046  2.450705  0.948809   \n",
            "\n",
            "      int_memory     m_dep  mobile_wt   n_cores        pc  px_height  \\\n",
            "0      -1.546715 -1.412319  -1.465532  1.498128 -1.304286  -0.774380   \n",
            "1      -1.436812  1.031744   0.027161 -1.098375  0.825996  -0.151939   \n",
            "2      -0.942248 -0.015712   0.534113 -0.665625  0.170525   0.827491   \n",
            "3       1.585524  0.333440   0.534113 -0.232874  0.006657  -0.483755   \n",
            "4      -0.887296 -1.412319  -1.465532 -0.232874  0.334393  -0.698863   \n",
            "...          ...       ...        ...       ...       ...        ...   \n",
            "1595    1.090960  0.682592   1.097393 -1.098375  0.006657  -1.410551   \n",
            "1596    0.486493 -0.714015  -1.071236 -1.531126  0.662128  -0.479178   \n",
            "1597    0.926105 -0.364863   0.365129  0.632627 -0.484947   1.701655   \n",
            "1598    1.145912 -1.063167   1.266377  0.632627 -0.648815  -0.891088   \n",
            "1599   -1.162054  0.333440  -0.057331  0.199876  0.989864  -1.309862   \n",
            "\n",
            "      px_width       ram      sc_h      sc_w  talk_time   three_g  \\\n",
            "0     0.018482 -0.854893  1.594475  2.113944  -1.302923  0.546535   \n",
            "1    -1.392406  1.039829 -0.773631  0.513878  -0.938150  0.546535   \n",
            "2     0.039298 -0.349264 -1.484062 -0.629026   1.068099  0.546535   \n",
            "3    -0.980704 -0.018660  0.173612  0.285297  -1.667695  0.546535   \n",
            "4    -0.531996  1.260231  0.173612 -0.629026   0.520941 -1.829707   \n",
            "...        ...       ...       ...       ...        ...       ...   \n",
            "1595 -1.110228  1.603800 -1.010441 -0.629026  -0.755764  0.546535   \n",
            "1596 -0.219750  0.134140  0.647233 -0.629026   1.250486  0.546535   \n",
            "1597  1.489505  1.453778  1.120854  0.056717   1.615258  0.546535   \n",
            "1598 -0.522744  1.407475 -1.247252 -1.086187   0.703327  0.546535   \n",
            "1599 -0.511179  0.641622  1.357665 -1.314768  -1.667695  0.546535   \n",
            "\n",
            "      touch_screen      wifi  \n",
            "0         0.985111  0.990050  \n",
            "1         0.985111 -1.010051  \n",
            "2         0.985111  0.990050  \n",
            "3        -1.015114  0.990050  \n",
            "4        -1.015114  0.990050  \n",
            "...            ...       ...  \n",
            "1595     -1.015114  0.990050  \n",
            "1596      0.985111 -1.010051  \n",
            "1597      0.985111 -1.010051  \n",
            "1598      0.985111  0.990050  \n",
            "1599     -1.015114 -1.010051  \n",
            "\n",
            "[1600 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize test data"
      ],
      "metadata": {
        "id": "MAeTEHtVTm7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer=tf.keras.layers.Normalization()\n",
        "layer.adapt(test_data)\n",
        "norm_test_data=layer(test_data)"
      ],
      "metadata": {
        "id": "rRuNMf4FTrhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tensor to numpy array"
      ],
      "metadata": {
        "id": "J00ifbSIT3SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_test_data_arr=norm_test_data.numpy()"
      ],
      "metadata": {
        "id": "nTdCWuYyT4SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert numpy array to dataframe"
      ],
      "metadata": {
        "id": "dHcb2p4eT7LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_test_dataframe=pandas.DataFrame(norm_test_data_arr,columns=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
        "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
        "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
        "       'touch_screen', 'wifi'])\n",
        "print(norm_test_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8gtDaTvT-hj",
        "outputId": "195afd90-dde1-48e7-d5c5-e1f8b2ef7c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     battery_power      blue  clock_speed  dual_sim        fc    four_g  \\\n",
            "0        -0.847987 -1.035634    -0.245858 -0.965592  0.145208 -1.005013   \n",
            "1        -1.225087  0.965592    -1.219554 -0.965592  0.382281 -1.005013   \n",
            "2         1.258256 -1.035634     1.214686  1.035635  1.093503 -1.005013   \n",
            "3         0.241925  0.965592     0.606126  1.035635  0.145208 -1.005013   \n",
            "4         0.398283  0.965592     0.362702  1.035635 -1.040161 -1.005013   \n",
            "..             ...       ...          ...       ...       ...       ...   \n",
            "395      -0.772107  0.965592     1.336398  1.035635  0.619355 -1.005013   \n",
            "396       1.329537 -1.035634    -0.732706 -0.965592  1.093503  0.995012   \n",
            "397      -0.459390  0.965592    -1.219554 -0.965592  0.619355 -1.005013   \n",
            "398       1.451404  0.965592     1.458110  1.035635  1.330576 -1.005013   \n",
            "399      -1.443529  0.965592    -1.219554  1.035635 -1.040161 -1.005013   \n",
            "\n",
            "     int_memory     m_dep  mobile_wt   n_cores        pc  px_height  px_width  \\\n",
            "0     -1.320426  0.031282   1.378451 -1.575934  1.738636  -0.473287 -0.125268   \n",
            "1      0.019825  1.045818   0.399959  0.251236 -0.126308  -0.381597 -1.040093   \n",
            "2     -1.655489 -1.321434   1.349672 -1.575934  0.721394  -0.089467 -1.192174   \n",
            "3      0.243200 -0.645076   0.227284  0.708028 -0.634928  -0.417846 -1.311499   \n",
            "4     -0.650301 -1.321434  -1.269234 -0.205557 -1.652170   1.089713  0.646836   \n",
            "..          ...       ...        ...       ...       ...        ...       ...   \n",
            "395    0.689950 -0.983255   0.658972 -0.662349  0.382313  -1.108722 -0.948845   \n",
            "396   -1.097051 -0.645076  -0.664871 -1.575934  1.399555  -1.208942  1.173270   \n",
            "397    0.578263 -1.321434  -0.751209 -0.662349 -0.295848   0.110972  0.759142   \n",
            "398   -1.320426  1.383997   0.831647  1.164821  0.551854   0.639791 -0.160363   \n",
            "399    0.578263  0.369460   0.745309  0.708028 -0.974009  -1.194016  0.848051   \n",
            "\n",
            "          ram      sc_h      sc_w  talk_time   three_g  touch_screen      wifi  \n",
            "0   -1.367008 -1.551928 -0.427402   0.845198 -1.633929     -0.970437 -1.030464  \n",
            "1   -0.607494 -0.111623  1.209706   1.406170 -1.633929      1.030464 -1.030464  \n",
            "2   -0.655587 -1.311877 -1.362893   1.780152  0.612022      1.030464  0.970437  \n",
            "3    0.422433  1.568732 -1.129020   0.284226 -1.633929      1.030464 -1.030464  \n",
            "4    1.618419 -0.591725 -0.895147  -0.650728 -1.633929     -0.970437  0.970437  \n",
            "..        ...       ...       ...        ...       ...           ...       ...  \n",
            "395  1.653809  0.128427  0.040343  -0.463737 -1.633929     -0.970437 -1.030464  \n",
            "396  0.309913 -1.311877 -0.427402  -0.837718  0.612022      1.030464  0.970437  \n",
            "397 -1.067558  0.848579  0.741961  -0.837718 -1.633929      1.030464 -1.030464  \n",
            "398 -0.764478 -1.071826 -1.129020  -1.585681 -1.633929     -0.970437  0.970437  \n",
            "399  0.111187 -1.311877 -0.427402   1.406170 -1.633929     -0.970437  0.970437  \n",
            "\n",
            "[400 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi layer neural network using Keras"
      ],
      "metadata": {
        "id": "GpIpEK9qULYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.api._v2.keras as keras\n",
        "from keras import layers\n",
        "callback =keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n",
        "model_1= keras.Sequential()"
      ],
      "metadata": {
        "id": "Tm5u1xIQUFka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "Ehnh9zCiUVyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(units=4,activation='softmax'))"
      ],
      "metadata": {
        "id": "mrI0t4SQUQoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the learning process of the model"
      ],
      "metadata": {
        "id": "gkInCRYuUk2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "IaGxUrOoUZme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IiwJZTDUuDZ",
        "outputId": "423a4514-93ab-49e3-e50a-3b8f0c5287af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 17)                357       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                216       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate on your training data in batches"
      ],
      "metadata": {
        "id": "KSLp9SIEUvca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = tf.one_hot(train_label, 4)\n",
        "Y_test=tf.one_hot(test_label,4)\n",
        "history_1=model_1.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Ov4dCWUzKd",
        "outputId": "f7473581-d06e-4d2b-ce9b-60e2198f4ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 1.3988 - accuracy: 0.2606 - val_loss: 1.3822 - val_accuracy: 0.2675\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.3759 - accuracy: 0.2663 - val_loss: 1.3625 - val_accuracy: 0.2925\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3594 - accuracy: 0.2887 - val_loss: 1.3472 - val_accuracy: 0.3000\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3463 - accuracy: 0.3069 - val_loss: 1.3343 - val_accuracy: 0.3275\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3347 - accuracy: 0.3219 - val_loss: 1.3225 - val_accuracy: 0.3525\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3238 - accuracy: 0.3375 - val_loss: 1.3113 - val_accuracy: 0.3800\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3135 - accuracy: 0.3494 - val_loss: 1.3004 - val_accuracy: 0.3850\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3031 - accuracy: 0.3638 - val_loss: 1.2892 - val_accuracy: 0.3950\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2924 - accuracy: 0.3750 - val_loss: 1.2779 - val_accuracy: 0.4075\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2814 - accuracy: 0.3956 - val_loss: 1.2662 - val_accuracy: 0.4200\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2699 - accuracy: 0.4100 - val_loss: 1.2544 - val_accuracy: 0.4250\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2581 - accuracy: 0.4238 - val_loss: 1.2422 - val_accuracy: 0.4475\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2460 - accuracy: 0.4338 - val_loss: 1.2300 - val_accuracy: 0.4500\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2337 - accuracy: 0.4556 - val_loss: 1.2174 - val_accuracy: 0.4725\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2211 - accuracy: 0.4638 - val_loss: 1.2045 - val_accuracy: 0.4775\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2082 - accuracy: 0.4800 - val_loss: 1.1915 - val_accuracy: 0.4875\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.1952 - accuracy: 0.4863 - val_loss: 1.1785 - val_accuracy: 0.4875\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1820 - accuracy: 0.4950 - val_loss: 1.1654 - val_accuracy: 0.4850\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1686 - accuracy: 0.5069 - val_loss: 1.1520 - val_accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.1551 - accuracy: 0.5175 - val_loss: 1.1386 - val_accuracy: 0.5100\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.1416 - accuracy: 0.5219 - val_loss: 1.1253 - val_accuracy: 0.5250\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1281 - accuracy: 0.5300 - val_loss: 1.1119 - val_accuracy: 0.5325\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.1147 - accuracy: 0.5350 - val_loss: 1.0986 - val_accuracy: 0.5425\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.1012 - accuracy: 0.5362 - val_loss: 1.0855 - val_accuracy: 0.5550\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0878 - accuracy: 0.5444 - val_loss: 1.0724 - val_accuracy: 0.5625\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0743 - accuracy: 0.5462 - val_loss: 1.0593 - val_accuracy: 0.5600\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0608 - accuracy: 0.5544 - val_loss: 1.0461 - val_accuracy: 0.5675\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0471 - accuracy: 0.5644 - val_loss: 1.0327 - val_accuracy: 0.5775\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.5663 - val_loss: 1.0192 - val_accuracy: 0.5875\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0194 - accuracy: 0.5719 - val_loss: 1.0055 - val_accuracy: 0.5925\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0054 - accuracy: 0.5788 - val_loss: 0.9916 - val_accuracy: 0.5900\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9912 - accuracy: 0.5819 - val_loss: 0.9776 - val_accuracy: 0.5900\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9772 - accuracy: 0.5888 - val_loss: 0.9636 - val_accuracy: 0.5950\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9631 - accuracy: 0.5906 - val_loss: 0.9496 - val_accuracy: 0.5950\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9491 - accuracy: 0.5962 - val_loss: 0.9358 - val_accuracy: 0.5925\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9352 - accuracy: 0.5956 - val_loss: 0.9220 - val_accuracy: 0.5975\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9214 - accuracy: 0.6006 - val_loss: 0.9085 - val_accuracy: 0.6025\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.6012 - val_loss: 0.8950 - val_accuracy: 0.6050\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.6081 - val_loss: 0.8817 - val_accuracy: 0.6025\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8811 - accuracy: 0.6175 - val_loss: 0.8687 - val_accuracy: 0.6000\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.6212 - val_loss: 0.8559 - val_accuracy: 0.6025\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8554 - accuracy: 0.6300 - val_loss: 0.8435 - val_accuracy: 0.6100\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8430 - accuracy: 0.6363 - val_loss: 0.8311 - val_accuracy: 0.6200\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8309 - accuracy: 0.6425 - val_loss: 0.8191 - val_accuracy: 0.6375\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.6444 - val_loss: 0.8073 - val_accuracy: 0.6475\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8074 - accuracy: 0.6506 - val_loss: 0.7957 - val_accuracy: 0.6550\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7960 - accuracy: 0.6612 - val_loss: 0.7846 - val_accuracy: 0.6625\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7849 - accuracy: 0.6631 - val_loss: 0.7735 - val_accuracy: 0.6800\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7741 - accuracy: 0.6719 - val_loss: 0.7627 - val_accuracy: 0.6925\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.6775 - val_loss: 0.7522 - val_accuracy: 0.7000\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.6825 - val_loss: 0.7417 - val_accuracy: 0.7025\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.6881 - val_loss: 0.7313 - val_accuracy: 0.7050\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.6988 - val_loss: 0.7211 - val_accuracy: 0.7100\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.7056 - val_loss: 0.7112 - val_accuracy: 0.7100\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.7169 - val_loss: 0.7012 - val_accuracy: 0.7175\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.7300 - val_loss: 0.6912 - val_accuracy: 0.7300\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.7331 - val_loss: 0.6813 - val_accuracy: 0.7325\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.7500 - val_loss: 0.6716 - val_accuracy: 0.7400\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.7513 - val_loss: 0.6616 - val_accuracy: 0.7450\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.7606 - val_loss: 0.6519 - val_accuracy: 0.7525\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.7656 - val_loss: 0.6419 - val_accuracy: 0.7550\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.7738 - val_loss: 0.6323 - val_accuracy: 0.7650\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.7831 - val_loss: 0.6222 - val_accuracy: 0.7700\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.7862 - val_loss: 0.6124 - val_accuracy: 0.7700\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.7937 - val_loss: 0.6029 - val_accuracy: 0.7775\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7975 - val_loss: 0.5932 - val_accuracy: 0.7850\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.8019 - val_loss: 0.5840 - val_accuracy: 0.7850\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.8056 - val_loss: 0.5747 - val_accuracy: 0.7900\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.8094 - val_loss: 0.5655 - val_accuracy: 0.7950\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.8194 - val_loss: 0.5564 - val_accuracy: 0.8000\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5476 - accuracy: 0.8238 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.8300 - val_loss: 0.5393 - val_accuracy: 0.8025\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.8331 - val_loss: 0.5311 - val_accuracy: 0.8100\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.8300 - val_loss: 0.5226 - val_accuracy: 0.8125\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8369 - val_loss: 0.5145 - val_accuracy: 0.8125\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.8400 - val_loss: 0.5067 - val_accuracy: 0.8175\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8419 - val_loss: 0.4989 - val_accuracy: 0.8175\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8450 - val_loss: 0.4915 - val_accuracy: 0.8175\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8431 - val_loss: 0.4848 - val_accuracy: 0.8250\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.8481 - val_loss: 0.4775 - val_accuracy: 0.8250\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.8475 - val_loss: 0.4707 - val_accuracy: 0.8350\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8531 - val_loss: 0.4639 - val_accuracy: 0.8425\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8544 - val_loss: 0.4574 - val_accuracy: 0.8475\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8594 - val_loss: 0.4512 - val_accuracy: 0.8475\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8631 - val_loss: 0.4451 - val_accuracy: 0.8475\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8644 - val_loss: 0.4396 - val_accuracy: 0.8525\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8669 - val_loss: 0.4333 - val_accuracy: 0.8600\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8694 - val_loss: 0.4272 - val_accuracy: 0.8600\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8775 - val_loss: 0.4218 - val_accuracy: 0.8550\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8712 - val_loss: 0.4168 - val_accuracy: 0.8575\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8744 - val_loss: 0.4117 - val_accuracy: 0.8550\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8731 - val_loss: 0.4064 - val_accuracy: 0.8525\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8775 - val_loss: 0.4022 - val_accuracy: 0.8575\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8788 - val_loss: 0.3966 - val_accuracy: 0.8550\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8788 - val_loss: 0.3928 - val_accuracy: 0.8600\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8844 - val_loss: 0.3887 - val_accuracy: 0.8525\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8844 - val_loss: 0.3844 - val_accuracy: 0.8550\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8831 - val_loss: 0.3797 - val_accuracy: 0.8600\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8856 - val_loss: 0.3754 - val_accuracy: 0.8650\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8838 - val_loss: 0.3711 - val_accuracy: 0.8675\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8844 - val_loss: 0.3679 - val_accuracy: 0.8750\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8894 - val_loss: 0.3637 - val_accuracy: 0.8675\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8931 - val_loss: 0.3600 - val_accuracy: 0.8675\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8913 - val_loss: 0.3572 - val_accuracy: 0.8675\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8950 - val_loss: 0.3542 - val_accuracy: 0.8650\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8975 - val_loss: 0.3505 - val_accuracy: 0.8700\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8919 - val_loss: 0.3475 - val_accuracy: 0.8700\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8975 - val_loss: 0.3443 - val_accuracy: 0.8725\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8963 - val_loss: 0.3409 - val_accuracy: 0.8700\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8969 - val_loss: 0.3375 - val_accuracy: 0.8725\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8969 - val_loss: 0.3350 - val_accuracy: 0.8725\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9019 - val_loss: 0.3318 - val_accuracy: 0.8725\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.9000 - val_loss: 0.3291 - val_accuracy: 0.8775\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.9025 - val_loss: 0.3274 - val_accuracy: 0.8775\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.9044 - val_loss: 0.3241 - val_accuracy: 0.8775\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.9044 - val_loss: 0.3217 - val_accuracy: 0.8775\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.9050 - val_loss: 0.3190 - val_accuracy: 0.8800\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9062 - val_loss: 0.3172 - val_accuracy: 0.8775\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.9056 - val_loss: 0.3144 - val_accuracy: 0.8775\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.9050 - val_loss: 0.3111 - val_accuracy: 0.8800\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.9112 - val_loss: 0.3098 - val_accuracy: 0.8775\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.9056 - val_loss: 0.3072 - val_accuracy: 0.8800\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9081 - val_loss: 0.3052 - val_accuracy: 0.8775\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2682 - accuracy: 0.9075 - val_loss: 0.3028 - val_accuracy: 0.8825\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.9137 - val_loss: 0.3003 - val_accuracy: 0.8825\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.9094 - val_loss: 0.2980 - val_accuracy: 0.8850\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.9119 - val_loss: 0.2967 - val_accuracy: 0.8775\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.9119 - val_loss: 0.2938 - val_accuracy: 0.8825\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.9106 - val_loss: 0.2914 - val_accuracy: 0.8825\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.9125 - val_loss: 0.2911 - val_accuracy: 0.8800\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.9131 - val_loss: 0.2882 - val_accuracy: 0.8875\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.9137 - val_loss: 0.2868 - val_accuracy: 0.8850\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.9144 - val_loss: 0.2853 - val_accuracy: 0.8850\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9125 - val_loss: 0.2830 - val_accuracy: 0.8925\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9150 - val_loss: 0.2819 - val_accuracy: 0.8875\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9169 - val_loss: 0.2790 - val_accuracy: 0.8925\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9162 - val_loss: 0.2768 - val_accuracy: 0.8875\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9212 - val_loss: 0.2761 - val_accuracy: 0.8900\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9200 - val_loss: 0.2735 - val_accuracy: 0.8900\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9181 - val_loss: 0.2711 - val_accuracy: 0.8850\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: 0.2697 - val_accuracy: 0.8850\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9212 - val_loss: 0.2681 - val_accuracy: 0.8825\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9194 - val_loss: 0.2665 - val_accuracy: 0.8925\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9231 - val_loss: 0.2652 - val_accuracy: 0.8875\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9212 - val_loss: 0.2647 - val_accuracy: 0.8925\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9237 - val_loss: 0.2642 - val_accuracy: 0.8875\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9269 - val_loss: 0.2616 - val_accuracy: 0.8875\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9244 - val_loss: 0.2607 - val_accuracy: 0.8900\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9256 - val_loss: 0.2592 - val_accuracy: 0.8900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate your test loss and metrics "
      ],
      "metadata": {
        "id": "EafJ0CDRU--j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=tf.one_hot(test_label,4)\n",
        "history_test=model_1.evaluate(norm_test_dataframe,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5z-a3f8VAAw",
        "outputId": "b3315665-7826-4076-cc77-ab517c38059f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict for the given input"
      ],
      "metadata": {
        "id": "WTGJequpVPKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.predict(norm_test_data_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO3kJzWzVJb0",
        "outputId": "0e20c501-d8c6-4f58-c7fe-eb5f6ae6e75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.56238854e-01, 3.43760461e-01, 7.08202435e-07, 2.75631162e-14],\n",
              "       [1.46874144e-33, 6.08564360e-13, 3.24062700e-03, 9.96759355e-01],\n",
              "       [9.41546440e-01, 5.84536120e-02, 3.14116129e-08, 8.34154341e-16],\n",
              "       ...,\n",
              "       [6.83685101e-27, 1.15536476e-10, 3.16452282e-03, 9.96835530e-01],\n",
              "       [6.38628669e-19, 6.96374218e-06, 7.71245897e-01, 2.28747115e-01],\n",
              "       [7.28401065e-01, 2.71420747e-01, 1.78308808e-04, 1.40033345e-08]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop"
      ],
      "metadata": {
        "id": "4JYuFJnzW7EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2= keras.Sequential()\n",
        "model_2.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLFrPaTeXAdl",
        "outputId": "72e79c2e-766d-449d-d0eb-d1fe39feaf8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 17)                357       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                216       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_2=model_2.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test),callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKpi6rBKXCSF",
        "outputId": "a29686e7-38de-484f-96d2-645e12040bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 2s 5ms/step - loss: 1.3854 - accuracy: 0.3075 - val_loss: 1.3641 - val_accuracy: 0.3300\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.3236 - accuracy: 0.3725 - val_loss: 1.3159 - val_accuracy: 0.3850\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2262 - accuracy: 0.4256 - val_loss: 1.1940 - val_accuracy: 0.4050\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0499 - accuracy: 0.4819 - val_loss: 1.0090 - val_accuracy: 0.4350\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.5462 - val_loss: 0.7847 - val_accuracy: 0.5350\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.7175 - val_loss: 0.5990 - val_accuracy: 0.7675\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8406 - val_loss: 0.4636 - val_accuracy: 0.8125\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8712 - val_loss: 0.3714 - val_accuracy: 0.8400\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.9000 - val_loss: 0.3330 - val_accuracy: 0.8600\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9144 - val_loss: 0.3107 - val_accuracy: 0.8575\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9244 - val_loss: 0.2969 - val_accuracy: 0.8725\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9244 - val_loss: 0.2586 - val_accuracy: 0.8950\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9300 - val_loss: 0.2762 - val_accuracy: 0.8775\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9369 - val_loss: 0.2573 - val_accuracy: 0.8925\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9444 - val_loss: 0.2740 - val_accuracy: 0.8800\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9425 - val_loss: 0.2281 - val_accuracy: 0.9075\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9519 - val_loss: 0.2367 - val_accuracy: 0.9100\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.2591 - val_accuracy: 0.8875\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9550 - val_loss: 0.2252 - val_accuracy: 0.9000\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.9619 - val_loss: 0.2388 - val_accuracy: 0.9075\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.2224 - val_accuracy: 0.9100\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9688 - val_loss: 0.2183 - val_accuracy: 0.9100\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9663 - val_loss: 0.2347 - val_accuracy: 0.9050\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9725 - val_loss: 0.2182 - val_accuracy: 0.9100\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9731 - val_loss: 0.2346 - val_accuracy: 0.9075\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9756 - val_loss: 0.2320 - val_accuracy: 0.9100\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9781 - val_loss: 0.2366 - val_accuracy: 0.9100\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9756 - val_loss: 0.2426 - val_accuracy: 0.9050\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9769 - val_loss: 0.2421 - val_accuracy: 0.8975\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9825 - val_loss: 0.2392 - val_accuracy: 0.9175\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.2328 - val_accuracy: 0.9100\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9856 - val_loss: 0.2350 - val_accuracy: 0.9100\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9862 - val_loss: 0.2662 - val_accuracy: 0.9075\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.2322 - val_accuracy: 0.9100\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.2522 - val_accuracy: 0.9150\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 0.2720 - val_accuracy: 0.9050\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.2826 - val_accuracy: 0.8975\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9906 - val_loss: 0.2527 - val_accuracy: 0.9125\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.2447 - val_accuracy: 0.9275\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 0.2737 - val_accuracy: 0.9050\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9906 - val_loss: 0.2380 - val_accuracy: 0.9250\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.2530 - val_accuracy: 0.9275\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9937 - val_loss: 0.2585 - val_accuracy: 0.9275\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.2894 - val_accuracy: 0.9000\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.2908 - val_accuracy: 0.9075\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.2905 - val_accuracy: 0.8950\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.3290 - val_accuracy: 0.8950\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 0.2823 - val_accuracy: 0.9150\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9956 - val_loss: 0.3015 - val_accuracy: 0.9000\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.2688 - val_accuracy: 0.9225\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9950 - val_loss: 0.2836 - val_accuracy: 0.9100\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.2910 - val_accuracy: 0.9225\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.3482 - val_accuracy: 0.8975\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9962 - val_loss: 0.3161 - val_accuracy: 0.9125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam"
      ],
      "metadata": {
        "id": "H-iFDPBjXRcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3= keras.Sequential()\n",
        "model_3.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_3.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzXvce3PXJQb",
        "outputId": "282ffb5b-c1ae-4941-ebd7-77cf1837df0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 17)                357       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 12)                216       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_3=model_3.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlGaf7GXXXha",
        "outputId": "ad1dc4ce-d04c-496a-ec9f-2553a16d0bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9862 - val_loss: 0.2468 - val_accuracy: 0.9125\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9894 - val_loss: 0.2801 - val_accuracy: 0.9125\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9912 - val_loss: 0.2752 - val_accuracy: 0.9050\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9925 - val_loss: 0.2927 - val_accuracy: 0.9025\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9925 - val_loss: 0.2992 - val_accuracy: 0.9000\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9956 - val_loss: 0.2909 - val_accuracy: 0.8975\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9944 - val_loss: 0.2821 - val_accuracy: 0.9025\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.3004 - val_accuracy: 0.9000\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9950 - val_loss: 0.3208 - val_accuracy: 0.9050\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.2876 - val_accuracy: 0.9075\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9962 - val_loss: 0.2990 - val_accuracy: 0.9100\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: 0.2893 - val_accuracy: 0.9025\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.2888 - val_accuracy: 0.9000\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9150\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9981 - val_loss: 0.2912 - val_accuracy: 0.9100\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9981 - val_loss: 0.3219 - val_accuracy: 0.9100\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.8975\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.3147 - val_accuracy: 0.9100\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.3268 - val_accuracy: 0.9050\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9050\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.3361 - val_accuracy: 0.9050\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 0.3570 - val_accuracy: 0.9000\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9981 - val_loss: 0.3600 - val_accuracy: 0.8975\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.3578 - val_accuracy: 0.9100\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.8950\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9994 - val_loss: 0.3587 - val_accuracy: 0.9025\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9025\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9100\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9125\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8950\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9000\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9050\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9025\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.5056 - val_accuracy: 0.8875\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9900 - val_loss: 0.3939 - val_accuracy: 0.9050\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.4018 - val_accuracy: 0.9075\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9025\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9075\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9100\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9100\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9075\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9050\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9100\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9100\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9075\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9125\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9050\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9100\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9150\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9025\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9100\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.9075\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9075\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9075\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.5972 - val_accuracy: 0.8800\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9850 - val_loss: 0.5600 - val_accuracy: 0.9000\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9925 - val_loss: 0.4574 - val_accuracy: 0.9125\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.5279 - val_accuracy: 0.8975\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9000\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8975\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9000\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9000\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.9529e-04 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8975\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.3865e-04 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.8975\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9153e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9000\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.6047e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8975\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.2743e-04 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8975\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8863e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9000\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8883e-04 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.8975\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3207e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9907e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7079e-04 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9050\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.8026e-04 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.8975\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3568e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8410e-04 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.9000\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8006e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9025\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6555e-04 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9025\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5974e-04 - accuracy: 1.0000 - val_loss: 0.5190 - val_accuracy: 0.9000\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3977e-04 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.9025\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.9622e-04 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.9000\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8263e-04 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9000\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3707e-04 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.9000\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3662e-04 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.9025\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8961e-04 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.9000\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.9579e-04 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.9025\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7278e-04 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.9025\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.3840e-04 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.9025\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.1647e-04 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.9050\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1708e-04 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8975\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8423e-04 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.9050\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1284e-04 - accuracy: 1.0000 - val_loss: 0.5732 - val_accuracy: 0.9025\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9856 - val_loss: 0.7096 - val_accuracy: 0.9000\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.5560 - val_accuracy: 0.9150\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9962 - val_loss: 0.5606 - val_accuracy: 0.9100\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.5604 - val_accuracy: 0.9100\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5824 - val_accuracy: 0.9100\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.0350e-04 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.9050\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6719e-04 - accuracy: 1.0000 - val_loss: 0.5688 - val_accuracy: 0.9075\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2412e-04 - accuracy: 1.0000 - val_loss: 0.5630 - val_accuracy: 0.9075\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8527e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9075\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5325e-04 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.9075\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3197e-04 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.9075\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1422e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9075\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9675e-04 - accuracy: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.9075\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7977e-04 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.9075\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6309e-04 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.9100\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 3.4662e-04 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.9100\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3237e-04 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.9075\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1956e-04 - accuracy: 1.0000 - val_loss: 0.5632 - val_accuracy: 0.9075\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0828e-04 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.9075\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9600e-04 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9050\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7747e-04 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.9075\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7260e-04 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9075\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6315e-04 - accuracy: 1.0000 - val_loss: 0.5783 - val_accuracy: 0.9075\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4829e-04 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.9050\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3992e-04 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.9075\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3080e-04 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.9050\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2106e-04 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.9025\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0821e-04 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.9050\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 2.0453e-04 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.9050\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9465e-04 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.9025\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8313e-04 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.9050\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7809e-04 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.9025\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6704e-04 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8975\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5928e-04 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8975\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5142e-04 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.9025\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4679e-04 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.8975\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3713e-04 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9025\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3831e-04 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9000\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2779e-04 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.9050\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2084e-04 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.8975\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1829e-04 - accuracy: 1.0000 - val_loss: 0.6149 - val_accuracy: 0.9000\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1137e-04 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.9000\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0608e-04 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.9000\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.8611e-05 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.8975\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.6946e-05 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.9000\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.4026e-05 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.9025\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.1795e-05 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.9025\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9646e-05 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.9025\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9207e-05 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.9025\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5254e-05 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 0.9000\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7008e-05 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.9025\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3342e-05 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9025\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9929e-05 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.9025\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9558e-05 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.9050\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9887 - val_loss: 0.7361 - val_accuracy: 0.8950\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9825 - val_loss: 0.7155 - val_accuracy: 0.9025\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.6660 - val_accuracy: 0.9025\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9409e-04 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.9050\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2023e-04 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.9025\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7974e-04 - accuracy: 1.0000 - val_loss: 0.6681 - val_accuracy: 0.9050\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4235e-04 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.9050\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1819e-04 - accuracy: 1.0000 - val_loss: 0.6631 - val_accuracy: 0.9050\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0211e-04 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.9050\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8828e-04 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.9050\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7515e-04 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.9050\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6479e-04 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.9050\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5636e-04 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.9050\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5095e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.9050\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4161e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.9050\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3561e-04 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.9050\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2904e-04 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9050\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2402e-04 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.9050\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1950e-04 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 0.9075\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1372e-04 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.9000\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0893e-04 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.9025\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0544e-04 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.9025\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0113e-04 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.9000\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.7388e-05 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.9000\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.4281e-05 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.9025\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9484e-05 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.9025\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.7686e-05 - accuracy: 1.0000 - val_loss: 0.6572 - val_accuracy: 0.9050\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4811e-05 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.9025\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1044e-05 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.9025\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7230e-05 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.9050\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5144e-05 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.9025\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.0743e-05 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.9050\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9705e-05 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.9050\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6971e-05 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.9050\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3961e-05 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.9050\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2091e-05 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.9050\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9586e-05 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.9050\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7017e-05 - accuracy: 1.0000 - val_loss: 0.6676 - val_accuracy: 0.9050\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.4407e-05 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.9050\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2493e-05 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.9050\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0885e-05 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.9075\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8469e-05 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.9100\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7321e-05 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.9075\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5302e-05 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.9075\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3854e-05 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9100\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0585e-05 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.9100\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0000e-05 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.9100\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9215e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.9100\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6355e-05 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.9075\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5436e-05 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.9075\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3846e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9075\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2201e-05 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.9100\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0364e-05 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.9100\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9714e-05 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.9075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adagrad"
      ],
      "metadata": {
        "id": "uTb9p803XcmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4= keras.Sequential()\n",
        "model_4.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_4.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adagrad(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_4.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivuK9iNxXdTS",
        "outputId": "640ca44b-2631-403e-b597-754462c70e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 17)                357       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 12)                216       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_4=model_4.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vfqh4K5XnTW",
        "outputId": "ecb92103-0104-4182-e733-67efdb4533af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3849 - accuracy: 0.2338 - val_loss: 1.3754 - val_accuracy: 0.2325\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3846 - accuracy: 0.2331 - val_loss: 1.3753 - val_accuracy: 0.2325\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3844 - accuracy: 0.2319 - val_loss: 1.3751 - val_accuracy: 0.2325\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3841 - accuracy: 0.2313 - val_loss: 1.3750 - val_accuracy: 0.2350\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3838 - accuracy: 0.2319 - val_loss: 1.3749 - val_accuracy: 0.2375\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3836 - accuracy: 0.2313 - val_loss: 1.3747 - val_accuracy: 0.2375\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.2319 - val_loss: 1.3746 - val_accuracy: 0.2375\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3831 - accuracy: 0.2331 - val_loss: 1.3745 - val_accuracy: 0.2400\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.2331 - val_loss: 1.3743 - val_accuracy: 0.2400\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.2338 - val_loss: 1.3742 - val_accuracy: 0.2375\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.2338 - val_loss: 1.3741 - val_accuracy: 0.2400\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3821 - accuracy: 0.2338 - val_loss: 1.3739 - val_accuracy: 0.2400\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3819 - accuracy: 0.2356 - val_loss: 1.3738 - val_accuracy: 0.2350\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3817 - accuracy: 0.2362 - val_loss: 1.3737 - val_accuracy: 0.2350\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.2375 - val_loss: 1.3735 - val_accuracy: 0.2375\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3812 - accuracy: 0.2381 - val_loss: 1.3734 - val_accuracy: 0.2425\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3810 - accuracy: 0.2387 - val_loss: 1.3732 - val_accuracy: 0.2425\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3808 - accuracy: 0.2400 - val_loss: 1.3731 - val_accuracy: 0.2425\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3805 - accuracy: 0.2400 - val_loss: 1.3730 - val_accuracy: 0.2425\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3803 - accuracy: 0.2419 - val_loss: 1.3728 - val_accuracy: 0.2450\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3801 - accuracy: 0.2419 - val_loss: 1.3727 - val_accuracy: 0.2450\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3799 - accuracy: 0.2412 - val_loss: 1.3725 - val_accuracy: 0.2450\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3796 - accuracy: 0.2431 - val_loss: 1.3724 - val_accuracy: 0.2450\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3794 - accuracy: 0.2419 - val_loss: 1.3722 - val_accuracy: 0.2450\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3792 - accuracy: 0.2425 - val_loss: 1.3721 - val_accuracy: 0.2475\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3790 - accuracy: 0.2419 - val_loss: 1.3719 - val_accuracy: 0.2475\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3788 - accuracy: 0.2425 - val_loss: 1.3717 - val_accuracy: 0.2475\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3785 - accuracy: 0.2431 - val_loss: 1.3716 - val_accuracy: 0.2475\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3783 - accuracy: 0.2431 - val_loss: 1.3714 - val_accuracy: 0.2475\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3781 - accuracy: 0.2431 - val_loss: 1.3712 - val_accuracy: 0.2475\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3778 - accuracy: 0.2412 - val_loss: 1.3711 - val_accuracy: 0.2475\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3776 - accuracy: 0.2419 - val_loss: 1.3709 - val_accuracy: 0.2475\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3774 - accuracy: 0.2438 - val_loss: 1.3707 - val_accuracy: 0.2500\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3771 - accuracy: 0.2419 - val_loss: 1.3705 - val_accuracy: 0.2550\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3769 - accuracy: 0.2431 - val_loss: 1.3703 - val_accuracy: 0.2550\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3767 - accuracy: 0.2425 - val_loss: 1.3702 - val_accuracy: 0.2625\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3764 - accuracy: 0.2419 - val_loss: 1.3700 - val_accuracy: 0.2650\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3762 - accuracy: 0.2425 - val_loss: 1.3698 - val_accuracy: 0.2650\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3760 - accuracy: 0.2419 - val_loss: 1.3696 - val_accuracy: 0.2600\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3757 - accuracy: 0.2425 - val_loss: 1.3694 - val_accuracy: 0.2600\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3755 - accuracy: 0.2431 - val_loss: 1.3693 - val_accuracy: 0.2600\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3753 - accuracy: 0.2438 - val_loss: 1.3691 - val_accuracy: 0.2600\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3750 - accuracy: 0.2431 - val_loss: 1.3689 - val_accuracy: 0.2600\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3748 - accuracy: 0.2438 - val_loss: 1.3687 - val_accuracy: 0.2600\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3746 - accuracy: 0.2463 - val_loss: 1.3685 - val_accuracy: 0.2600\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3743 - accuracy: 0.2431 - val_loss: 1.3683 - val_accuracy: 0.2600\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3741 - accuracy: 0.2438 - val_loss: 1.3681 - val_accuracy: 0.2600\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3738 - accuracy: 0.2463 - val_loss: 1.3679 - val_accuracy: 0.2600\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3736 - accuracy: 0.2456 - val_loss: 1.3677 - val_accuracy: 0.2625\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3733 - accuracy: 0.2431 - val_loss: 1.3675 - val_accuracy: 0.2625\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3731 - accuracy: 0.2438 - val_loss: 1.3673 - val_accuracy: 0.2625\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3728 - accuracy: 0.2438 - val_loss: 1.3670 - val_accuracy: 0.2625\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3726 - accuracy: 0.2444 - val_loss: 1.3668 - val_accuracy: 0.2625\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3723 - accuracy: 0.2438 - val_loss: 1.3666 - val_accuracy: 0.2575\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3721 - accuracy: 0.2431 - val_loss: 1.3664 - val_accuracy: 0.2600\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3718 - accuracy: 0.2438 - val_loss: 1.3662 - val_accuracy: 0.2600\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3716 - accuracy: 0.2444 - val_loss: 1.3660 - val_accuracy: 0.2575\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3713 - accuracy: 0.2450 - val_loss: 1.3658 - val_accuracy: 0.2550\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3710 - accuracy: 0.2456 - val_loss: 1.3655 - val_accuracy: 0.2525\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3708 - accuracy: 0.2444 - val_loss: 1.3653 - val_accuracy: 0.2550\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3705 - accuracy: 0.2450 - val_loss: 1.3651 - val_accuracy: 0.2550\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3702 - accuracy: 0.2438 - val_loss: 1.3648 - val_accuracy: 0.2550\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3699 - accuracy: 0.2444 - val_loss: 1.3646 - val_accuracy: 0.2550\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3697 - accuracy: 0.2450 - val_loss: 1.3643 - val_accuracy: 0.2550\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3694 - accuracy: 0.2450 - val_loss: 1.3641 - val_accuracy: 0.2550\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3691 - accuracy: 0.2444 - val_loss: 1.3638 - val_accuracy: 0.2550\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3688 - accuracy: 0.2438 - val_loss: 1.3636 - val_accuracy: 0.2550\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3685 - accuracy: 0.2431 - val_loss: 1.3633 - val_accuracy: 0.2525\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3682 - accuracy: 0.2438 - val_loss: 1.3631 - val_accuracy: 0.2525\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3679 - accuracy: 0.2431 - val_loss: 1.3628 - val_accuracy: 0.2550\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3676 - accuracy: 0.2450 - val_loss: 1.3625 - val_accuracy: 0.2550\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3673 - accuracy: 0.2456 - val_loss: 1.3623 - val_accuracy: 0.2575\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3670 - accuracy: 0.2463 - val_loss: 1.3620 - val_accuracy: 0.2500\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3666 - accuracy: 0.2481 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3663 - accuracy: 0.2481 - val_loss: 1.3614 - val_accuracy: 0.2475\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3660 - accuracy: 0.2481 - val_loss: 1.3612 - val_accuracy: 0.2500\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3657 - accuracy: 0.2488 - val_loss: 1.3609 - val_accuracy: 0.2550\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3653 - accuracy: 0.2494 - val_loss: 1.3606 - val_accuracy: 0.2550\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3650 - accuracy: 0.2500 - val_loss: 1.3603 - val_accuracy: 0.2525\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3647 - accuracy: 0.2500 - val_loss: 1.3600 - val_accuracy: 0.2525\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3643 - accuracy: 0.2500 - val_loss: 1.3597 - val_accuracy: 0.2525\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3640 - accuracy: 0.2750 - val_loss: 1.3595 - val_accuracy: 0.3675\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3636 - accuracy: 0.3075 - val_loss: 1.3592 - val_accuracy: 0.3675\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3633 - accuracy: 0.3475 - val_loss: 1.3589 - val_accuracy: 0.3650\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3629 - accuracy: 0.3456 - val_loss: 1.3586 - val_accuracy: 0.3625\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3626 - accuracy: 0.3444 - val_loss: 1.3583 - val_accuracy: 0.3600\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3622 - accuracy: 0.3462 - val_loss: 1.3580 - val_accuracy: 0.3650\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3619 - accuracy: 0.3475 - val_loss: 1.3576 - val_accuracy: 0.3650\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3615 - accuracy: 0.3456 - val_loss: 1.3573 - val_accuracy: 0.3650\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3612 - accuracy: 0.3450 - val_loss: 1.3570 - val_accuracy: 0.3625\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3608 - accuracy: 0.3456 - val_loss: 1.3567 - val_accuracy: 0.3625\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3604 - accuracy: 0.3450 - val_loss: 1.3564 - val_accuracy: 0.3625\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3601 - accuracy: 0.3450 - val_loss: 1.3560 - val_accuracy: 0.3625\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3597 - accuracy: 0.3462 - val_loss: 1.3557 - val_accuracy: 0.3625\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3593 - accuracy: 0.3450 - val_loss: 1.3554 - val_accuracy: 0.3625\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3589 - accuracy: 0.3431 - val_loss: 1.3550 - val_accuracy: 0.3625\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3585 - accuracy: 0.3438 - val_loss: 1.3547 - val_accuracy: 0.3625\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3581 - accuracy: 0.3450 - val_loss: 1.3544 - val_accuracy: 0.3650\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3578 - accuracy: 0.3469 - val_loss: 1.3540 - val_accuracy: 0.3650\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3574 - accuracy: 0.3494 - val_loss: 1.3537 - val_accuracy: 0.3625\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3570 - accuracy: 0.3512 - val_loss: 1.3533 - val_accuracy: 0.3675\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3565 - accuracy: 0.3500 - val_loss: 1.3530 - val_accuracy: 0.3725\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3561 - accuracy: 0.3506 - val_loss: 1.3526 - val_accuracy: 0.3725\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3557 - accuracy: 0.3506 - val_loss: 1.3522 - val_accuracy: 0.3750\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3553 - accuracy: 0.3519 - val_loss: 1.3519 - val_accuracy: 0.3750\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3549 - accuracy: 0.3531 - val_loss: 1.3515 - val_accuracy: 0.3775\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3545 - accuracy: 0.3525 - val_loss: 1.3511 - val_accuracy: 0.3775\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3541 - accuracy: 0.3537 - val_loss: 1.3507 - val_accuracy: 0.3800\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3537 - accuracy: 0.3544 - val_loss: 1.3504 - val_accuracy: 0.3800\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3533 - accuracy: 0.3544 - val_loss: 1.3500 - val_accuracy: 0.3800\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3528 - accuracy: 0.3537 - val_loss: 1.3496 - val_accuracy: 0.3825\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3524 - accuracy: 0.3544 - val_loss: 1.3492 - val_accuracy: 0.3800\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3520 - accuracy: 0.3556 - val_loss: 1.3488 - val_accuracy: 0.3800\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3516 - accuracy: 0.3569 - val_loss: 1.3484 - val_accuracy: 0.3800\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3511 - accuracy: 0.3575 - val_loss: 1.3480 - val_accuracy: 0.3800\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3507 - accuracy: 0.3562 - val_loss: 1.3476 - val_accuracy: 0.3800\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3502 - accuracy: 0.3587 - val_loss: 1.3472 - val_accuracy: 0.3800\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3498 - accuracy: 0.3587 - val_loss: 1.3468 - val_accuracy: 0.3825\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3494 - accuracy: 0.3600 - val_loss: 1.3463 - val_accuracy: 0.3825\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3489 - accuracy: 0.3613 - val_loss: 1.3459 - val_accuracy: 0.3800\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3485 - accuracy: 0.3631 - val_loss: 1.3455 - val_accuracy: 0.3800\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3480 - accuracy: 0.3638 - val_loss: 1.3451 - val_accuracy: 0.3800\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3475 - accuracy: 0.3619 - val_loss: 1.3446 - val_accuracy: 0.3825\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3471 - accuracy: 0.3638 - val_loss: 1.3442 - val_accuracy: 0.3825\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3466 - accuracy: 0.3644 - val_loss: 1.3437 - val_accuracy: 0.3825\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3461 - accuracy: 0.3663 - val_loss: 1.3433 - val_accuracy: 0.3850\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3457 - accuracy: 0.3663 - val_loss: 1.3428 - val_accuracy: 0.3825\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3452 - accuracy: 0.3663 - val_loss: 1.3424 - val_accuracy: 0.3850\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3447 - accuracy: 0.3675 - val_loss: 1.3420 - val_accuracy: 0.3825\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3442 - accuracy: 0.3669 - val_loss: 1.3415 - val_accuracy: 0.3850\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3437 - accuracy: 0.3669 - val_loss: 1.3410 - val_accuracy: 0.3875\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3432 - accuracy: 0.3681 - val_loss: 1.3406 - val_accuracy: 0.3900\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3428 - accuracy: 0.3675 - val_loss: 1.3401 - val_accuracy: 0.3925\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3423 - accuracy: 0.3688 - val_loss: 1.3397 - val_accuracy: 0.3900\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3418 - accuracy: 0.3681 - val_loss: 1.3392 - val_accuracy: 0.3900\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3413 - accuracy: 0.3706 - val_loss: 1.3387 - val_accuracy: 0.3875\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3408 - accuracy: 0.3725 - val_loss: 1.3383 - val_accuracy: 0.3850\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3403 - accuracy: 0.3719 - val_loss: 1.3378 - val_accuracy: 0.3850\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3398 - accuracy: 0.3744 - val_loss: 1.3373 - val_accuracy: 0.3875\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3393 - accuracy: 0.3756 - val_loss: 1.3368 - val_accuracy: 0.3900\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3388 - accuracy: 0.3756 - val_loss: 1.3364 - val_accuracy: 0.3900\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3382 - accuracy: 0.3787 - val_loss: 1.3359 - val_accuracy: 0.3900\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3377 - accuracy: 0.3781 - val_loss: 1.3354 - val_accuracy: 0.3900\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3372 - accuracy: 0.3800 - val_loss: 1.3349 - val_accuracy: 0.3900\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3367 - accuracy: 0.3794 - val_loss: 1.3344 - val_accuracy: 0.3900\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.3362 - accuracy: 0.3812 - val_loss: 1.3339 - val_accuracy: 0.3925\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.3357 - accuracy: 0.3812 - val_loss: 1.3334 - val_accuracy: 0.3975\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.3351 - accuracy: 0.3819 - val_loss: 1.3329 - val_accuracy: 0.3975\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 1.3346 - accuracy: 0.3825 - val_loss: 1.3324 - val_accuracy: 0.3975\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3340 - accuracy: 0.3819 - val_loss: 1.3319 - val_accuracy: 0.3975\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3335 - accuracy: 0.3812 - val_loss: 1.3314 - val_accuracy: 0.3975\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3330 - accuracy: 0.3806 - val_loss: 1.3309 - val_accuracy: 0.3975\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3324 - accuracy: 0.3812 - val_loss: 1.3303 - val_accuracy: 0.3975\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3318 - accuracy: 0.3812 - val_loss: 1.3298 - val_accuracy: 0.3975\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3313 - accuracy: 0.3825 - val_loss: 1.3293 - val_accuracy: 0.3975\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3307 - accuracy: 0.3825 - val_loss: 1.3288 - val_accuracy: 0.3975\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3302 - accuracy: 0.3850 - val_loss: 1.3282 - val_accuracy: 0.3975\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3296 - accuracy: 0.3850 - val_loss: 1.3277 - val_accuracy: 0.3950\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3290 - accuracy: 0.3844 - val_loss: 1.3272 - val_accuracy: 0.3950\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3285 - accuracy: 0.3844 - val_loss: 1.3266 - val_accuracy: 0.3900\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3279 - accuracy: 0.3856 - val_loss: 1.3261 - val_accuracy: 0.3900\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3273 - accuracy: 0.3844 - val_loss: 1.3255 - val_accuracy: 0.3900\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3267 - accuracy: 0.3850 - val_loss: 1.3250 - val_accuracy: 0.3900\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3261 - accuracy: 0.3837 - val_loss: 1.3244 - val_accuracy: 0.3925\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3255 - accuracy: 0.3806 - val_loss: 1.3239 - val_accuracy: 0.3950\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3250 - accuracy: 0.3800 - val_loss: 1.3233 - val_accuracy: 0.3925\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3244 - accuracy: 0.3787 - val_loss: 1.3228 - val_accuracy: 0.3875\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3238 - accuracy: 0.3762 - val_loss: 1.3222 - val_accuracy: 0.3875\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3232 - accuracy: 0.3762 - val_loss: 1.3216 - val_accuracy: 0.3925\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3226 - accuracy: 0.3731 - val_loss: 1.3210 - val_accuracy: 0.3950\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3220 - accuracy: 0.3738 - val_loss: 1.3205 - val_accuracy: 0.3950\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3213 - accuracy: 0.3719 - val_loss: 1.3199 - val_accuracy: 0.3925\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3207 - accuracy: 0.3706 - val_loss: 1.3193 - val_accuracy: 0.3900\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3201 - accuracy: 0.3706 - val_loss: 1.3187 - val_accuracy: 0.3900\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3195 - accuracy: 0.3688 - val_loss: 1.3181 - val_accuracy: 0.3850\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3188 - accuracy: 0.3694 - val_loss: 1.3175 - val_accuracy: 0.3875\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3182 - accuracy: 0.3619 - val_loss: 1.3170 - val_accuracy: 0.3775\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3176 - accuracy: 0.3594 - val_loss: 1.3164 - val_accuracy: 0.3825\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3169 - accuracy: 0.3625 - val_loss: 1.3158 - val_accuracy: 0.3825\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3163 - accuracy: 0.3631 - val_loss: 1.3152 - val_accuracy: 0.3825\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3156 - accuracy: 0.3625 - val_loss: 1.3145 - val_accuracy: 0.3800\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3150 - accuracy: 0.3613 - val_loss: 1.3139 - val_accuracy: 0.3825\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3143 - accuracy: 0.3613 - val_loss: 1.3133 - val_accuracy: 0.3775\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3137 - accuracy: 0.3606 - val_loss: 1.3127 - val_accuracy: 0.3800\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3130 - accuracy: 0.3619 - val_loss: 1.3121 - val_accuracy: 0.3825\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3124 - accuracy: 0.3619 - val_loss: 1.3115 - val_accuracy: 0.3825\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3117 - accuracy: 0.3625 - val_loss: 1.3108 - val_accuracy: 0.3825\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3111 - accuracy: 0.3644 - val_loss: 1.3102 - val_accuracy: 0.3800\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3104 - accuracy: 0.3644 - val_loss: 1.3096 - val_accuracy: 0.3800\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3097 - accuracy: 0.3644 - val_loss: 1.3089 - val_accuracy: 0.3800\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3090 - accuracy: 0.3644 - val_loss: 1.3083 - val_accuracy: 0.3750\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3084 - accuracy: 0.3663 - val_loss: 1.3077 - val_accuracy: 0.3750\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3077 - accuracy: 0.3669 - val_loss: 1.3070 - val_accuracy: 0.3750\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3070 - accuracy: 0.3681 - val_loss: 1.3064 - val_accuracy: 0.3700\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3063 - accuracy: 0.3675 - val_loss: 1.3057 - val_accuracy: 0.3700\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3056 - accuracy: 0.3688 - val_loss: 1.3051 - val_accuracy: 0.3700\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3049 - accuracy: 0.3675 - val_loss: 1.3044 - val_accuracy: 0.3700\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3042 - accuracy: 0.3675 - val_loss: 1.3037 - val_accuracy: 0.3700\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3035 - accuracy: 0.3663 - val_loss: 1.3031 - val_accuracy: 0.3700\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3028 - accuracy: 0.3663 - val_loss: 1.3024 - val_accuracy: 0.3700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot accuracy for various optimizers"
      ],
      "metadata": {
        "id": "omZcvjzhXyXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_1.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 0].plot(history_1.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 0].set_title('SGD')\n",
        "axs[0, 1].plot(history_2.history['accuracy'],label='train_accuracy')\n",
        "axs[0, 1].plot(history_2.history['val_accuracy'],label='test_accuracy')\n",
        "axs[0, 1].set_title('RMSprop')\n",
        "axs[1, 0].plot(history_3.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 0].plot(history_3.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 0].set_title('Adam')\n",
        "axs[1, 1].plot(history_4.history['accuracy'],label='train_accuracy')\n",
        "axs[1, 1].plot(history_4.history['val_accuracy'],label='test_accuracy')\n",
        "axs[1, 1].set_title('Adagrad')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='accuracy')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "4-ni7ksvXsJj",
        "outputId": "546432b3-a19e-4707-c06a-4163cda09cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss for various optimizers"
      ],
      "metadata": {
        "id": "JQGKj84xX7aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_1.history['loss'],label='train_loss')\n",
        "axs[0, 0].plot(history_1.history['val_loss'],label='test_loss')\n",
        "axs[0, 0].set_title('SGD')\n",
        "axs[0, 1].plot(history_2.history['loss'],label='train_loss')\n",
        "axs[0, 1].plot(history_2.history['val_loss'],label='test_loss')\n",
        "axs[0, 1].set_title('RMSprop')\n",
        "axs[1, 0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[1, 0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[1, 0].set_title('Adam')\n",
        "axs[1, 1].plot(history_4.history['loss'],label='train_loss')\n",
        "axs[1, 1].plot(history_4.history['val_loss'],label='test_loss')\n",
        "axs[1, 1].set_title('Adagrad')\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UHXvP7_vX3UD",
        "outputId": "aaf43ac2-8885-4101-a7cf-007819dc2c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e87M+mFhBRKAoReQgkQuoiugChIEVBREVYUsSurrnXt667+VuwiFuwNxAJKVXoPndB7QgjpvWfO7487YIQAATLczOR8nuc+zNw274Q7972n3HNFKYWmaZqmAVjMDkDTNE2rOXRS0DRN007SSUHTNE07SScFTdM07SSdFDRN07STdFLQNE3TTtJJQdM0TTtJJwUXJCKXicgqEckWkQwRWSki3RzLGojIhyKSJCJ5InJARD4VkTaO5VEiohzL8kTkuIjMEZEB5n4rzV2IyCERKXQcX8mO48/fsexTx/E37JRtpjjmj3e89xSR/4lIomM/h0TkDRO+Tq2jk4KLEZFAYA7wNlAXiACeB4pFJARYBfgCfYEAoAuwFDj1pB+klPIHOgELgR9P/CA1rRpc5zi+YoDOwBMVlu0BbjvxRkRswA3A/grrPAHEAt0xjuMrgI0XEohj/1oV6aTgeloBKKW+UUqVK6UKlVILlFJbgYeBHGCsUmq/MmQppaYrpd6ubGdKqWSl1JvAc8B/RUQfE1q1UUolA/MxksMJs4HLRCTY8X4QsBVIrrBON+BHpVSS4zg+pJT6/MRCR8nhCRHZISKZIjJdRLwdy65wlDD+KSLJwHQR8RKRNxwl6CTHa69T1n9SRNIc+77FeX+Vmk2fAFzPHqBcRD4TkWsq/LAA+mP8kOwXsN9ZQDjQujqC1DQAEYkErgH2VZhdBPwM3OR4fxvw+SmbrgEmi8g9ItJBRKSS3d8CXA00x7hYerrCsvoYJekmwETgKaAnRnLqhFECOXX9UIyS9zhgmojUyt+CTgouRimVA1wGKOBDIFVEfhGRehgH9cmrLREZKiJZIpIrIgvOseskx791nRG3Vuv8JCK5QAKQAjx7yvLPgdtEJAjoB/x0yvJXgP9inPjjgKMiMu6Udd5RSiUopTKAl4ExFZbZgWeVUsVKqULHfl5QSqUopVIxqlzHnrK/ZxzrLwV+xajSqnV0UnBBSqmdSqnxSqlIoD3QEHgDSAcaVFjvF6VUEEa1kuc5dhvh+DfDCSFrtc9wpdSJtoA2GBcsJymlVgBhGFfwcxwn7orLy5VS7yql+gBBGCf9T0SkbYXVEiq8PozxOzghVSlVVOF9Q8c6Z1o/UymVf5bltYZOCi5OKbUL+BQjOfwODL/AdoERGFd0u6svOq22c1x1fwr8XyWLvwT+welVR6fuo1Ap9S6QCbSrsKhRhdeN+bO0C0ZJuqIkjKqkM60fLCJ+Z1lea+ik4GJEpI2I/MNRV4uINMIoNq8BXgeCgS9EpLkYAvhrI9+p+6snIvdhFO+fuMD2CE07mzeAASLS6ZT5b2H0ilt26gYi8pCjAdhHRGyOqqMAYFOF1e4VkUgRqYtR4vjuLDF8AzwtImEiEgr8CyMpVfS8oytsX2AIMON8vqS70F21XE8u0AOjES4IyMLoovqoUipHRHoCLwIrMH5Exx2v7z5lP1mOxrt8jDrb0UqpeZfoO2i1iFIqVUQ+xzgR51aYn4FRuq1MAfA/oAXGVf8eYKRS6kCFdb4GFmBU8/wMvHSWMF4CAjF6OYFxwq+4fjJGSSTJ8dmTHKXwWkf0Q3Y0TXM1InIIuEMptaga9nUF8KWjja7W09VHmqZp2kk6KWiapmkn6eojTdM07SRdUtA0TdNOcrneR6GhoSoqKsrsMDQ3tWHDhjSlVJgZn62Pbc2Zqnpsu1xSiIqKIi4uzuwwNDclIofPvZZz6GNbc6aqHtu6+kjTNE07yW2SglKKgpIys8PQtGpXVFqO3a47hGiXhtskhed/3saED5dSUqZHadDcR0pOEVe/sYxv1yece2VNqwZukxTG57zPY8cf47nvV1JWrhOD5h7C/D14wDKTb377neTsonNvoGkXyW2SQlS3wXS0HmLirgm8+uEXZBWUmB2Spl00yU9leNlc3uK/vDJrNfq+Is3Z3CYp0HYI1vGzCfW18mTyA8S9NpSFi/+gXNfFaq4soD7Wm76ksSWVkQeeYf7WRLMj0tyc+yQFgCa98X9oLamdH6A3mxmwdARbXr6cDb99THlpsdnRadqFadIbBv+Py63byPjpcfKLdYcKzXncKykAeAcSNuxFvB/Zwe7oh2hoT6bruslk/7slu794mNKUvWZHqGnnzRo7nuOtx3KzmsPSlSvMDkdzY+6XFBwsfnVpPfp5wp7aydre09hpa0vzfZ/i8V4sx94aQMmu+aDrZzUXEn7tEwCkr5+h2xY0p3HbpHCC1Wajx8Ab6f3kPFYPW8aXvuNQ6fvw/PYG0l7vRcnuix6OXdMuCakTQUpQDF3yl7M1MdvscDQ35fZJ4QQRoW+XDtzy6JscunklHwRNJj87Hc9vRpLx8SjING10A02rssAu1xNtOczcZavMDkVzU7UmKZwgIvRu3ZC7HnqWhJsXM9V2K15HllH0di/KNn1rdniadlbeHYYDYN09m+yCUpOj0dxRrUsKFV3WJpLbHnuTD6K/YltZBLaf76LguzuhVN8kpNVQwU0oCO3IANYya5PunqpVv1qdFAB8PW1MvmEAqdfP4n01Ct+d35P/0WDITzM7NE2rlG+nEcRY9rN20xazQ9HcUK1PCidcG9OIAfe+wTMej2BN3kLh+1dA1hGzw9K007UbBkCj47/rsb60aqeTQgUtwgO47/5HeTzg35TmplP44TU6MWg1T0hzcgNb0o8NxCfpXkha9dJJ4RT1Ar15/t6/86+glynNy6Doo2sh55jZYWnaX1ijetPJcoBNh9PNDkVzMzopVKKOjwfPTryVpwJeojw3lYLPRkJxntlhadpJvk17ECCFHN271exQNDejk8IZBPt58uykW3nO+1E803dS+M04KNdjzmg1RGQsAJKkH9+pVS+dFM4i1N+LuyZM4j/cjs+hRRQveNbskDTNENKSEps/TYt2kZRVaHY0mhvRSeEcWoT787exT/B1+VV4rX0HtXuu2SFpGlgsFIfHEGPZx4bDmWZHo7kRnRSqoHfzUEr6/5t4exOKZ0zUPZK0GsG3WQ9aSwJbD+mOEFr10UmhisZd3ppvm75EaWkpuV//Hey6f7hmLmujbtjETt6B9WaHorkRnRSqSER4bMw1vO11JwEpcRSvet/skLTaLsJobA5M30pRabnJwWjuQieF8xDg7cHVNz/E4vIY5PfnIX2/2SFptZl/GIV+kXSQfWxJyDI7Gs1N6KRwnrpGhRAf+yJFditZ307U1UiaqSQylhjLfrYn5ZgdiuYmdFK4AHcO7sM03zsJSo2jaNVUs8PRajHvqO5EShoJRw6aHYrmJnRSuABeNiv9xzzMUntH+ONFyD5qdkhabeVoV+DoBnPj0NyGTgoXKKZxMJs7PAPlpWTNmmx2OJqLEpGJIhInInGpqannv4N60QAEZu+muEw3NmsXTyeFi3D7dVfyse1Ggg7Po2znr2aHo7kgpdQ0pVSsUio2LCzs/Hfg5U++XyNaSQJ7j+vxubSL57SkICKfiEiKiGw/w3IRkbdEZJ+IbBWRLs6KxVkCvD1oOfxxdtsjKfxpsh40TzNHvWjayBF26MZmrRo4s6TwKTDoLMuvAVo6pomAS3b8H9ihET9FPkpAcTI5814yOxytFvKN6ECUJLPn6AVUP2naKZyWFJRSy4CMs6wyDPhcGdYAQSLSwFnxONNtN97ID+pv+G6ahjq+w+xwtFpG6kdjEzs5CfFmh6K5ATPbFCKAhArvEx3zTnPRjXFO1qCOD4X9niFX+ZA5435QyuyQtNqkXnsAbGk7sNv1saddHJdoaL7oxrhL4KZ+MXzmO566aXEUbfzG7HC02qRuM8osXkSVHyYhs8DsaDQXZ2ZSOAo0qvA+0jHPJdmsFi674WE22VtQPvdJKNTDDmiXiMVKSXBL3disVQszk8IvwG2OXkg9gWyllEuPARzbNJRlLf+Jd2kWmb/qB/Jol45nRAfaWBKI10lBu0jO7JL6DbAaaC0iiSIyQUQmicgkxyq/AQeAfcCHwD3OiuVSGnv9cGbIQOps/xyVtMnscLRawla/PeGSRUKiftaHdnFsztqxUmrMOZYr4F5nfb5Z6vp5Yu3/L9IXrsY64wHq3r8ULC7RdKO5snrtACg9th0YYG4smkvTZysnGNk7mi8D76Ru5lYK1n1qdjhabRBuDHdRr3A/qbnFJgejuTKdFJzAYhEG3PgAa+1tYOGzkJ9udkiau/MPp9QrhNaSQHxSttnRaC6sSklBRB4UkUBHo/DHIrJRRAY6OzhX1j4yiA3RT+FZlkfGL0+aHY7m7kSQ+u1oYzmiG5u1i1LVksLtSqkcYCAQDIwF/uO0qNzErcOu4RvLEOru/hb7kXVmh6O5OVuDjrSxJLIjUZdMtQtX1aQgjn+vBb5QSsVXmKedQaC3B8HXPMMxVZesmQ+AXQ9trDlRRBe8KaHoaKVjUGpalVQ1KWwQkQUYSWG+iAQA+jmUVTC4W0u+rTuJujk7yV/xgdnhaO4soisA9XLjyS4oNTkYzVVVNSlMAB4HuimlCgAP4O9Oi8qNiAjX3XQ3K+wdsCx5GXKPmx2S5q6CoyjxCiZG9hF/TDc2axemqkmhF7BbKZUlIrcCTwP6qKuiFvUC2dP1X1jKi0n99h49YJ7mHCLQsCsxln3EH9WNzdqFqWpSeB8oEJFOwD+A/cDnTovKDd0y+Co+9bmVsKOLKIz7yuxwNDfl2aQ7LSxJ7E1IMjsUzUVVNSmUOe5AHga8o5R6FwhwXljux8tmpceYZ1hnb4PMfQyyE80OSXNHkV2xoChP3Gh2JJqLqmpSyBWRJzC6ov4qIhaMdgXtPMQ0CWFDzMuUl5eR+c1EsOu2eq2aNTSealsvdzv5xWUmB6O5oqomhRuBYoz7FZIxhrl+zWlRubG/X3clH3jfTnDySgpW6t5IWjXzrUuBfxQxso+dx3S7gnb+qpQUHIngK6COiAwBipRSuk3hAnh7WBk49nGW2Tti/eM5VNo+s0PS3Iw0iiXGsp9tifqZHtr5q+owFzcA64DRwA3AWhEZ5czA3Fn7yCAS+r5Gkd1C+hfjoLTI7JA0N+LdpBvhksWhg3vNDkVzQVWtPnoK4x6FcUqp24DuwDPOC8v9jbmqB9NDHyE0ezvZPzygu6lq1UYiuwFQcngdSh9X2nmqalKwKKVSKrxPP49ttUpYLMLN4+/lQxlFnV3fUbhKty9o1aR+e8otnrQoiicxs9DsaDQXU9UT+zwRmS8i40VkPPArxpPTtIsQHuBNp7H/5Q97FzwWPkn5geVmh6S5A5sXRQ17cYVlM2sPZpgdjeZiqtrQ/CgwDejomKYppf7pzMBqi+7NQkkd8DaH7eGUfH0zpOl6YO3i+URfQ3PLMfbt2mp2KJqLqXIVkFLqB6XUZMf0ozODqm1u7NueWW3fIL8U8j8ZDnkp595I087C0vpqAPwO/25yJJqrOWtSEJFcEcmpZMoVEd0Juho9OHogU8JexJKfQu4nI6BQdyfULkLdZmT5RtGpcC0pObp3m1Z1Z00KSqkApVRgJVOAUirwUgVZG3jaLPzzjlt4JeAJvNN3GiWGIj3moHbhSpr1p4dlJxv2JZgdiuZCdA+iGiTQ24P7Jt7DM16P4pW6laLpw6FIF8i0CxMScx1eUkbmtoVmh6K5EJ0UapjwQG/umvgAj1smYzu+haJPh0NxrtlhaU4iIhNFJE5E4lJTU6t139ao3hSIL8FHF1frfjX3ppNCDdQ01I+Jdz3I45aHsSVvoujjIZBXvScMrWZQSk1TSsUqpWLDwsKqd+c2T5JCetG5eD0ZecXVu2/NbemkUEO1qhfAxLse4hHLY5Cyg5IP+0PGAbPD0lyMd/S11JdMNiyfa3YomovQSaEGa1UvgLsn3sck6/PkZ6dTOq0/HNXj5GtVF9H7JvLww2/Lx2aHorkIpyYFERkkIrtFZJ+IPF7J8vEikioimx3THc6MxxW1rh/AC/eM5wGf/3C80ELZ9MGwVzccalUjXv7sjRxB98IVJB3WI/Jq5+a0pCAiVuBd4BqgHTBGRNpVsup3SqkYx/SRs+JxZY1DfJly72ieqPs6u0rCsX91A6yYogfR06qk3lX3IyiSFr1jdiiaC3BmSaE7sE8pdUApVQJ8i/E4T+0ChPp7MXXStbzZ6A1+K+8Oi55DfXuzvslNO6eGTduwwbsXLRNnokoKzA5Hq+GcmRQigIp3zSQ65p1qpIhsFZGZItKosh05s9ueK/HzsvHe7f1Y3/X/eL50LOW751P+QT9I2mR2aFoNlxszgToql8QVX5odilbDmd3QPBuIUkp1BBYCn1W2klO77bkYD6uF54d3oM3wx7i57F9kZOegpl0Jv78I9nKzw9NqqNh+Q9mlGhO06j+QssvscLQazJlJ4ShQ8co/0jHvJKVUulLqRAfqj4CuTozHrdzYrTH/vHMcN1jf4Ad7P1j+f6gvR0KWHtJAO10dX09+av4ihaXllE+/FpK3mR2SVh2yE2H2Q1CNj/V1ZlJYD7QUkaYi4gncBPxScQURaVDh7VBgpxPjcTtdmwTz3QNX82Ojx3midAIlB1ej3usB6z4Eu93s8LQaZuzQq7nN/hzZpRb4dAjsnK07K9QE+/+4sIs5ux1m3QUbpsOHf4M9C6olHKclBaVUGXAfMB/jZP+9UipeRF4QkaGO1R4QkXgR2QI8AIx3VjzuKjzQm88n9CSy/z0MLP4v60tbwG+PwKfXQvJ2s8PTapCIIB+u+1tfhuY/Rb5XOHx3K3w6GBLjdHIwy4op8MUI4/d6vqMWrHkXDq+Avz0NwY3h6xtg+esX/X8prvYM19jYWBUXF2d2GDXSpiOZPPL9ZjplzOMln6/xLc+BttdB/+chpLnZ4bkEEdmglIo147MvxbFdXFbO1VOW4SF25vY9iG3pK1CQBqGtocMo6Doe/MOdGoOGceJe+l9Y8gq06A+HVkL9DjBuNtjLYONnYPOG2NtB5PTtj++Aaf2g5UC48UsoLYSf74W843Dbz2D1OG2Tqh7bOim4maLScqYs3MN3y7dyv+8ixskcrPZSpMdd0Pcf4FvX7BBrNHdPCgB/7DrO7Z/GccdlTXm6fwRsmwHbfoAjqyCosXFiCo5yehw1Wu5xOLoBGvUAv5AL309xLsx7HA6vgtIiKKvwbIvCDIi5BYa+bVTlzRgHkd0hfS8UZhrrdLwJrnsTbF6QuB72LjDagxLWgcUK96wBv1BjXaWgJB+8/CsNRSeFWm7jkUwe/2ErmccTeS3kF/rlz0esHtBuOPR/DupU1jtYqw1JAeDZn7fz2erD/Of6DtzUvbExM3EDfHk9ePrBrbPg+HZY+4FxIut1H7QfCVmHYf3HxjhcI94Hn+BLEm+1Kc6FzEPGVfmpinJg/YewbSak7DDmBTSAkR9DVJ+/rnt4FSz/H1z+KDTuWflnpe4xqujS90KbIeAdaFz9I6DsULcZ9LwHLI5a/BVTYNFz0Ooa4wLu4BL44yWo1wHKCiF9H4gVQltB/fbQ426IrHrfHJ0UNErL7Xy55jCvL9xDo9KDPB8RR2z6zwhA86ug3VDoNKby4mktVVuSQlm5nds/i2PVvjQ+n9Cd3s0dV5vJ2+Dz4UaVEkBIC7B6GidJvzDITwWLzVjWuJeRPGyef+449zgs+bfxgKjr3gTvOpfk+1TJ8R3w3S1GQrvyKeOELmIkg3UfwKp3oCgLmlwGLftDWBuY/5SRRPr+A9oMhrDWsPItWPof48rc5gWjPjGWFWXDzjnG3yrjIBxcaiSBUZ9As35Vi7Eo+69/s51z4Nd/GNW/ncZAu2FGcrkAOiloJ6XlFfPavN18vyGBtt5ZvNbgD9rmrMCSlwwRsdD7fqPtwWI1O1TT1ZakAJBTVMrI91ZxLLuIF4ZFM6JzBCICqbthxRvGCajlQGPlvfNh05fGFXbX8XBgKfw40ThRDXvX2GbXHGO78hJAGQnl5u8hMAIOLYe0PcZxFtjw9GAKs6A4x6i+OqGsxCitePoZJ8qyYqMLZnYCpO83rsDzUkAsxrHr6W9Uj/qGGp8d1gZ8gqAkD5I2G9U4XgEQ2c2ItdMYY73V7xjVNa0GQb9/QkSXP2MoyoHZD0L8LMcMMb5bxxvhyidh5u3GzaMtBsDBZcYVvc3HqH6rFw0DXqgxpXKdFLTTbEvM5n8Ld7NkdyqhvlamtNxCn+PfYMk6CEFNoPNYiB4BdZvW2gRRm5ICwLHsQh78ZjPrDmUwuGMDXh7eniBfz3NvCLDkv0apwOZjnAzBqCYZ8ALkHDWqTiw246Sd7+hZI1Zocy20vBoCGxilkC3fwfYfjH1E9TWSTspO2Pg55KdU/tliMY7ZgAaAMhpni/OMk3tBmvH+VI16wOjPIKA+LH3ViB0qTwanyjhonPyPbYEGnaD99cb8knwjMRxeDR1GQsyt0LDzn1VCNYhOCtoZbTicyRuL9rB8bxp1fSw81+ow1xTMxiNhhbFCSAtofQ20HQqNupsb7CVW25ICQLld8cGy/by+YA8B3jYmD2zNmG6NsFnPcWJTCla9BZmHITLWaCQNbfHn8rS9MOdh4+q9/Uijh9Pmr4wSR2HGn+t5+EHHG6BOJGz4DLKPAGKcrDuMMtYpzDQSSFAjCIyE4CZG1U2lX6jMqPJJ3WW0IXgFGG0fjbr/tVfOgaVGVUzDzhfyZ/vr30GpGpkIKtJJQTunDYczmbp0Pwt3HMfbw8IdrQq5IfQwjZLmIUkbjWqAE/WrLQYYxWE3b3+ojUnhhJ3Hcnjul3jWHsygTf0A7v9bSwa1r4/VUs3/5+WlRjVQbrJxso/q82c9ur0cjqw2qpEqViVpF00nBa3K9qXk8fGKg/yy+Sj5JeW0qufP2K5hjCr+CZ99v8Fxx5AIAQ2hSW/jqjCkhdFYXcOvjs5XbU4KAEop5m5P5tV5uziUXkBUiC/je0cxuGNDwgLOcGWuuQSdFLTzlldcxuwtSXy77ghbErOxWoSezeoyormFAV7bqZO4xOi2mJNobBDezqjTjehi1BGHtapZvU0uQG1PCieU2xUL4pOZunQ/WxKzsQj0ah7C4A4NGRhdj1B/nSBcjU4K2kWJT8rm163HmBefzIHUfAA6Nw7i6uj6DIkoJDJjNcT/ZHThS9lh9LsGI1E0/5vRqBfSwuiL7eFt4jc5PzopnG53ci5ztiYxe0sSh9ILsIgx7laXJsHERAYRG1VXlyJcgE4KWrXZl5LLvO3JzItPZvvRHABa1wugf7twejULpWs4+CQuN/p/754Lx7ZCuWPwW09/o7eHXxg07AKNuhkNe3Ua18iqJ50Uzkwpxa7kXOZuO8bSPansPJZLSblxMRDdMJDLW4XRLSqYmEbB1PWrYg8m7ZLRSUFzioSMAhbsOM787clsOJJJuV3hYRU6RQbRs1kIPZuF0DXSH5+UTUa3xCNrjJ4m2YlGd74Tt/nbvCGkJfgGg28IBDc1ShV1Hf/61zclaeikUHXFZeXsSMph1f50lu5JZcNh43gAY/C9qFBfokL86BZVl8tbhelEYTKdFDSnyysuI+5QBmsOZLDmQDrbjmafTBIdI4PoEFGHdg0DiW4YSMvwADwpMxqtk7cbNzKl7TFuDspPgawjf+1bbvUy2ica9zAShH+4UdrwCQaUcXNQ3eYXfHfnmeikcOHyi8vYdjSbTUey2J2cw8H0Ag6k5pFbVIYItK0fSFiAF0G+HjSo40Pr+v60DA8gIsiHIF8P48Y5zWl0UtAuuYpJYv2hDHYk5VBYajwNzsMqtAwPINqRJNo1rEPbBgEEeDv6jZeXGXeqZhyAzING3/ecJKN0kZ9i3P5fGb8wIzn41jXubg1uYpRA6rUD/3pGt0abN3gFgtV2zu+gk0L1stsV245ms3h3ChuPZJFdUEJmQSnHsgspLf/z3ONps9Ao2IcOEXXoEBlE47q+hPp7Eh7oTYNAbyzV3S22FtJJQTNduV1xKD2f+KQcdiTlEJ+UzY6kHNLzS06uExXiS7uGgbStH0jzcH+ahfkRFeKHt8cpd1SXFRt3xZ4YPTLjIGTsN4Y7yDhgLAtsaDyBKjfpz4bvEyw2x3AJQcY4MgNfMu67OIVOCpdGabmdQ2n57E3J41h2ESk5RexPzWfb0SyO5xT/ZV1Pm4WoEF8ig30JD/AiLMCLun6e1PXzJMTPi2A/D+r6eRLq74XHuW64q8Wqemyf+9JJ0y6Q1SI0D/OneZg/QzsZ490opUjJLSY+KZv4oznsOJbD9qM5/LYt+eR2IhAZ7EPzMH+ahfrTJMSXyGAfIoPrEBFcH38vW+WjXJ5QlGPc0ZqXAlmH/kwoRdnGspSdRgO4ZhoPq4WW9QJoWS/gtGUpuUUkZxeRlldMcnYxh9LzOZCaR1JWEduOZpOeV4y9kmtZi0D9QG8aBvnQIMiHBnW8Cfb1xMtmwcfTSl0/T8ICvAjx88Tbw4qXzYKvpw1Pm04kFemkoF1SIkK9QG/qBXrztzb1Ts7PLy7jYFo++1PzOJCaz4G0fPan5LH2QMbJKqgTgnw9iAjycSQK35OvIxzv6/gEQoOOl/qradUkPMCb8IAzd2MutyuyCkrILCghPc+ojsrILyE5u5DErEKSsgrZlpjFgvgiisvO/VhaT5uFQG8b9QK9aVDHmyBfTwTj4sTfy4NgXw+CfD0I8vUkyNcDX08rNosFD6sFPy8rvp42/LyseNusblHNpZOCViP4edloH1GH9hF/vflNKUVaXgmJmQUczSokMbPQeJ1ZyIHUfJbtSTstaQR42xyJwihhNAwyklB4gDfhgV7UC/Q2ShuaS7JahBB/L0L8vWhxlofEKaUoKrVTVFpOYWk5GfklpOYWk5FfQnGZMb+gpIzc4jJyCktJzi4iMbOQHUlGt2u7gtyiUvJLys/8IafwslkI8LYR6OOBn6eN0nI7xWV2PK0WQgOM6i4/LxveHha8bFZsFsFqEbw9rPh6nphs+Hpa8bRZEJ8GUwoAACAASURBVAGLCOV2RZldIUAdHw/q+Hjg7WHFIsaFls0iWK2Cp9VyetXredK/DK1GExHCHPXInRuf/kAXpRSZBaUkZhaQmFnIUUfSOJE8Vu9Pq/RHPWNSL7pF6afQuTMRwcfTio+nlWCgYZDPBe2npMxOVkEJ2YWlZBaUUlhaTlm5nZIyO4Wl5eSXlFNQXEZRqZ2C0jJyi8rILiyloLgMT5sFT5uV4tJy0vKK2ZKZRUFJOUUl5RSVlVNuV5VWhV2oluH+LJxcxWc3nIFOCppLE5GTjY4dI4NOW66UIq+4jOM5xaTkFHE8t4jjOcU0DfUzIVrNFXnaLIQHehMe6Jw78+12RXGZnYKSMgpKyh1TGSVldhRgVwqrCDarYFeQXVBKdmEpJeV27Epht6uTJYlAn9OfzXy+dFLQ3JqIEODtQYC3By3Ca17jsohMBCYCNG6sRwWtjSyWP0s0F/E06Gqjm901zURKqWlKqVilVGxYWJjZ4WiaTgqapmnan1zu5jURSQUOn2FxKJB2CcOpCh1T1dSUmJoopUy5ZHfBY/ti6O9z6VXp2Ha5pHA2IhJn1t2oZ6JjqpqaGFNN4m5/H/19ai5dfaRpmqadpJOCpmmadpK7JYVpZgdQCR1T1dTEmGoSd/v76O9TQ7lVm0JtJyKfAolKqafNjkXTzkdNOnZFZDxwh1LqMrNjMYO7lRTclogsEZFMEdEPw9Vcij52XYtOCi5ARKKAvoAChpoajKadB7OPXRHRozacJ50UXMNtwBrgU2DciZki0llENopIroh8B3hXWBYsInNEJNVxlTZHRCIrLF8iIi+JyCoRyROR2SISIiJfiUiOiKx3/KA17WI449htKiLLHNsuEpF3ReRLx7IoEVEiMkFEjgB/OObPEJFkEcl2bBtdYX8hIvKL47hfBzR38t+kRtNJwTXcBnzlmK4WkXoi4gn8BHwB1AVmACMrbGMBpgNNgMZAIfDOKfu9CRgLRGD8EFY7tqkL7ASeddL30WoPZxy7XwPrgBDgOYxj+FT9gLbA1Y73c4GWQDiw0RHPCe8CRUAD4HbHVHsppfRUgyfgMqAUCHW83wU8DFwOJOHoLOBYtgp46Qz7iQEyK7xfAjxV4f3/gLkV3l8HbDb7++vJdSdnHLsYSaIM8K2w/EvgS8frKIyqqmZniSvIsU4dwOqIsU2F5f8GVpj99zNr0iWFmm8csEApdeIW+q8d8xoCR5XjKHY4OUSCiPiKyAciclhEcoBlQJCIVHwCx/EKrwsreV/zhhXVXIkzjt2GQIZSqqDCtgmVfPbJeSJiFZH/iMh+x/4OORaFAmEYo0VX3MeZhhqpFXQjTA0mIj7ADYBVRE48xNgL40rnGBAhIlLhx9UY2O94/Q+gNdBDKZUsIjHAJsD1nxeo1XhOPHaPAXVFxLdCYmhUSQgVE87NwDCgP0ZCqANkOvaXilHyaIRRkjkRS62lSwo123CgHGiHUYSOwagnXe5YVgY8ICIeInI90L3CtgEYV/tZIlIX3T6gXVpOOXaVUoeBOOA5EfEUkV4YVZ1nEwAUA+mAL0b10In9lQOzHPvzFZF2VGgQr410UqjZxgHTlVJHlFLJJyaMRrcxwPXAeCADuBHj4D7hDcAHY+TGNcC8Sxm4Vus589i9BeiFcZJ/CfgO46R/Jp9jVAkdBXY49lnRfRhVpckYvaSmn8f3dDv6jmZN01yao0vrLqWULg1XA11S0DTNpYhINxFpLiIWERmE0V7wk9lxuQvd0Kxpmqupj1HdFAIkAncrpTaZG5L70NVHmqZp2km6+kjTNE07yWnVRyLyCTAESFFKta9k+RXAz8BBx6xZSqkXzrXf0NBQFRUVVY2RatqfNmzYkKZMekazPrY1Z6rqse3MNoVPMbqffX6WdZYrpYacz06joqKIi4u7mLg07YxExLS7WfWxrTlTVY9tp1UfKaWWYfRB1jRN01yE2W0KvURki4jMrTiU7alEZKKIxIlIXGpqaqXrHE7PZ9meypdpmiubtz2ZzPwSs8PQagkzk8JGoIlSqhPwNmfpZ6yUmqaUilVKxYaFVV4l9ur83Uz+fjPldt2bSnMfaXnF3Pv1Rnq+8juPzdxCfFK22SFpbs60pKCUylFK5Tle/wZ4iEjohe7v6uj6pOWVsOlIZrXFqGlmC/X34tcHLuP6LpHM3nKMwW+tYOT7q/hu/RFyi0rNDk9zQ6YlBRGpLyLieN3dEUv6he7vytZheFotzI9PPvfKmuZC2tQP5JXrO7Dmiat4enBbMgtK+OcP2+j28iIe/m4zq/alYdclZK2aOLNL6jfAFUCoiCRijHToAaCUmgqMAu4WkTKMERFvUhdxJ12Atwe9W4QwP/44T17bFke+0TS3UcfXgzv6NmPCZU3ZlJDFzA2JzN6SxI+bjhIR5MOwmIZc3yWCFuEBZoequTCnJQWl1JhzLH+H0x8PeVEGtqvPkz9uY1dyLm0bBFbnrjWtxhARujQOpkvjYP41pB3z45OZtfEoU5fu570l++kQUYfhnSMY2qkhYQFeZoeruRj3Gfso4yCDvbbzlBhVSDopaLWBt4eVYTERDIuJICW3iNlbjvHjpkRenLODf/+2k74tQxnROYKB7erj42k99w61Ws99ksLCZ6hzcDm9G01nQfxxHurfyuyINO2SCg/wZsJlTZlwWVP2Hs/lx01H+WnTUR78djN+nlYGtW/A9V0i6NksBKtFV69qlXOfpNDrPtg5m7sbr+PWrR1IyCigUV1fs6PSNFO0rBfAY4Pa8MjA1qw9mMGPmxKZuy2ZHzYmUj/Qm2GdGzKicwRt6usStfZX7pMUGvWAiK70OP4tQjTz45O5o28zs6PSNFNZLEKv5iH0ah7CC8Pas3DHcX7adJSPlx/kg6UHaNsgkOs7RzAspiHhgd5mh6vVAGbf0Vx9RKDXfXhkH2RcyC4WxB83OyJNqx7l1XM/greHles6NeTj8d1Y++RVPHddOzytwsu/7aTnK78z9uO1zNqYSH5xWbV8nuaa3KekANB2KNRpxAT1G5cfbkdGfgl1/TzNjkrTLlx5GbzaHOo2hchYiIiFyG4Q0ty4ELpAIf5ejO/TlPF9mrIvJY+fNh3lx01Hmfz9Fnw9t3N1dH1GdI6gT4tQ3f5Qy7hXUrDaoMckGi14imgOsHxvKsNiIsyOStPOSEQmAhMBGjdufPoKZUXQ/Q5IXA9bvoP1HxnzvYMgoqsxRcYa//pd2IAALcL9eeTq1kwe0Iq4w5n8uCmROVuP8eOmo4QHeDG0U0NGdImgXYNAff9PLeByT16LjY1VZx1euCgb9Xo0c0tjWND6Rd64qfOlC05zeSKyQSkVa8Znn/PYtpdD2h4jQSTGwdGNkBIPym4sD2pSIVF0g4adwXZhJeWi0nIW70ph1qajLNmdQmm5onW9AEZ0iWBkl0h9/4MLquqx7X5JAWDeE5Sv+YArLZ+w+OlhuvirVVmNTgqVKcmHY1scSWKDMWUnGMtsPtCoGzS5DKL6GFVPHuffmJyZX8KcrUnM2nSUTUey8LAKV0fX59aeTejRtK4uPbiIqh7b7lV9dELboVjXvEe7ok1sTexH58bBZkekac7h6QdNehvTCbnHIXEdHFoJh1fAklcABVZPIzFE9YGm/Ywee1UoSQT7eTK2VxRje0WxLyWPr9ceYeaGBOZsPUaLcH9u6dGY67tEUsfHw3nfU7tk3LOkUF6K+m9Tvi2M5djlrzJ5gL6RTasalyspVEVhJhxZaySIQyuNkoUqB88AaNYPWlwFLfpDUCVtGmfaZUk5s7cm8dXaI2xJyMLHw8rQTg0Z26sJ7SPqVP930C5a7S4pWD2Q5lfQf/caJuw6rpOCVrv5BEPrQcYEUJQDh5bDvkWwdxHsmmPMD20FLQYYSSLqMrCdud3Ax9PKDbGNuCG2EdsSs/lq7WF+3pzEd3EJ9GxWlzv7NuPK1uFYdNWty3HPpADQ/CrCds4mP2knqbnddcOYpp3gHQhtBhuTUpC210gQ+xYavZvWvGuUIlr2h9aDoeUA8Ak64+46RNbhP5EdeeLatny/PoFPVh5kwmdxNA/zY8Jlzbi+SwTeHnrcJVfhvkmhxVUAXGHZwrI9qYzsGmlyQJpWA4lAWCtj6nUPlBQYpYhdv8LuuRD/I1hsRsmhzRBjCmxQ6a7q+Hhw5+XNGN8nit+2HePD5Qd48sdtTFm0h0n9mnNLj8Y6ObgA92xTcFDvdGNNui9ftZzCOzd3cXJkmjtwyzaFC2W3w9E4I0Hs+hXS9wICTfpA++uh3bCz3huhlGL1gXTe/n0fqw+kE+rvxaR+zbilRxM9YqsJqnpsu88wF5WQ5lcRyw7W7TlKWbnd7HA0zbVYLNCoOwx4Hu6Pg3vXwRWPQ95x+HUy/F8r+OJ62PQVFJ3+7GgRoXfzUL6Z2JPvJvakVT1/Xvp1J31fXcxHyw9QVFpuwpfSzsWtkwItrsJDldCmZBvrD+lnN2vaRQlrbSSF+9bDpBXQ5wGj9PDzPfBaC/jmZqNEUclYTT2ahfD1nT35/q5etK5vJIcrXlvCt+uO6Au2Gsa9k0KTPiirF3+zbWPe9mNmR6Np7kEE6neA/s/Bg1vhjt+h2x1GVdO3N8OUaFj4LKTtO23T7k3r8tUdPfl2Yk8aBHnz+KxtDHxjGXO3HcPVqrLdlXsnBU9fpElvBnrFM3d7sn64uaZVNxFj7KVBr8DDO+Cmb4xhNla9De90hU+uMcZsKiv+y2Y9m4Uw6+7eTBvbFasId3+1keHvrmTlvjSTvoh2gnsnBYAW/WlYehjPvAQ2HtFVSJrmNFYbtLkWxnwDk3fAVc8a7Q8/ToQp7WHxK5CbfHJ1EWFgdH3mPXQ5r43qSGpuMbd8tJZxn6xjX0quiV+kdnP/pNBuKArhJo9l/LYt+dzra5p28QLqQ9/JcF8c3DoLIrrA0v8ayeGHOyBh/clVrRZhdGwj/njkCp4e3JaNRzK5+o3lPPdLPFkFJSZ+idrJaUlBRD4RkRQR2X6G5SIib4nIPhHZKiLO6TMa1Bhp0Z9bPJayYFuirkLStEvJYjHuGbr5O7h/A3S/E/bMh4/7w0cDYOdsY/RXjIcA3dG3GUseuYIx3Rvx+epDXPF/S/hs1SFKdWP0JePMksKnwKCzLL8GaOmYJgLvOy2SruMILk+ndd4atiRmOe1jNE07i5DmRtvD5B1wzatG1dJ3t8I73WD9x1BaaKzm78VLwzvw24N9iW4YyLO/xHPNm8tZtifV5C9QOzgtKSillgEZZ1llGPC5MqwBgkSk8lslL1arQdj9wrnFtpi523UVkqaZyisAetwF92+EUdONYTd+nWz0WlryHygwThtt6gfy5YQeTBvbldJyO7d9so77vt5ISk6RyV/AvZnZphABJFR4n+iYV/2sHli6jOUKy2bitmzTXd80rSaw2ow7o+9cDON/NYb1XvIKvNEBFj0P+eknG6MXPHw5kwe0YsGO41z1v6V8tuoQ5boq2ClcoqFZRCaKSJyIxKWmXmARssttWLDTN28eWxJPv/tS0zSTiBhjK93yPdy9GloOhBVTHMnhOchPx8tm5YGrWrLgocuJaRzEs7/EM+K9lWzTv+VqZ2ZSOAo0qvA+0jHvNEqpaUqpWKVUbFhY2IV9WnAUZU2v5CbbEj5atvfC9qFpmnPVawejp8M9a4yhvle88WdyKMwkKtSPz2/vzttjOnMsu4hh767gpTk7KCzRQ2ZUFzOTwi/AbY5eSD2BbKWUU287tnX7Ow0knfIdc9ifmufMj9I07WKEt4FRn/w1ObzZCVa+iZQVc12nhiya3I8x3Rvz0YqDDHpzGav3p5sdtVtwZpfUb4DVQGsRSRSRCSIySUQmOVb5DTgA7AM+BO5xViwntR5Med0WPGL7ng8W73b6x2madpFOJIdJKyCyOyz8F7zdFTZ/TR0vCy+P6MA3d/YEYMyHa3jyx23kFp0+9pJWdc7sfTRGKdVAKeWhlIpUSn2slJqqlJrqWK6UUvcqpZorpToopZw/ZrDVhnXAczSXJGxbvyExs8DpH6lpWjWo3x5unQnjZoN/OPx0N0y9DPYuolfzEOY9eDl3XNaUb9cdYeCUZSzenWJ2xC7LJRqaq1WbIZQ06MoD1pl8sniH2dFomnY+ml4Od/4Boz+DsiL4aiR8fSM+uYd4ekg7Zt7dGz8vG3+fvp7J323Wd0RfgNqXFETwvPpF6ksmvps+0n2eNc3ViED0cLhnLQx4EQ6thPd6wsJn6VLPxq8PXMb9f2vBL1uS6P/6Mv7YddzsiF1K7UsKAFF9KIjqz0TLz3y9ZIvZ0WiadiFsnsYzHe7fAB1Gw8o34O1YvOJn8o8Brfj5vj6E+nty+6dxPPXjNgpKysyO2CXUzqQA+F7zIoFSgGXjJ+QX64NFM0e13INT2wXUg+HvGc91CGxojMr6ydVEW4/y0719uLNvU75ed4TBb61gc4Ie5uZcqpQURORBEQl0dB/9WEQ2ishAZwfnVPXakR8WwxX2tcyISzj3+prmBNVyD45miIw1EsOwdyF9H3zQF+9lL/PUwKZ8dUcPikvLGfn+Kt5ctFc/7e0sqlpSuF0plQMMBIKBscB/nBbVJeLXaTgdLQf5dfk6fcu8prkDiwU63wr3rocON8Dy/8H7vekt8cx96HKu69iAKYv2MGrqao6k696HlalqUhDHv9cCXyil4ivMc11trgOgfe5yFsTrgfI0zW34hcCI9+G2n0Ep+HwodeY/yBvDmvL2mM7sT81j8FvLmbtNP6b3VFVNChtEZAFGUpgvIgGA65e/Qlugwtoy1GsjH604aHY0mqZVt2ZXwD2r4bLJsOVbeL831/nv4rcH+tIszI+7v9rIv37eTlGpHibjhKomhQnA40A3pVQB4AH83WlRXULSdgid7Ds5ePiwflynprkjDx/o/yxMWAiefvDFCBqtepoZt3dkwmVN+Xz1YUa+v4pDaflmR1ojVDUp9AJ2K6WyRORW4GnAPYYnbDMEC3YGe2/my9WHzY5G0zRniewKdy2DXvdB3Cd4ftiXZzpk8eFtsSRmFjLk7RXM2ZpkdpSmq2pSeB8oEJFOwD+A/cDnTovqUmrQCeo0Zoz/VhbuOE5xmS5Gaprb8vCBq1+Gv/9mvJ9+LQOOvsuv93anZT1/7vt6E//6eTslZa5fO36hqpoUypTxZJphwDtKqXeBAOeFdQmJQJvBtC6Iw16cy4q9aWZHpGmaszXpDZNWQpfbYOWbRM4azvej63GHozrppmmrSc6unaMdVDUp5IrIExhdUX8VEQtGu4J7aHsdVnsJg7y386vujaBptYOXPwx9C274HDIO4vFhP56O3MI7Y2LYlZzLkLdXsPZA7RuOu6pJ4UagGON+hWSMB+K85rSoLrXGPcE3lNsCN+sqJE2rbdoNg7tXGlXJP01iyL5nmX1HBwK9bdz80Vo+Wn6gVj3Ct0pJwZEIvgLqiMgQoEgp5R5tCgAWK0SPoH3+KuxFuazcp6uQNK1WqRNpDMt95VOwfRbNZ13D7BFe9G8bzku/7uT+bzbVmuFwqjrMxQ3AOmA0cAOwVkRGOTOwS67DaKzlxQz13sSvW/WNbJpW61is0O8x+PtcUAq/LwcztfFiHr+6Jb9tO8aI91ZysBZ0W61q9dFTGPcojFNK3QZ0B55xXlgmaNQdghpzm986Fu5IrtW9DzStVmvcAyYth+jhyOKXmHToYb69qQmpucUMfXsFi3e59wN8qpoULEqpin+J9PPY1jWIQPtRtC7YgK0oQ1chaVpt5hMEIz+GYe9B0ia6zx/GwuHQOMSXCZ+td+t2hqqe2OeJyHwRGS8i44FfMZ6x7F46jMaiyrnea73uhaRptZ0IdL4FJi4G3xBCf7yRHzusZlA7o53hsZlb3bJTSlUbmh8FpgEdHdM0pdQ/nRmYKeq1g/BobvFbx/ztyXo8FE3TIKy18QjQ6OvxXPoy71pe49F+9ZixIZFbP1pLWl6x2RFWK1tVV1RK/QD84MRYaoYOo2j6+/PUKTnGop3HGdKxodkRabVYaWkpiYmJFBXVzhupqpO3tzeRkZF4eFzALVZe/jDyI2jUA5n/JPem7qTDoNe5c1E2w95ZyUfjYmnbILD6gzbBWZOCiOQClVWcCaCUUu7xV6io/Uj4/XnG+K7nx43ROilopkpMTCQgIICoqChEXH+0erMopUhPTycxMZGmTZte2E5EoMdEaNgZZozn8uW38PsVzzFybUtGT13Ne7d04fJWrv+gpLNWHymlApRSgZVMAVVJCCIySER2i8g+EXm8kuXjRSRVRDY7pjsu5stUi+Am0KgnN3iuZOmeFNLdrGiouZaioiJCQkJ0QrhIIkJISEj1lLgadTMG1ovqQ+SKJ1jcehZNg2zc/ul6vneDpzg6rQeRiFiBd4FrgHbAGBFpV8mq3ymlYhzTR86K57x0upGwwoO0VgeZs1U3OGvm0gmhelTr39EvBG6ZCX0fwXf71/zk/x8GRQmPzdzKlIV7XLpnkjO7lXYH9imlDiilSoBvMQbUq/miR4DVkzsD1zJr01Gzo9E0rSayWOGqZ2DUdKzHt/F23mQeapfHm7/v5dGZWyl10edAOzMpRAAVy1KJjnmnGikiW0Vkpog0qmxHIjJRROJEJC41NdUZsf6VTzC0voaB9hXEJ6SxPzXP+Z+paZpran89TFiAiJUHjzzAex33M3NDIrd/up7colKzoztvZt+ANhuIUkp1BBYCn1W2klJqmlIqVikVGxZ2iRpyOt6Eb2kG/azb+FmXFrRaKisri/fee++8t7v22mvJyso67+3Gjx/PzJkzz3s70zXoCBOXIBFduXbPM8yLXsTa/amMnrqalBzX6jlW5S6pF+AoUPHKP9Ix7ySlVMVxaT8CXnViPOenRX/wDeFOtY5HN/fm4QGtdN2uZqrnZ8ezIymnWvfZrmEgz14XfcblJ5LCPffc85f5ZWVl2GxnPn389pv73dt6Tn6hMPYnmPc4beI+ZnXUQa5OHM+oqav5ckIPGof4mh1hlTizpLAeaCkiTUXEE7gJ+KXiCiLSoMLbocBOJ8Zzfmye0H4U3YpXk52RRtxh/fxmrfZ5/PHH2b9/PzExMXTr1o2+ffsydOhQ2rUz+owMHz6crl27Eh0dzbRp005uFxUVRVpaGocOHaJt27bceeedREdHM3DgQAoLC6v02b///judO3emQ4cO3H777RQXF5+MqV27dnTs2JFHHnkEgBkzZtC+fXs6derE5ZdfXs1/hfNg84Qhr8Pg/xFybBnLQv+Ld2EyI6euYuex6k3oTqOUctoEXAvswXh851OOeS8AQx2vXwHigS3AYqDNufbZtWtXdckkxin1bKB65plH1OM/bLl0n6uZBohTTvxNnG2q7NjesWOHU75nVR08eFBFR0crpZRavHix8vX1VQcOHDi5PD09XSmlVEFBgYqOjlZpaWlKKaWaNGmiUlNT1cGDB5XValWbNm1SSik1evRo9cUXX5zx88aNG6dmzJihCgsLVWRkpNq9e7dSSqmxY8eqKVOmqLS0NNWqVStlt9uVUkplZmYqpZRq3769SkxM/Mu8ylzSv+eehUq9HKFKXm2lbn3xQ9Xh2Xlq/cH0S/f5p6jqse3UNgWl1G9KqVZKqeZKqZcd8/6llPrF8foJpVS0UqqTUupKpdQuZ8Zz3hp2gdBW3O5nPNBbD3uh1Xbdu3f/y81fb731Fp06daJnz54kJCSwd+/e07Zp2rQpMTExAHTt2pVDhw6d83N2795N06ZNadWqFQDjxo1j2bJl1KlTB29vbyZMmMCsWbPw9TWqZPr06cP48eP58MMPKS+vIb/Tlv3h9nl4WK18Js8w2Hsbt368tsaPsmp2Q3PNJgLd7iSqcAddS+L4o4b/Z2qu55L3rLtIfn5+J18vWbKERYsWsXr1arZs2ULnzp0rvTnMy8vr5Gur1UpZ2YU/rMZms7Fu3TpGjRrFnDlzGDRoEABTp07lpZdeIiEhga5du5KeXkMeo1m/PdzxO5aQFvy7+GUeDFzCnZ/H8fPmmtt5RSeFc+k6HlW3Gf/y+oafNhw2OxrNzSgzetadh4CAAHJzcytdlp2dTXBwML6+vuzatYs1a9ZU2+e2bt2aQ4cOsW/fPgC++OIL+vXrR15eHtnZ2Vx77bVMmTKFLVu2ALB//3569OjBCy+8QFhYGAkJNejO4sAG8Pe5SMuruTt/Kv8X/CMPfbeJz1YdMjuySjmz95F7sHki/Z+n2fdjCds3g/S8zoT4e517O01zAyEhIfTp04f27dvj4+NDvXr1Ti4bNGgQU6dOpW3btrRu3ZqePXtW2+d6e3szffp0Ro8eTVlZGd26dWPSpElkZGQwbNgwioqKUErx+uuvA/Doo4+yd+9elFJcddVVdOrUqdpiqRZe/nDTV/DbIwyP+4TwkCxu++VWikrLuatfc7Oj+wtRLnY7dmxsrIqLi7u0H6oUBR8MIO/YXhZeNZdbLq9stA7NHYjIBqVUrBmfXdmxvXPnTtq2bWtGOG7J9L+nUrD0VVjyb7b79WB0+l3cO7Aj9/2tpdM/uqrHtq4+qgoRfAe/QrhkYVn9ttnRaJrmqkTgin/CkClEF6xnbtD/8dGCDTVqvCSdFKqqUTcO1RvI8IKZLF+5zOxotItR7npDD7ibe++9l5iYmL9M06dPNzusSyf2duSGz2lSup/5gS8z4/fV/N+C3f/f3pmHV1VdC/y37pSbGTMBEhAQVCYVpKAi1OGJqFiKoqioaAvYvj6tr31UqGLVZ1ttrcVWPiegT8ABRPnEPi1QRMRXZRCQSRlU+AxhCNGEjDe5N+v9sU/CBRJJSO6QsH/ft7977jn77LXuvvvstYez144Lw2DnFJpAp1umU/r0xXRZdjff9PqQjIzMWKt0alL0NVSVmYVCHj+ktDfOyU5EdQWsnQkfzYAf/QNO6xpxVS31M2PGjFirEHt6XYfch7zMXQAAE4tJREFUvoicV2/m3ZRHufH9yVSHlKlXnxNT7wnWKDQBb7tOFI98kdzFY9k6ezwZv3zbdAdPZVShZB+kNXMzopoQrJ8DX30A51wL54wEr99cC1ZB/gbY8S5sfxcKjlnOkpZrNj8ZcIdxZhiqhsIvjF4ujwkHtsCqP5lzZ15uewuW+KDrEORH/yBt3g28pY8xblUFj9UoD17bK2aGwRqFJtL1guF8sOXnDPvqz+x842F6XjcZfMltxzjUdl8b83uqK+Htn8Om16DHlXDlI9A+zI9OY9Pa8y9491ewfzMkpMPWN8HfDnoOh2+/gn2fQqgKxA1dh8CA8ZCSYyr2qlLY9hYsewjefxxO6waFO038Y+lyEdwwy6RhscQL7fsgP16Kf84oXtMnGP+vah53C1NGxKbHYI3CSXDRuGl88MQ6hm2ZDlumAwL+dOj9Axh0t1mwEmm+WgXJ2ZBzTvPTqq6EL1fAtsWw/R0zzJLS3lS8nQfBJf9pjsM5vA/mj4O9n0C/G2HnUnh2iHEj7PLAgW1waDtojTGa3mTwJYEn0fQAVCFQYkJJvmntj/kb9B5legsb5sIX70HWWTD4bug0ELp/3/QEjmXQRGNQVj8PJfvNStKcPpCea+TXBMGfZlaotxXjbWlbtOuC3PUu3jk/ZM6hPzJpVRVPuW/kl8PPjroq1iicBF6Pm5w7ZjFt1p/JdpVyy/kZZIcOwqbXzRBIl4th4I+g10jwJh6fQKDEDIcc3geeBDMu7k2ExHam0kvKMhVofYSqYdlv4OMZIC4zZHLZA8dX2scSDMCOJZC/HvI3wsFtZlw+GIAaZyglIR3OHmEMQulBU1mvfh4++R+48Kem8i/8Ag5+ButmQeVhGDsPel0H5d+Y4Zm1MyEpE3J6mUrc7YPqctOir64wBqi6zOie3gkSUk3F/72JR37zmZeZ0BQ69INRzzTtHoslnkjtgNz5v3jmjWbmvqe45/0Af3Hfwb1XRP511XDsOoVmsONACeNnr6G0Msjzd1zAxR1dsGGeqRiL9phKtt8NkN7ZVLKlB8x4eMHnpgXbEC4P9PqBqYhzv3ekdVt6EF6/C/Z8CN+bYOKtnWla3/1vgy6DTfy0TkfuCQXh01dh5RNQ/LW5J6c3dDjXGCG3zxim3IHQdZiZvA3n0C5Y8VszpBNO+74w+vnje0Wqrbo1btcpHE1RURGvvPLKca6zG8P06dOZNGlSnX+i+ujatSvr1q0jKyurOWo2mljnZ6OoLEZfvgn9eg2TqyZx5vCJ/PulPZqdbGPLtjUKzSS/qILxs9ewp7Cce6/owYSh3fG7xVTcG+aZ8e5gJfhSTWs+o5sZCskdaMa/Q1XmenU5VBRBxbemFb/hZQgUQ/t+pgVddshMkqrCdU/DeWONAod2wj8fhp3LIGRcC+NvB6kdIbU9FOdB4S4zdHLZr6Hr0CMTuE1h/2YTss6G7LPNCs02SFwbhXenmP+gJenQD65+vMHLu3fvZuTIkWzZsqXJSTemwrdGoQGqytBXb0W+ep8Hq+/ijKvuZeKw7s1KsrFl2w4fNZPT2yXy+k8uYuqbm3ly6Q5e/ySPh0b25opew6DbMBg5HVAzrt4ULnvATOBufgPcXuh4ntn4Z8AdR7fOs3qa5fPBKvOGTd5a0xMpPWjG15My4d8eNm/zNKcF36GfCZZTivD9FK688kpycnJYsGABgUCA0aNH88gjj1BWVsZNN91EXl4eoVCIadOmceDAAfLz87nsssvIyspixYoVJ5T11FNPMXv2bAAmTJjAfffdV2/aY8eOZcqUKSxevBiPx8Pw4cN58sknI50V0cWXjNw6n5oF43ls59/4/ZJK/ua+n7uGdDvxvc2lMf614ylEdT+FJrJqR4Fe/uQKPeP+v+ulf1yhj769Vf9vV4FWBUOxVs3SSLD7KRxF+H4KS5Ys0YkTJ2pNTY2GQiG99tprdeXKlbpw4UKdMGFC3T1FRUWqemRPhe+iNs66deu0b9++WlpaqiUlJdq7d29dv359vWk3tKdCY4h1fjaZYJWG5o9X/U2a/uHXE3TOR7tPOqnGlm27orkFuaRnFv+4bxi/v74fnTOSmPvRHm59cTUX/m45D721hU/2fBsXKxYtlpNh6dKlLF26lP79+zNgwAA+//xzdu7cSb9+/Vi2bBn3338/q1atIj09vclpf/jhh4wePZrk5GRSUlK4/vrrWbVqVb1pN7SnQpvE7cU1Zhahvjcy2buA/W8/xsJP8iIq0g4ftTBet4tbBnXhlkFdKAsEWbWzgLc37WP+2q+Z89EeclITuLB7Jhd2z2RQt9PolpWC29V6J2Ytpw6qytSpU7n77ruPu7Z+/XreeecdHnzwQa644goeeuihFpF51lln1Zv2mjVrWL58OQsXLuSZZ57hvffeaxF5cYnLjfv65wkBk7cs4E+LYIn/v7mqT4eIiLNGIYIkJ3gY0bcjI/p2pKSymiVbD/DBjgI+/rKQxZ/mA5Dkc9Pn9DT6nJ7OmTkp9MhOoUdOCtmp1j23JfaE76dw1VVXMW3aNMaNG0dKSgp79+7F6/USDAbJyMjgtttuo127dsycOfOoexsziTx06FDuvPNOpkyZgqqyaNEi5s6dS35+/nFpl5aWUl5ezjXXXMOQIUPo3r15E7CtAscwBFX55dYFPPWakDL+dwzp0fIT9NYoRIlUv5cxF+Qy5oJcVJUvD5Wxfs+3bM0/zOa9xSxY9zXlVUe2EeyQ5ufc3HTO69yO3qen0adjGtmpCTH1iWI59QjfT+Hqq6/m1ltv5aKLLgIgJSWFefPmsWvXLiZPnozL5cLr9fLss88CMGnSJEaMGMHpp59+wonmAQMGcOeddzJo0CDATDT379+fJUuWHJd2SUlJvXsqtHlcbjw3vECVwi+2zefpOZA04Qn6d6lnQWczsK+kxgmqyv7Dlew6WMr2/SVs3lvMprxivjpUVhcnM9lH9+xkOmckcUZGMtmpCaQlekjze2mf5qdrVhIJnkY4hrM0SFy/kmppNm0iP2tCVC6YiP/zN/grN3PlT/7IOR3STnibfSW1lSEidExPpGN6IkN7HtmWsbiims/3HWbbvsNsyz/Mnm/K+eiLQhZt2Mux9tztEs7ITKJrZjIZyT4yk31kJPtIT/SakOQlJzWB7BQ/aYke2+uwWFojLjf+m16kbL5yz/bX+OsLHhJ/9gfOyGzia+8NYI1CnJOe6GVw90wGdz/aTXcgGKKovJriChPyiyrYeaCUXQdL+frbcj7bd5jC0iqqQvWvnPZ5XKQmeEj0uUn2eUj1m5CW6CUj2UeHND8d0v2cluQjyecm0ecmzW+uJfnc1qBYmsTgwYMJBAJHnZs7dy79+tm1LyeFy03y2JmUvBLinl3zmP6cn1vu+S3t005iYeoxRNQoiMgI4GnADcxU1cePuZ4AzAEuAAqBsaq6O5I6tRUSPG7ap7m/sxCoKmVVIWM4yqspKq+ioDRAQUmAgtIAZYEg5YEQpYEgpYEgBaUBvigo41Bp4Kj5jeNlu+p6IGmJXlITPNSoElKoqVGSfG5z3u8h2VdreNwkJZjvyQlu/F43HpfgcbvwuV2k+j2kOEbK4xLcLrGGx0FVW31erF69OtYqtL3XwV1uUm+ZRfGcSu7bM5Ppz/q5696HSU/0NivZiBkFEXEDM4ArgTxgrYgsVtVtYdF+DHyrqj1E5GbgCWBspHQ61RARUhJMZdupXT2O+RpAVSkJBDlQXElRRTXlVSEqqkIcrqzmm7KqulBcUc3himr2H67EJaYidwkcKg1QUhnkcEU1ZVVBak7yWXS7BJ/bhc9jQoITfB43qkp1qIZgjZLk85CdmkB2SgLJCW6qQ0qopgaX8/tT/V6SfG5CqoRqTLhpYGc6pDe/VRVp/H4/hYWFZGZmtnrDEEtUlcLCQvz++P/Pm4TbS/rtc/lm9o3cu3cGzzyXyE/u+TU+z8kvQYtkT2EQsEtVvwQQkdeAUUC4URgFPOwcLwSeERHRNmfSWxciQprfS5q/eS0OMA9jIFhDeVWIskCQsqogZYEggWpToYdqlMrqI72V8qpQXcUdrKmhKmhCIOwzEAwhYgyGxy2UBYIUlATYdaCE8uoQHpcLr1sI1qjpDdXT6xnaM6tVGIXc3Fzy8vIoKCiItSqtHr/fT25ubqzVaHk8CWTcNZ9DL4zitrKFeJkMnPwr7ZE0Cp2Ar8O+5wGDG4qjqkERKQYygUPhkURkEjAJoEuXLpHS1xIBRAS/1wwXZST7TnxDBAiGaqhwjIXLhflsJY1ur9dLt25R8Hdjad14E8ma8KazTW3z1ji1CjcXqvqCqg5U1YHZ2dknvsFiCcPjdpHq95Loc5Pgcdv5CkvbJCHFeEZuJpE0CnuBzmHfc51z9cYREQ+QjplwtlhOCURkkoisE5F1dojIEg9E0iisBXqKSDcR8QE3A4uPibMYGO8cjwHes/MJllMJ2wu2xBsRXdEsItcA0zGvpM5W1d+KyKMYF66LRcQPzAX6A98AN9dOTH9HmgXAngYuZ3HMfESUiaX8U1V2S8s/Q1VjUjvHedmuJV70AKtLQzSkS6PKdqtzc/FdiMi6WLkoiLX8U1V2PMiPBvHyG+NFD7C6NERzdWkVE80Wi8ViiQ7WKFgsFouljrZmFF44heWfqrLjQX40iJffGC96gNWlIZqlS5uaU7BYLBZL82hrPQWLxWKxNANrFCwWi8VSR5sxCiIyQkS2i8guEZkSYVmzReSgiGwJO5chIstEZKfz2bJ75B2R01lEVojINhHZKiI/j7J8v4isEZFPHfmPOOe7ichqJ//nOwsWI4KIuEVkg4j8Pdqyo000y3UD8neLyGYR2Sgi65xz0SprjX7OxPAXJ582iciAKOjysIjsdfJmo7Muq/baVEeX7SJyVQvq0aTn/6TyRVVbfcAsjvsC6A74gE+B3hGUNwwYAGwJO/cHYIpzPAV4IkKyOwIDnONUYAfQO4ryBUhxjr3AauBCYAFm8SHAc8BPI5j/vwBeAf7ufI+a7GiGaJfrBnTYDWQdcy5aZa3RzxlwDfCuUz4vBFZHQZeHgf+qJ25v579KALo5/6G7hfRo0vN/MvnSVnoKdW66VbUKqHXTHRFU9QPMCuxwRgEvOccvAT+MkOx9qrreOS4BPsN4m42WfFXVUuer1wkKXI5xfx5R+SKSC1wLzHS+S7Rkx4ColusmEK2y1pTnbBQwxymfHwPtRKRjhHVpiFHAa6oaUNWvgF2Y/7Il9Gjq89/kfGkrRqE+N92doqxDe1Xd5xzvB5rvrvAEiEhXjIuQ1dGU7wzfbAQOAsswLaEiVQ06USKZ/9OBXwG1+4xmRlF2tImHcq3AUhH5RIwLe4hBWQ+jIdmxyqv/cIZlZocNo0VFl0Y+/03Wpa0YhbhCTb8tou/6ikgK8AZwn6oejqZ8VQ2p6vkYz7eDgHMiJSscERkJHFTVT6IhzwLAJao6ALga+JmIDAu/GI2y3hCxlO3wLHAmcD6wD/hTtARH8vlvK0ahMW66I82B2m6Z83kwUoJExIspEC+r6pvRll+LqhYBK4CLMN3S2k2bIpX/Q4AfiMhuzFDK5Zg9wKMhOxbEvFyr6l7n8yCwCNMIiHpZC6Mh2VHPK1U94DSQaoAXOTJEFFFdmvj8N1mXtmIUGuOmO9KEuwEfD7wVCSHOGPos4DNVfSoG8rNFpJ1znIjZg/szjHEYE0n5qjpVVXNVtSvmP35PVcdFQ3aMiGm5FpFkEUmtPQaGA1uIUllrgIZkLwbucN62uRAoDhtOiQjHjM2PxuRNrS43i0iCiHQDegJrWkhmU5//pudLS87QxzJgZtl3YMa3H4iwrFcx3cVqzBjdjzFj28uBncA/gYwIyb4E0zXcBGx0wjVRlH8usMGRvwV4yDnfHVPwdwGvAwkR/g8u5cjbR1GVHc0QzXJdj+zumLdoPgW21sqPYllr9HOGebtmhpNPm4GBUdBlriNrk1P5dgyL/4Cjy3bg6hbUo0nP/8nki3VzYbFYLJY62srwkcVisVhaAGsULBaLxVKHNQoWi8ViqcMaBYvFYrHUYY2CxWKxWOqwRsGCiFwqjsdRi6WtYMv1yWGNgsVisVjqsEahFSEit4nZy2CjiDzvOKYrFZE/O77Vl4tIthP3fBH52HHWtSjMv3oPEfmnmP0Q1ovImU7yKSKyUEQ+F5GXnZWTFkvEseU6vrBGoZUgIr2AscAQNc7oQsA4IBlYp6p9gJXAb5xb5gD3q+q5mJWMtedfBmao6nnAxZhVmmC8Ld6H8c3eHeNnyGKJKLZcxx+eE0exxAlXABcAa53GTiLG6VUNMN+JMw94U0TSgXaqutI5/xLwuuPHppOqLgJQ1UoAJ701qprnfN8IdAU+jPzPspzi2HIdZ1ij0HoQ4CVVnXrUSZFpx8Q7Wb8lgbDjELZsWKKDLddxhh0+aj0sB8aISA7U7cl6BuY/rPUQeivwoaoWA9+KyFDn/O3ASjU7NeWJyA+dNBJEJCmqv8JiORpbruMMazVbCaq6TUQexOyC5cJ4a/wZUAYMcq4dxIzPgnGf+5zzcHwJ3OWcvx14XkQeddK4MYo/w2I5Cluu4w/rJbWVIyKlqpoSaz0slpbEluvYYYePLBaLxVKH7SlYLBaLpQ7bU7BYLBZLHdYoWCwWi6UOaxQsFovFUoc1ChaLxWKpwxoFi8VisdTx/xi9fW93ztXOAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture-2"
      ],
      "metadata": {
        "id": "FgpkLCwlwbIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5= keras.Sequential()\n",
        "model_5.add(tf.keras.layers.Dense(units=32,input_shape=(20,),activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=16,activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=8,activation='relu'))\n",
        "model_5.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_5.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_5.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlm76cwtwWHn",
        "outputId": "c44022b6-f4a6-44bf-cbff-f8e6c20a3e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 32)                672       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,372\n",
            "Trainable params: 1,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_5=model_5.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdblQbaxx9P3",
        "outputId": "06fa0de9-e665-4589-f3b6-a6cb8e94eed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.2739 - accuracy: 0.3681 - val_loss: 1.1144 - val_accuracy: 0.4675\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8876 - accuracy: 0.5987 - val_loss: 0.7028 - val_accuracy: 0.6900\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8275 - val_loss: 0.4274 - val_accuracy: 0.8550\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8988 - val_loss: 0.3363 - val_accuracy: 0.8400\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9125 - val_loss: 0.2785 - val_accuracy: 0.8800\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9375 - val_loss: 0.2600 - val_accuracy: 0.8850\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9431 - val_loss: 0.2342 - val_accuracy: 0.9075\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9550 - val_loss: 0.2565 - val_accuracy: 0.8850\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9631 - val_loss: 0.2757 - val_accuracy: 0.8650\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9656 - val_loss: 0.2327 - val_accuracy: 0.8950\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9694 - val_loss: 0.2492 - val_accuracy: 0.8875\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9712 - val_loss: 0.2428 - val_accuracy: 0.8975\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.2706 - val_accuracy: 0.8875\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.2433 - val_accuracy: 0.8950\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9856 - val_loss: 0.2660 - val_accuracy: 0.8975\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9881 - val_loss: 0.2951 - val_accuracy: 0.8950\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.2712 - val_accuracy: 0.8875\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.2702 - val_accuracy: 0.8925\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9906 - val_loss: 0.2813 - val_accuracy: 0.9025\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9956 - val_loss: 0.3152 - val_accuracy: 0.8975\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9956 - val_loss: 0.2771 - val_accuracy: 0.9075\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9962 - val_loss: 0.3029 - val_accuracy: 0.8950\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9975 - val_loss: 0.3155 - val_accuracy: 0.9025\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.2954 - val_accuracy: 0.9025\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9981 - val_loss: 0.3239 - val_accuracy: 0.8925\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9075\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9981 - val_loss: 0.3383 - val_accuracy: 0.9050\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9025\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.8950\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9994 - val_loss: 0.3441 - val_accuracy: 0.8950\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9050\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.8975\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9050\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9025\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9100\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9050\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9075\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9025\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9075\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.8975\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9025\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9000\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9000\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9000\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9050\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9000\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8975\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.8975\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.9822e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9000\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.8975\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6474e-04 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9025\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.4441e-04 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.9025\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.1383e-04 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.9000\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9021e-04 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.8950\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2646e-04 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.8975\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8901e-04 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.9050\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.1940e-04 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9025\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9650 - val_loss: 0.7281 - val_accuracy: 0.8750\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.5251 - val_accuracy: 0.8900\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.4869 - val_accuracy: 0.9025\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9025\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8975\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.8891e-04 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9000\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9780e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9025\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.2803e-04 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.8975\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7217e-04 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9000\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2761e-04 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9000\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6953e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9000\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2868e-04 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8419e-04 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5430e-04 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0403e-04 - accuracy: 1.0000 - val_loss: 0.5209 - val_accuracy: 0.9000\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8299e-04 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5143e-04 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.8975\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1754e-04 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8975\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9530e-04 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8975\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7402e-04 - accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.9025\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5714e-04 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9000\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2703e-04 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9025\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1182e-04 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.9025\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 2.9053e-04 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9025\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7668e-04 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8975\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 2.6643e-04 - accuracy: 1.0000 - val_loss: 0.5517 - val_accuracy: 0.9000\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4226e-04 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9025\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.3562e-04 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.9050\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 2.1784e-04 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9000\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0491e-04 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.9075\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9747e-04 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.9075\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8750e-04 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.9050\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7655e-04 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.9050\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6511e-04 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.9025\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5146e-04 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9025\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4195e-04 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9025\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3917e-04 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.9025\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2636e-04 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1716e-04 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.9100\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0949e-04 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.9050\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0182e-04 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.9050\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.6163e-05 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9075\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.2161e-05 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.9075\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4324e-05 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.9000\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.9378e-05 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.9125\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6667e-05 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.9100\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.0028e-05 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 0.9100\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3662e-05 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.9100\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0277e-05 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.9050\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5241e-05 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.9100\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 5.0234e-05 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.9050\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 4.8184e-05 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.9075\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 4.1496e-05 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.9075\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 4.0190e-05 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.9075\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.6724e-05 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.9100\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5949e-05 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.9050\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2157e-05 - accuracy: 1.0000 - val_loss: 0.6827 - val_accuracy: 0.9075\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8858e-05 - accuracy: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.9050\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7000e-05 - accuracy: 1.0000 - val_loss: 0.6986 - val_accuracy: 0.9075\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4447e-05 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.9075\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3037e-05 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.9050\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1510e-05 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.9075\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8695e-05 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.9100\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7447e-05 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.9075\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6078e-05 - accuracy: 1.0000 - val_loss: 0.7518 - val_accuracy: 0.9025\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4512e-05 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.9050\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3344e-05 - accuracy: 1.0000 - val_loss: 0.7430 - val_accuracy: 0.9075\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2175e-05 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.9050\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0914e-05 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.9075\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0444e-05 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.9100\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.4186e-06 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.9025\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.3716e-06 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.9050\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7696e-06 - accuracy: 1.0000 - val_loss: 0.7954 - val_accuracy: 0.9050\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3108e-06 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.9025\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5389e-06 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.9075\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.1321e-06 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.9050\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3812e-06 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.9050\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3234e-06 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.9025\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3412e-06 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.9075\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2006e-06 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.9025\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8254e-06 - accuracy: 1.0000 - val_loss: 0.8417 - val_accuracy: 0.9025\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5706e-06 - accuracy: 1.0000 - val_loss: 0.8482 - val_accuracy: 0.9050\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4712e-06 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.9050\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0129e-06 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.9050\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6269e-06 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.9100\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4755e-06 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.9050\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2032e-06 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.9025\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9862e-06 - accuracy: 1.0000 - val_loss: 0.8605 - val_accuracy: 0.9075\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9345e-06 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.9125\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7649e-06 - accuracy: 1.0000 - val_loss: 0.8693 - val_accuracy: 0.9100\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5508e-06 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.9050\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4840e-06 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.9050\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3793e-06 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.9050\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2139e-06 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.9075\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1290e-06 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.9075\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0680e-06 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.9100\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.3139e-07 - accuracy: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.9075\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1986e-07 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.9075\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7113e-07 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.9075\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7413e-07 - accuracy: 1.0000 - val_loss: 0.9280 - val_accuracy: 0.9075\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6206e-07 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.9075\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2279e-07 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.9025\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3979e-07 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9050\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8928e-07 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.9025\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5523e-07 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.9025\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1984e-07 - accuracy: 1.0000 - val_loss: 0.9893 - val_accuracy: 0.9025\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8020e-07 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.9050\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5025e-07 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.9050\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1553e-07 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.9025\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9854e-07 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9000\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5652e-07 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.9025\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4982e-07 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.9050\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1867e-07 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9025\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0593e-07 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.9025\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7911e-07 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.9025\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6846e-07 - accuracy: 1.0000 - val_loss: 1.0502 - val_accuracy: 0.9000\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7799e-07 - accuracy: 1.0000 - val_loss: 1.0421 - val_accuracy: 0.9025\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4231e-07 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.9050\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3173e-07 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.9025\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2070e-07 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.9050\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1094e-07 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9025\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.9391e-08 - accuracy: 1.0000 - val_loss: 1.0598 - val_accuracy: 0.9025\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.3654e-08 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9025\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1435e-08 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 0.9000\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7039e-08 - accuracy: 1.0000 - val_loss: 1.0781 - val_accuracy: 0.9050\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2718e-08 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.9025\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6161e-08 - accuracy: 1.0000 - val_loss: 1.0862 - val_accuracy: 0.9050\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8115e-08 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.9025\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3570e-08 - accuracy: 1.0000 - val_loss: 1.1154 - val_accuracy: 0.9000\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0664e-08 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.9025\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.9621e-08 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.9025\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3139e-08 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.9025\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9041e-08 - accuracy: 1.0000 - val_loss: 1.1284 - val_accuracy: 0.9000\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6210e-08 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.9025\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5167e-08 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.9025\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9057e-08 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.9025\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8163e-08 - accuracy: 1.0000 - val_loss: 1.1505 - val_accuracy: 0.9025\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5705e-08 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.9025\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3469e-08 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.9025\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2724e-08 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.9050\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1905e-08 - accuracy: 1.0000 - val_loss: 1.1695 - val_accuracy: 0.9025\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7956e-08 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.9025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture-3"
      ],
      "metadata": {
        "id": "fF99jg2zybXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6= keras.Sequential()\n",
        "model_6.add(tf.keras.layers.Dense(units=24,input_shape=(20,),activation='relu'))\n",
        "model_6.add(tf.keras.layers.Dense(units=16,activation='relu'))\n",
        "model_6.add(tf.keras.layers.Dense(units=8,activation='relu'))\n",
        "model_6.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_6.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_6.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zWQQpiayeOm",
        "outputId": "b8832a4e-7de3-4390-f4af-8f825d351792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 24)                504       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 16)                400       \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,076\n",
            "Trainable params: 1,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_6=model_6.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rXtmnYW-pu3",
        "outputId": "55c5ce4d-d763-42b5-c857-eadbccaadbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7494e-07 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.9250\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5713e-07 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.9225\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3113e-07 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.9250\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2495e-07 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.9200\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.1683e-07 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.9225\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1012e-07 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.9225\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.9391e-08 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.9225\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2241e-07 - accuracy: 1.0000 - val_loss: 0.7571 - val_accuracy: 0.9175\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.7752e-08 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.9225\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4713e-08 - accuracy: 1.0000 - val_loss: 0.7643 - val_accuracy: 0.9200\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.6161e-08 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.9225\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.4298e-08 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.9250\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.8860e-08 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.9225\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0440e-08 - accuracy: 1.0000 - val_loss: 0.7786 - val_accuracy: 0.9225\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7609e-08 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.9225\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.4331e-08 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.9225\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.9935e-08 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.9200\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 3.7551e-08 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.9225\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.6359e-08 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.9225\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.2336e-08 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.9200\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 3.2932e-08 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.9200\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6450e-08 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.9200\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5555e-08 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.9225\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6301e-08 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.9225\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0862e-08 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9225\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0191e-08 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.9225\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8105e-08 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.9250\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8477e-08 - accuracy: 1.0000 - val_loss: 0.8373 - val_accuracy: 0.9225\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6689e-08 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.9225\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5199e-08 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.9200\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5497e-08 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.9250\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4231e-08 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.9225\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1176e-08 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.9225\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9856 - val_loss: 1.3812 - val_accuracy: 0.9125\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9825 - val_loss: 1.1313 - val_accuracy: 0.9225\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.0118 - val_accuracy: 0.9225\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 1.0039 - val_accuracy: 0.9225\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.0676 - val_accuracy: 0.9125\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3022e-04 - accuracy: 1.0000 - val_loss: 1.0202 - val_accuracy: 0.9200\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5866e-05 - accuracy: 1.0000 - val_loss: 1.0249 - val_accuracy: 0.9150\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1238e-05 - accuracy: 1.0000 - val_loss: 1.0258 - val_accuracy: 0.9150\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8296e-05 - accuracy: 1.0000 - val_loss: 1.0257 - val_accuracy: 0.9150\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.6129e-05 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.9150\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.4544e-05 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.9150\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.3193e-05 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.9150\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.2151e-05 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.9150\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.1196e-05 - accuracy: 1.0000 - val_loss: 1.0249 - val_accuracy: 0.9150\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.0363e-05 - accuracy: 1.0000 - val_loss: 1.0245 - val_accuracy: 0.9150\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 9.6282e-06 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.9150\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 8.9705e-06 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.9150\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 8.3718e-06 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.9150\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 7.8497e-06 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.9150\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 7.3715e-06 - accuracy: 1.0000 - val_loss: 1.0205 - val_accuracy: 0.9150\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 6.9328e-06 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.9150\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 6.5268e-06 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.9150\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 6.1466e-06 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9150\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 5.8284e-06 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.9150\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 5.4803e-06 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.9150\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 5.1730e-06 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.9150\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 4.9026e-06 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.9125\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 4.6440e-06 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.9125\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 4.3946e-06 - accuracy: 1.0000 - val_loss: 1.0115 - val_accuracy: 0.9125\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 4.1585e-06 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.9125\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 3.9326e-06 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.9125\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 3.7364e-06 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.9100\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 3.5362e-06 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.9075\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 3.3556e-06 - accuracy: 1.0000 - val_loss: 1.0051 - val_accuracy: 0.9075\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 3.1833e-06 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.9075\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 3.0205e-06 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.9075\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 2.8604e-06 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.9075\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.7095e-06 - accuracy: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.9100\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.5778e-06 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.9100\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.4384e-06 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.9100\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.3195e-06 - accuracy: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.9100\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 2.2049e-06 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.9100\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 2.0896e-06 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.9100\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.9891e-06 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.9100\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8951e-06 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.9075\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8051e-06 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9075\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7204e-06 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.9075\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6427e-06 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.9075\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5581e-06 - accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 0.9075\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4863e-06 - accuracy: 1.0000 - val_loss: 0.9804 - val_accuracy: 0.9075\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4124e-06 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.9075\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3525e-06 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.9075\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2900e-06 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.9075\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2285e-06 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.9075\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1728e-06 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.9075\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1185e-06 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.9075\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0715e-06 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.9075\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0191e-06 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.9075\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.7921e-07 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.9075\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.2691e-07 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.9075\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9525e-07 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9075\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.5151e-07 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9075\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1724e-07 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.9075\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8036e-07 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.9075\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5190e-07 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.9075\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.1555e-07 - accuracy: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.9075\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.8515e-07 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9075\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5512e-07 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.9075\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2473e-07 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9075\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0319e-07 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.9075\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7585e-07 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.9075\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5275e-07 - accuracy: 1.0000 - val_loss: 0.9503 - val_accuracy: 0.9075\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3294e-07 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.9075\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0597e-07 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.9100\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8130e-07 - accuracy: 1.0000 - val_loss: 0.9498 - val_accuracy: 0.9100\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.6171e-07 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.9100\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.4234e-07 - accuracy: 1.0000 - val_loss: 0.9506 - val_accuracy: 0.9100\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2185e-07 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.9100\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0546e-07 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.9100\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8408e-07 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.9100\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.6612e-07 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.9100\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5032e-07 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.9100\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3520e-07 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.9100\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1732e-07 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.9100\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0547e-07 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.9100\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8640e-07 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.9100\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7500e-07 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.9100\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6010e-07 - accuracy: 1.0000 - val_loss: 0.9467 - val_accuracy: 0.9100\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4825e-07 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.9100\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3760e-07 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 0.9100\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2531e-07 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.9100\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1465e-07 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.9100\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0407e-07 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.9075\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9357e-07 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.9075\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8537e-07 - accuracy: 1.0000 - val_loss: 0.9481 - val_accuracy: 0.9075\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7479e-07 - accuracy: 1.0000 - val_loss: 0.9442 - val_accuracy: 0.9075\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6630e-07 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.9075\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5862e-07 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.9075\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4953e-07 - accuracy: 1.0000 - val_loss: 0.9463 - val_accuracy: 0.9075\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4164e-07 - accuracy: 1.0000 - val_loss: 0.9448 - val_accuracy: 0.9075\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 0.9449 - val_accuracy: 0.9075\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2882e-07 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9075\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1973e-07 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.9075\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1310e-07 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.9075\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0759e-07 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.9075\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0103e-07 - accuracy: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.9075\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.6857e-08 - accuracy: 1.0000 - val_loss: 0.9529 - val_accuracy: 0.9075\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.0823e-08 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.9150\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.5160e-08 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.9100\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.0764e-08 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9150\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.7635e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9100\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.1824e-08 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.9150\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7279e-08 - accuracy: 1.0000 - val_loss: 0.9563 - val_accuracy: 0.9150\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3255e-08 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.9150\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0201e-08 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.9150\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6699e-08 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.9150\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3346e-08 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.9150\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.9546e-08 - accuracy: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.9175\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.6864e-08 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.9150\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.4703e-08 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.9150\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1500e-08 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.9150\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9414e-08 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.9150\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7327e-08 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9175\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4645e-08 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.9150\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2708e-08 - accuracy: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.9175\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1218e-08 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.9175\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9132e-08 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.9175\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7791e-08 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.9175\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5555e-08 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9175\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4438e-08 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.9175\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2948e-08 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9175\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1905e-08 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.9175\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0042e-08 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9175\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8850e-08 - accuracy: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.9175\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7509e-08 - accuracy: 1.0000 - val_loss: 0.9779 - val_accuracy: 0.9175\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6913e-08 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.9175\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5572e-08 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.9175\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5050e-08 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.9175\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3635e-08 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.9175\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3039e-08 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 0.9175\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2219e-08 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.9200\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1399e-08 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.9200\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0803e-08 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.9200\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.9093e-09 - accuracy: 1.0000 - val_loss: 0.9839 - val_accuracy: 0.9175\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.4622e-09 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.9175\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.1642e-09 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.9175\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.8976e-09 - accuracy: 1.0000 - val_loss: 0.9910 - val_accuracy: 0.9175\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.0466e-09 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.9175\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.9175\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 0.9949 - val_accuracy: 0.9175\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3016e-09 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.9150\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7369e-09 - accuracy: 1.0000 - val_loss: 0.9950 - val_accuracy: 0.9175\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6624e-09 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.9175\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0664e-09 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.9175\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0664e-09 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.9175\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3958e-09 - accuracy: 1.0000 - val_loss: 1.0079 - val_accuracy: 0.9175\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0233e-09 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.9175\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5449e-09 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.9175\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.0978e-09 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.9175\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.9175\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7998e-09 - accuracy: 1.0000 - val_loss: 1.0272 - val_accuracy: 0.9175\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2037e-09 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.9175\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8743e-09 - accuracy: 1.0000 - val_loss: 1.0183 - val_accuracy: 0.9175\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.9125\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9057e-09 - accuracy: 1.0000 - val_loss: 1.0229 - val_accuracy: 0.9125\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9057e-09 - accuracy: 1.0000 - val_loss: 1.0297 - val_accuracy: 0.9150\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8312e-09 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.9150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture-4"
      ],
      "metadata": {
        "id": "WtPX-1opNpbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_7= keras.Sequential()\n",
        "model_7.add(tf.keras.layers.Dense(units=20,input_shape=(20,),activation='relu'))\n",
        "model_7.add(tf.keras.layers.Dense(units=16,activation='relu'))\n",
        "model_7.add(tf.keras.layers.Dense(units=8,activation='relu'))\n",
        "model_7.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_7.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "print(model_7.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI4fuW2gNH1S",
        "outputId": "74cf3508-106a-4853-b254-517374c7a8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 16)                336       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 928\n",
            "Trainable params: 928\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_7=model_7.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdJxuNdcQO5W",
        "outputId": "a762ee29-e92c-4fb9-c979-6abb0c579116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 2s 6ms/step - loss: 1.3469 - accuracy: 0.3363 - val_loss: 1.2563 - val_accuracy: 0.4400\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 1.1059 - accuracy: 0.5250 - val_loss: 0.9448 - val_accuracy: 0.5575\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.6594 - val_loss: 0.6456 - val_accuracy: 0.7000\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5346 - accuracy: 0.7806 - val_loss: 0.4698 - val_accuracy: 0.8150\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.4024 - accuracy: 0.8494 - val_loss: 0.4000 - val_accuracy: 0.8425\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.3209 - accuracy: 0.8806 - val_loss: 0.3288 - val_accuracy: 0.8850\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.2636 - accuracy: 0.9019 - val_loss: 0.2814 - val_accuracy: 0.8900\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.2233 - accuracy: 0.9169 - val_loss: 0.2637 - val_accuracy: 0.8875\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.1961 - accuracy: 0.9244 - val_loss: 0.2611 - val_accuracy: 0.8875\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9344 - val_loss: 0.2285 - val_accuracy: 0.9050\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9463 - val_loss: 0.2515 - val_accuracy: 0.9100\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9506 - val_loss: 0.2344 - val_accuracy: 0.8950\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9594 - val_loss: 0.2409 - val_accuracy: 0.9100\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1149 - accuracy: 0.9625 - val_loss: 0.2318 - val_accuracy: 0.9050\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1023 - accuracy: 0.9688 - val_loss: 0.2252 - val_accuracy: 0.9050\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9719 - val_loss: 0.2227 - val_accuracy: 0.9225\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9719 - val_loss: 0.2233 - val_accuracy: 0.9100\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0811 - accuracy: 0.9781 - val_loss: 0.2413 - val_accuracy: 0.9050\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9769 - val_loss: 0.2461 - val_accuracy: 0.9050\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.2399 - val_accuracy: 0.9100\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9831 - val_loss: 0.2419 - val_accuracy: 0.8950\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9844 - val_loss: 0.2269 - val_accuracy: 0.9300\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9869 - val_loss: 0.2246 - val_accuracy: 0.9200\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9831 - val_loss: 0.2259 - val_accuracy: 0.9225\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9894 - val_loss: 0.2581 - val_accuracy: 0.9125\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9925 - val_loss: 0.2687 - val_accuracy: 0.9125\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9950 - val_loss: 0.2590 - val_accuracy: 0.9175\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9919 - val_loss: 0.2484 - val_accuracy: 0.9150\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9956 - val_loss: 0.2562 - val_accuracy: 0.9150\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9937 - val_loss: 0.2686 - val_accuracy: 0.9150\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9969 - val_loss: 0.2625 - val_accuracy: 0.9225\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 0.2942 - val_accuracy: 0.9100\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.2766 - val_accuracy: 0.9200\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9981 - val_loss: 0.2817 - val_accuracy: 0.9150\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9981 - val_loss: 0.3338 - val_accuracy: 0.9100\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9950 - val_loss: 0.3056 - val_accuracy: 0.9125\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9000\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9987 - val_loss: 0.3062 - val_accuracy: 0.9150\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.8975\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.3255 - val_accuracy: 0.9225\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9987 - val_loss: 0.3290 - val_accuracy: 0.9125\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.3624 - val_accuracy: 0.9050\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9100\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9150\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.3860 - val_accuracy: 0.9025\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9175\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9075\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.3799 - val_accuracy: 0.9150\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.3963 - val_accuracy: 0.9175\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9994 - val_loss: 0.4100 - val_accuracy: 0.9025\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9075\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9000\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.3975 - val_accuracy: 0.9150\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.4705 - val_accuracy: 0.8950\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 0.4606 - val_accuracy: 0.9075\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9025\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9100\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9100\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9175\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9150\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9175\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9125\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9125\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9150\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9100\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9175\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9050\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9025\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9100\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9100\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.6462 - val_accuracy: 0.8800\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9762 - val_loss: 0.4922 - val_accuracy: 0.9075\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.4825 - val_accuracy: 0.9075\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9075\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9075\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9075\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9100\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9125\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9075\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9125\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9125\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.9025\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9075\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9050\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.5029e-04 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.9050\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.0183e-04 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9050\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.4440e-04 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9050\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.0454e-04 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9050\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6220e-04 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.9050\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.4713e-04 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.9025\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.9274e-04 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.9000\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7757e-04 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.9050\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5968e-04 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.9025\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2787e-04 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.9075\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2423e-04 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9050\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6576e-04 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2381e-04 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 0.8950\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3941e-04 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.8950\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2187e-04 - accuracy: 1.0000 - val_loss: 0.5701 - val_accuracy: 0.9050\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5131e-04 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.9000\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2728e-04 - accuracy: 1.0000 - val_loss: 0.5754 - val_accuracy: 0.9075\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.7673e-04 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.9025\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9812 - val_loss: 0.8854 - val_accuracy: 0.8725\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.5898 - val_accuracy: 0.9150\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.5879 - val_accuracy: 0.9125\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9050\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1678e-04 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.9025\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.2945e-04 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.9075\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5338e-04 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.9075\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.1924e-04 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.9075\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7661e-04 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.9075\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.4269e-04 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.9100\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0748e-04 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.9100\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8350e-04 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.9075\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5487e-04 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.9100\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.3458e-04 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.9125\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2114e-04 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.9100\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9244e-04 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9100\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.8174e-04 - accuracy: 1.0000 - val_loss: 0.6012 - val_accuracy: 0.9125\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5908e-04 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.9050\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4745e-04 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9125\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.3017e-04 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.9100\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1703e-04 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9125\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0965e-04 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9075\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9401e-04 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.9025\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7927e-04 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.9125\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6859e-04 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9075\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7123e-04 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.9075\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4783e-04 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.9075\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3909e-04 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.9075\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2832e-04 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.9050\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1588e-04 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 0.9075\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0222e-04 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.9050\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9706e-04 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9050\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8449e-04 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.9075\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7934e-04 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.9050\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7125e-04 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.9050\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5985e-04 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.9050\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5410e-04 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.9075\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4552e-04 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.9075\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3964e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.9050\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3683e-04 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.9075\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2562e-04 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.9075\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1850e-04 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.9050\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1526e-04 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.9050\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0507e-04 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.9075\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.6531e-05 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.9125\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.7587e-05 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.9025\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.8654e-05 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.9000\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5842e-05 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.9025\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3726e-05 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.9075\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.1923e-05 - accuracy: 1.0000 - val_loss: 0.7179 - val_accuracy: 0.9050\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.3154e-05 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.9050\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.0004e-05 - accuracy: 1.0000 - val_loss: 0.7228 - val_accuracy: 0.9100\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9315e-05 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.9125\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5442e-05 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8975\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.0720e-05 - accuracy: 1.0000 - val_loss: 0.7419 - val_accuracy: 0.9050\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.5529e-05 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.9075\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9416e-05 - accuracy: 1.0000 - val_loss: 0.7545 - val_accuracy: 0.9025\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.2089e-05 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.9075\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5783e-05 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.9025\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4098e-05 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.9050\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.9193 - val_accuracy: 0.9075\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9663 - val_loss: 1.0440 - val_accuracy: 0.8825\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.8172 - val_accuracy: 0.8925\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.8900\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2651e-04 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.9000\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6142e-04 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.9000\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3532e-04 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.9000\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1483e-04 - accuracy: 1.0000 - val_loss: 0.7871 - val_accuracy: 0.9000\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9936e-04 - accuracy: 1.0000 - val_loss: 0.7867 - val_accuracy: 0.9000\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8670e-04 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.9000\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8002e-04 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.9000\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6807e-04 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.9000\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5836e-04 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 0.9000\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5228e-04 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.9000\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4469e-04 - accuracy: 1.0000 - val_loss: 0.7901 - val_accuracy: 0.9000\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3845e-04 - accuracy: 1.0000 - val_loss: 0.7915 - val_accuracy: 0.8975\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.9000\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2658e-04 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.9000\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2103e-04 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.9000\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1669e-04 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.8975\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.7926 - val_accuracy: 0.9000\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0700e-04 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8975\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0269e-04 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.8975\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 9.6839e-05 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.9000\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 9.3079e-05 - accuracy: 1.0000 - val_loss: 0.7922 - val_accuracy: 0.9000\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 8.8735e-05 - accuracy: 1.0000 - val_loss: 0.7949 - val_accuracy: 0.8975\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 8.5432e-05 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.8975\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.1537e-05 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.8975\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 7.9259e-05 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.9000\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5089e-05 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.8975\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.1693e-05 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.9025\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.8242e-05 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.9025\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.5811e-05 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.9025\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.2884e-05 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.9025\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.9671e-05 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.9000\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.5576e-05 - accuracy: 1.0000 - val_loss: 0.8020 - val_accuracy: 0.9025\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.3954e-05 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.9000\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.1421e-05 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.9025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[0, 0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[0, 0].set_title('17,12,7,4 neurons')\n",
        "axs[0, 1].plot(history_5.history['loss'],label='train_loss')\n",
        "axs[0, 1].plot(history_5.history['val_loss'],label='test_loss')\n",
        "axs[0, 1].set_title('32,16,8,4 neurons')\n",
        "axs[1, 0].plot(history_6.history['loss'],label='train_loss')\n",
        "axs[1, 0].plot(history_6.history['val_loss'],label='test_loss')\n",
        "axs[1, 0].set_title('24,16,8,4 neurons')\n",
        "axs[1, 1].plot(history_7.history['loss'],label='train_loss')\n",
        "axs[1, 1].plot(history_7.history['val_loss'],label='test_loss')\n",
        "axs[1, 1].set_title('20,16,8,4 neurons')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "VYReUknPQp7n",
        "outputId": "41d91894-2e5d-48dc-d5c1-68ba90ff61bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the accuracy of the 4 different architectures"
      ],
      "metadata": {
        "id": "8iswW1iLWBGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_3.history['accuracy'],label='accuracy')\n",
        "axs[0, 0].plot(history_3.history['val_accuracy'],label='val_accuracy')\n",
        "axs[0, 0].set_title('17,12,7,4 neurons')\n",
        "axs[0, 1].plot(history_5.history['accuracy'],label='accuracy')\n",
        "axs[0, 1].plot(history_5.history['val_accuracy'],label='val_accuracy')\n",
        "axs[0, 1].set_title('32,16,8,4 neurons')\n",
        "axs[1, 0].plot(history_6.history['accuracy'],label='accuracy')\n",
        "axs[1, 0].plot(history_6.history['val_accuracy'],label='val_accuracy')\n",
        "axs[1, 0].set_title('24,16,8,4 neurons')\n",
        "axs[1, 1].plot(history_7.history['accuracy'],label='accuracy')\n",
        "axs[1, 1].plot(history_7.history['val_accuracy'],label='val_accuracy')\n",
        "axs[1, 1].set_title('20,16,8,4 neurons')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XlvSDq3CWReI",
        "outputId": "2ac54d8c-e5ad-4b24-cae7-ca0d16598451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam_learning_rate=1e-4"
      ],
      "metadata": {
        "id": "ThZZHiQvdrcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_8= keras.Sequential()\n",
        "model_8.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_8.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_8.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_8.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_8.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "print(model_8.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po33rAAndoCJ",
        "outputId": "f8334d0b-a338-4992-f029-d5ee7e33af05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_8=model_8.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZirhJLTeGIS",
        "outputId": "f7764a71-9a06-49a3-db42-0f7fd8cef76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 2ms/step - loss: 1.4198 - accuracy: 0.2825 - val_loss: 1.4046 - val_accuracy: 0.2950\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4042 - accuracy: 0.3044 - val_loss: 1.3914 - val_accuracy: 0.3150\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3907 - accuracy: 0.3181 - val_loss: 1.3795 - val_accuracy: 0.3250\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3782 - accuracy: 0.3356 - val_loss: 1.3682 - val_accuracy: 0.3475\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3662 - accuracy: 0.3525 - val_loss: 1.3572 - val_accuracy: 0.3600\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3540 - accuracy: 0.3663 - val_loss: 1.3462 - val_accuracy: 0.3725\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3418 - accuracy: 0.3919 - val_loss: 1.3339 - val_accuracy: 0.3900\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3284 - accuracy: 0.4087 - val_loss: 1.3207 - val_accuracy: 0.4050\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3142 - accuracy: 0.4250 - val_loss: 1.3058 - val_accuracy: 0.4175\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2986 - accuracy: 0.4431 - val_loss: 1.2892 - val_accuracy: 0.4400\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2819 - accuracy: 0.4538 - val_loss: 1.2702 - val_accuracy: 0.4600\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2638 - accuracy: 0.4644 - val_loss: 1.2505 - val_accuracy: 0.4775\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2445 - accuracy: 0.4756 - val_loss: 1.2291 - val_accuracy: 0.4950\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2237 - accuracy: 0.4894 - val_loss: 1.2067 - val_accuracy: 0.5100\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2017 - accuracy: 0.4969 - val_loss: 1.1831 - val_accuracy: 0.5275\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1785 - accuracy: 0.5013 - val_loss: 1.1587 - val_accuracy: 0.5350\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1546 - accuracy: 0.5181 - val_loss: 1.1341 - val_accuracy: 0.5450\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1304 - accuracy: 0.5275 - val_loss: 1.1097 - val_accuracy: 0.5525\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1062 - accuracy: 0.5331 - val_loss: 1.0846 - val_accuracy: 0.5550\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.5381 - val_loss: 1.0597 - val_accuracy: 0.5650\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0578 - accuracy: 0.5412 - val_loss: 1.0347 - val_accuracy: 0.5675\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0339 - accuracy: 0.5519 - val_loss: 1.0101 - val_accuracy: 0.5725\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0103 - accuracy: 0.5575 - val_loss: 0.9861 - val_accuracy: 0.5775\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.5656 - val_loss: 0.9620 - val_accuracy: 0.5800\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9635 - accuracy: 0.5756 - val_loss: 0.9389 - val_accuracy: 0.5925\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9409 - accuracy: 0.5800 - val_loss: 0.9165 - val_accuracy: 0.6000\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9189 - accuracy: 0.5863 - val_loss: 0.8943 - val_accuracy: 0.6025\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8972 - accuracy: 0.6000 - val_loss: 0.8726 - val_accuracy: 0.6075\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8761 - accuracy: 0.6031 - val_loss: 0.8515 - val_accuracy: 0.6150\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8552 - accuracy: 0.6162 - val_loss: 0.8310 - val_accuracy: 0.6225\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8348 - accuracy: 0.6206 - val_loss: 0.8097 - val_accuracy: 0.6300\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.8147 - accuracy: 0.6306 - val_loss: 0.7894 - val_accuracy: 0.6375\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7949 - accuracy: 0.6375 - val_loss: 0.7691 - val_accuracy: 0.6425\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7754 - accuracy: 0.6531 - val_loss: 0.7495 - val_accuracy: 0.6475\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7561 - accuracy: 0.6531 - val_loss: 0.7303 - val_accuracy: 0.6550\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.6644 - val_loss: 0.7114 - val_accuracy: 0.6675\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.6669 - val_loss: 0.6925 - val_accuracy: 0.6700\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.6781 - val_loss: 0.6735 - val_accuracy: 0.6775\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6831 - val_loss: 0.6538 - val_accuracy: 0.6875\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6950 - val_loss: 0.6332 - val_accuracy: 0.6950\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.7106 - val_loss: 0.6118 - val_accuracy: 0.7050\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7300 - val_loss: 0.5914 - val_accuracy: 0.7275\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7519 - val_loss: 0.5705 - val_accuracy: 0.7475\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7713 - val_loss: 0.5502 - val_accuracy: 0.7800\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7887 - val_loss: 0.5304 - val_accuracy: 0.8025\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.8056 - val_loss: 0.5119 - val_accuracy: 0.8200\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.8175 - val_loss: 0.4952 - val_accuracy: 0.8275\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8313 - val_loss: 0.4793 - val_accuracy: 0.8325\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8356 - val_loss: 0.4640 - val_accuracy: 0.8425\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8438 - val_loss: 0.4495 - val_accuracy: 0.8450\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8494 - val_loss: 0.4362 - val_accuracy: 0.8475\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8587 - val_loss: 0.4237 - val_accuracy: 0.8550\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8625 - val_loss: 0.4124 - val_accuracy: 0.8575\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8725 - val_loss: 0.4017 - val_accuracy: 0.8650\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8756 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8794 - val_loss: 0.3816 - val_accuracy: 0.8725\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8838 - val_loss: 0.3728 - val_accuracy: 0.8725\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8881 - val_loss: 0.3650 - val_accuracy: 0.8825\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8888 - val_loss: 0.3562 - val_accuracy: 0.8900\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8925 - val_loss: 0.3485 - val_accuracy: 0.8925\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8950 - val_loss: 0.3427 - val_accuracy: 0.8900\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8956 - val_loss: 0.3356 - val_accuracy: 0.8950\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.9000 - val_loss: 0.3296 - val_accuracy: 0.8950\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.9013 - val_loss: 0.3233 - val_accuracy: 0.8950\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.9019 - val_loss: 0.3186 - val_accuracy: 0.8975\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.9025 - val_loss: 0.3118 - val_accuracy: 0.8925\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.9031 - val_loss: 0.3068 - val_accuracy: 0.8950\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9062 - val_loss: 0.3021 - val_accuracy: 0.8925\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.9094 - val_loss: 0.2973 - val_accuracy: 0.8950\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9106 - val_loss: 0.2931 - val_accuracy: 0.8950\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.9125 - val_loss: 0.2890 - val_accuracy: 0.8975\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2762 - accuracy: 0.9156 - val_loss: 0.2841 - val_accuracy: 0.8950\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.9169 - val_loss: 0.2809 - val_accuracy: 0.8975\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2667 - accuracy: 0.9169 - val_loss: 0.2771 - val_accuracy: 0.8975\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9206 - val_loss: 0.2739 - val_accuracy: 0.8975\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9187 - val_loss: 0.2715 - val_accuracy: 0.9050\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9212 - val_loss: 0.2679 - val_accuracy: 0.9050\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9206 - val_loss: 0.2645 - val_accuracy: 0.9025\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9219 - val_loss: 0.2632 - val_accuracy: 0.9075\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9237 - val_loss: 0.2599 - val_accuracy: 0.9075\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9212 - val_loss: 0.2578 - val_accuracy: 0.9100\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9231 - val_loss: 0.2550 - val_accuracy: 0.9050\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9256 - val_loss: 0.2517 - val_accuracy: 0.9050\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9225 - val_loss: 0.2496 - val_accuracy: 0.9100\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9231 - val_loss: 0.2484 - val_accuracy: 0.9075\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9250 - val_loss: 0.2465 - val_accuracy: 0.9100\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9256 - val_loss: 0.2453 - val_accuracy: 0.9175\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9256 - val_loss: 0.2429 - val_accuracy: 0.9125\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9250 - val_loss: 0.2401 - val_accuracy: 0.9125\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9275 - val_loss: 0.2385 - val_accuracy: 0.9125\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9275 - val_loss: 0.2373 - val_accuracy: 0.9100\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9300 - val_loss: 0.2351 - val_accuracy: 0.9100\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9281 - val_loss: 0.2340 - val_accuracy: 0.9125\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9287 - val_loss: 0.2321 - val_accuracy: 0.9125\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9306 - val_loss: 0.2314 - val_accuracy: 0.9125\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9325 - val_loss: 0.2291 - val_accuracy: 0.9125\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9312 - val_loss: 0.2279 - val_accuracy: 0.9125\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9331 - val_loss: 0.2291 - val_accuracy: 0.9225\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9362 - val_loss: 0.2265 - val_accuracy: 0.9225\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9337 - val_loss: 0.2245 - val_accuracy: 0.9200\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9319 - val_loss: 0.2241 - val_accuracy: 0.9175\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9337 - val_loss: 0.2230 - val_accuracy: 0.9200\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9356 - val_loss: 0.2217 - val_accuracy: 0.9225\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9344 - val_loss: 0.2205 - val_accuracy: 0.9200\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9362 - val_loss: 0.2204 - val_accuracy: 0.9200\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9362 - val_loss: 0.2184 - val_accuracy: 0.9200\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9394 - val_loss: 0.2178 - val_accuracy: 0.9200\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9400 - val_loss: 0.2164 - val_accuracy: 0.9200\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9400 - val_loss: 0.2147 - val_accuracy: 0.9200\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9388 - val_loss: 0.2155 - val_accuracy: 0.9200\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9381 - val_loss: 0.2161 - val_accuracy: 0.9225\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9394 - val_loss: 0.2136 - val_accuracy: 0.9200\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9419 - val_loss: 0.2128 - val_accuracy: 0.9200\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9406 - val_loss: 0.2129 - val_accuracy: 0.9200\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9419 - val_loss: 0.2116 - val_accuracy: 0.9200\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9419 - val_loss: 0.2115 - val_accuracy: 0.9225\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9413 - val_loss: 0.2103 - val_accuracy: 0.9200\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9438 - val_loss: 0.2106 - val_accuracy: 0.9225\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9450 - val_loss: 0.2090 - val_accuracy: 0.9225\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9456 - val_loss: 0.2076 - val_accuracy: 0.9200\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9450 - val_loss: 0.2061 - val_accuracy: 0.9225\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9450 - val_loss: 0.2056 - val_accuracy: 0.9175\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9438 - val_loss: 0.2063 - val_accuracy: 0.9200\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9450 - val_loss: 0.2066 - val_accuracy: 0.9175\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9481 - val_loss: 0.2052 - val_accuracy: 0.9175\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9463 - val_loss: 0.2039 - val_accuracy: 0.9200\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9475 - val_loss: 0.2050 - val_accuracy: 0.9200\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9456 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9469 - val_loss: 0.2029 - val_accuracy: 0.9200\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9506 - val_loss: 0.2019 - val_accuracy: 0.9200\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9481 - val_loss: 0.2020 - val_accuracy: 0.9200\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9488 - val_loss: 0.2030 - val_accuracy: 0.9225\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9481 - val_loss: 0.2033 - val_accuracy: 0.9225\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9488 - val_loss: 0.2014 - val_accuracy: 0.9200\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9506 - val_loss: 0.2008 - val_accuracy: 0.9200\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9513 - val_loss: 0.1999 - val_accuracy: 0.9200\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9513 - val_loss: 0.1983 - val_accuracy: 0.9200\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9494 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9494 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9519 - val_loss: 0.2004 - val_accuracy: 0.9200\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9531 - val_loss: 0.1971 - val_accuracy: 0.9200\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9506 - val_loss: 0.1972 - val_accuracy: 0.9200\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9531 - val_loss: 0.1959 - val_accuracy: 0.9200\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9519 - val_loss: 0.1960 - val_accuracy: 0.9200\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9525 - val_loss: 0.1949 - val_accuracy: 0.9200\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9550 - val_loss: 0.1946 - val_accuracy: 0.9200\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9544 - val_loss: 0.1961 - val_accuracy: 0.9225\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9550 - val_loss: 0.1944 - val_accuracy: 0.9225\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9538 - val_loss: 0.1944 - val_accuracy: 0.9200\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9563 - val_loss: 0.1948 - val_accuracy: 0.9250\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 0.1932 - val_accuracy: 0.9200\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9569 - val_loss: 0.1931 - val_accuracy: 0.9250\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9575 - val_loss: 0.1937 - val_accuracy: 0.9200\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9575 - val_loss: 0.1934 - val_accuracy: 0.9250\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9569 - val_loss: 0.1924 - val_accuracy: 0.9250\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9594 - val_loss: 0.1927 - val_accuracy: 0.9250\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9581 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9594 - val_loss: 0.1939 - val_accuracy: 0.9250\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9600 - val_loss: 0.1901 - val_accuracy: 0.9275\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9606 - val_loss: 0.1905 - val_accuracy: 0.9275\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9588 - val_loss: 0.1913 - val_accuracy: 0.9225\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9594 - val_loss: 0.1903 - val_accuracy: 0.9250\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9613 - val_loss: 0.1901 - val_accuracy: 0.9250\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9619 - val_loss: 0.1893 - val_accuracy: 0.9275\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9606 - val_loss: 0.1877 - val_accuracy: 0.9275\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9613 - val_loss: 0.1876 - val_accuracy: 0.9275\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9613 - val_loss: 0.1873 - val_accuracy: 0.9250\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9613 - val_loss: 0.1876 - val_accuracy: 0.9250\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9625 - val_loss: 0.1871 - val_accuracy: 0.9275\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9631 - val_loss: 0.1873 - val_accuracy: 0.9250\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9656 - val_loss: 0.1864 - val_accuracy: 0.9275\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9638 - val_loss: 0.1867 - val_accuracy: 0.9250\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9663 - val_loss: 0.1849 - val_accuracy: 0.9325\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9644 - val_loss: 0.1856 - val_accuracy: 0.9300\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9656 - val_loss: 0.1846 - val_accuracy: 0.9325\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9638 - val_loss: 0.1851 - val_accuracy: 0.9300\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9650 - val_loss: 0.1849 - val_accuracy: 0.9275\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9644 - val_loss: 0.1837 - val_accuracy: 0.9325\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9663 - val_loss: 0.1846 - val_accuracy: 0.9300\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.9669 - val_loss: 0.1841 - val_accuracy: 0.9300\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9663 - val_loss: 0.1843 - val_accuracy: 0.9275\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9669 - val_loss: 0.1834 - val_accuracy: 0.9325\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9669 - val_loss: 0.1826 - val_accuracy: 0.9325\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9681 - val_loss: 0.1829 - val_accuracy: 0.9275\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9663 - val_loss: 0.1831 - val_accuracy: 0.9275\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9669 - val_loss: 0.1849 - val_accuracy: 0.9300\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9688 - val_loss: 0.1819 - val_accuracy: 0.9250\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9688 - val_loss: 0.1826 - val_accuracy: 0.9225\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9681 - val_loss: 0.1811 - val_accuracy: 0.9200\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9688 - val_loss: 0.1822 - val_accuracy: 0.9250\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9725 - val_loss: 0.1832 - val_accuracy: 0.9275\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9700 - val_loss: 0.1817 - val_accuracy: 0.9250\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9694 - val_loss: 0.1809 - val_accuracy: 0.9250\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9681 - val_loss: 0.1812 - val_accuracy: 0.9250\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9706 - val_loss: 0.1812 - val_accuracy: 0.9250\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9700 - val_loss: 0.1815 - val_accuracy: 0.9275\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9700 - val_loss: 0.1817 - val_accuracy: 0.9300\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9700 - val_loss: 0.1803 - val_accuracy: 0.9250\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9700 - val_loss: 0.1788 - val_accuracy: 0.9200\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9712 - val_loss: 0.1803 - val_accuracy: 0.9275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam_learning_rate=1e-5"
      ],
      "metadata": {
        "id": "sL_MH3xugcWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_9= keras.Sequential()\n",
        "model_9.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_9.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_9.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_9.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_9.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              metrics=['accuracy'])\n",
        "print(model_9.summary())"
      ],
      "metadata": {
        "id": "7i-wN9Xqgb6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5de3ef-e0aa-4ba0-93c4-b433d3e3f9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_9=model_9.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQUJL_XbiiWB",
        "outputId": "23dd504d-3da1-44dc-e0c5-8f47747ba1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.5024 - accuracy: 0.2125 - val_loss: 1.4630 - val_accuracy: 0.2225\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4964 - accuracy: 0.2150 - val_loss: 1.4584 - val_accuracy: 0.2250\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4907 - accuracy: 0.2163 - val_loss: 1.4539 - val_accuracy: 0.2225\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4853 - accuracy: 0.2188 - val_loss: 1.4496 - val_accuracy: 0.2250\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4801 - accuracy: 0.2175 - val_loss: 1.4456 - val_accuracy: 0.2325\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4752 - accuracy: 0.2212 - val_loss: 1.4417 - val_accuracy: 0.2425\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4705 - accuracy: 0.2225 - val_loss: 1.4380 - val_accuracy: 0.2450\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4660 - accuracy: 0.2237 - val_loss: 1.4345 - val_accuracy: 0.2450\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4616 - accuracy: 0.2275 - val_loss: 1.4311 - val_accuracy: 0.2425\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4574 - accuracy: 0.2300 - val_loss: 1.4278 - val_accuracy: 0.2475\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4534 - accuracy: 0.2294 - val_loss: 1.4246 - val_accuracy: 0.2525\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4495 - accuracy: 0.2338 - val_loss: 1.4216 - val_accuracy: 0.2550\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4457 - accuracy: 0.2362 - val_loss: 1.4187 - val_accuracy: 0.2600\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4421 - accuracy: 0.2381 - val_loss: 1.4158 - val_accuracy: 0.2600\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4386 - accuracy: 0.2425 - val_loss: 1.4130 - val_accuracy: 0.2650\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4352 - accuracy: 0.2450 - val_loss: 1.4104 - val_accuracy: 0.2675\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4319 - accuracy: 0.2450 - val_loss: 1.4078 - val_accuracy: 0.2700\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4287 - accuracy: 0.2456 - val_loss: 1.4052 - val_accuracy: 0.2750\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4256 - accuracy: 0.2519 - val_loss: 1.4027 - val_accuracy: 0.2725\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.2544 - val_loss: 1.4003 - val_accuracy: 0.2725\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4195 - accuracy: 0.2569 - val_loss: 1.3980 - val_accuracy: 0.2750\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4166 - accuracy: 0.2612 - val_loss: 1.3957 - val_accuracy: 0.2775\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4137 - accuracy: 0.2612 - val_loss: 1.3934 - val_accuracy: 0.2800\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4109 - accuracy: 0.2606 - val_loss: 1.3912 - val_accuracy: 0.2800\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4082 - accuracy: 0.2625 - val_loss: 1.3890 - val_accuracy: 0.2775\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4054 - accuracy: 0.2631 - val_loss: 1.3868 - val_accuracy: 0.2750\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4027 - accuracy: 0.2663 - val_loss: 1.3848 - val_accuracy: 0.2850\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4001 - accuracy: 0.2663 - val_loss: 1.3827 - val_accuracy: 0.2850\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3975 - accuracy: 0.2675 - val_loss: 1.3807 - val_accuracy: 0.2850\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3950 - accuracy: 0.2700 - val_loss: 1.3788 - val_accuracy: 0.2825\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3926 - accuracy: 0.2731 - val_loss: 1.3769 - val_accuracy: 0.2825\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3902 - accuracy: 0.2744 - val_loss: 1.3751 - val_accuracy: 0.2850\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3877 - accuracy: 0.2738 - val_loss: 1.3732 - val_accuracy: 0.2875\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3854 - accuracy: 0.2744 - val_loss: 1.3713 - val_accuracy: 0.2900\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3830 - accuracy: 0.2775 - val_loss: 1.3695 - val_accuracy: 0.2975\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3807 - accuracy: 0.2825 - val_loss: 1.3676 - val_accuracy: 0.3025\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3783 - accuracy: 0.2831 - val_loss: 1.3658 - val_accuracy: 0.3025\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3760 - accuracy: 0.2850 - val_loss: 1.3640 - val_accuracy: 0.3050\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3737 - accuracy: 0.2856 - val_loss: 1.3622 - val_accuracy: 0.3100\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3714 - accuracy: 0.2875 - val_loss: 1.3603 - val_accuracy: 0.3100\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3692 - accuracy: 0.2919 - val_loss: 1.3585 - val_accuracy: 0.3150\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3669 - accuracy: 0.2950 - val_loss: 1.3567 - val_accuracy: 0.3175\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3647 - accuracy: 0.2956 - val_loss: 1.3549 - val_accuracy: 0.3200\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3625 - accuracy: 0.2975 - val_loss: 1.3531 - val_accuracy: 0.3175\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3602 - accuracy: 0.2981 - val_loss: 1.3513 - val_accuracy: 0.3225\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3580 - accuracy: 0.3006 - val_loss: 1.3495 - val_accuracy: 0.3275\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3558 - accuracy: 0.3050 - val_loss: 1.3478 - val_accuracy: 0.3325\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3537 - accuracy: 0.3088 - val_loss: 1.3460 - val_accuracy: 0.3275\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3515 - accuracy: 0.3125 - val_loss: 1.3443 - val_accuracy: 0.3250\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3493 - accuracy: 0.3137 - val_loss: 1.3425 - val_accuracy: 0.3275\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.3471 - accuracy: 0.3156 - val_loss: 1.3407 - val_accuracy: 0.3275\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3449 - accuracy: 0.3175 - val_loss: 1.3390 - val_accuracy: 0.3275\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3428 - accuracy: 0.3200 - val_loss: 1.3372 - val_accuracy: 0.3275\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3406 - accuracy: 0.3219 - val_loss: 1.3354 - val_accuracy: 0.3275\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3385 - accuracy: 0.3237 - val_loss: 1.3337 - val_accuracy: 0.3250\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3363 - accuracy: 0.3269 - val_loss: 1.3319 - val_accuracy: 0.3300\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3341 - accuracy: 0.3306 - val_loss: 1.3301 - val_accuracy: 0.3300\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3320 - accuracy: 0.3331 - val_loss: 1.3283 - val_accuracy: 0.3300\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3298 - accuracy: 0.3375 - val_loss: 1.3265 - val_accuracy: 0.3300\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3277 - accuracy: 0.3406 - val_loss: 1.3247 - val_accuracy: 0.3300\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3255 - accuracy: 0.3413 - val_loss: 1.3229 - val_accuracy: 0.3300\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3234 - accuracy: 0.3419 - val_loss: 1.3211 - val_accuracy: 0.3325\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3212 - accuracy: 0.3431 - val_loss: 1.3193 - val_accuracy: 0.3350\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3191 - accuracy: 0.3450 - val_loss: 1.3175 - val_accuracy: 0.3400\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3169 - accuracy: 0.3462 - val_loss: 1.3156 - val_accuracy: 0.3400\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3148 - accuracy: 0.3500 - val_loss: 1.3138 - val_accuracy: 0.3375\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3126 - accuracy: 0.3569 - val_loss: 1.3120 - val_accuracy: 0.3375\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3104 - accuracy: 0.3587 - val_loss: 1.3101 - val_accuracy: 0.3375\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3083 - accuracy: 0.3619 - val_loss: 1.3083 - val_accuracy: 0.3400\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3061 - accuracy: 0.3625 - val_loss: 1.3064 - val_accuracy: 0.3375\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3039 - accuracy: 0.3700 - val_loss: 1.3045 - val_accuracy: 0.3400\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3017 - accuracy: 0.3719 - val_loss: 1.3026 - val_accuracy: 0.3425\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2995 - accuracy: 0.3756 - val_loss: 1.3007 - val_accuracy: 0.3450\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2973 - accuracy: 0.3762 - val_loss: 1.2987 - val_accuracy: 0.3475\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2950 - accuracy: 0.3781 - val_loss: 1.2968 - val_accuracy: 0.3500\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2928 - accuracy: 0.3812 - val_loss: 1.2948 - val_accuracy: 0.3525\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2906 - accuracy: 0.3831 - val_loss: 1.2928 - val_accuracy: 0.3575\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2883 - accuracy: 0.3862 - val_loss: 1.2908 - val_accuracy: 0.3600\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.3862 - val_loss: 1.2888 - val_accuracy: 0.3600\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2837 - accuracy: 0.3875 - val_loss: 1.2868 - val_accuracy: 0.3625\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2814 - accuracy: 0.3900 - val_loss: 1.2847 - val_accuracy: 0.3675\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2790 - accuracy: 0.3906 - val_loss: 1.2827 - val_accuracy: 0.3700\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2766 - accuracy: 0.3925 - val_loss: 1.2806 - val_accuracy: 0.3700\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2743 - accuracy: 0.3969 - val_loss: 1.2785 - val_accuracy: 0.3725\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2719 - accuracy: 0.3988 - val_loss: 1.2764 - val_accuracy: 0.3675\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2695 - accuracy: 0.3988 - val_loss: 1.2743 - val_accuracy: 0.3675\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2671 - accuracy: 0.4006 - val_loss: 1.2722 - val_accuracy: 0.3725\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2647 - accuracy: 0.4006 - val_loss: 1.2701 - val_accuracy: 0.3750\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2622 - accuracy: 0.4013 - val_loss: 1.2680 - val_accuracy: 0.3800\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2598 - accuracy: 0.4038 - val_loss: 1.2658 - val_accuracy: 0.3800\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2573 - accuracy: 0.4075 - val_loss: 1.2637 - val_accuracy: 0.3825\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2549 - accuracy: 0.4100 - val_loss: 1.2615 - val_accuracy: 0.3875\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2524 - accuracy: 0.4150 - val_loss: 1.2593 - val_accuracy: 0.3925\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2499 - accuracy: 0.4162 - val_loss: 1.2570 - val_accuracy: 0.3950\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2474 - accuracy: 0.4162 - val_loss: 1.2548 - val_accuracy: 0.4025\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2449 - accuracy: 0.4181 - val_loss: 1.2525 - val_accuracy: 0.3975\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.2423 - accuracy: 0.4194 - val_loss: 1.2502 - val_accuracy: 0.4075\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2398 - accuracy: 0.4219 - val_loss: 1.2479 - val_accuracy: 0.4075\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2372 - accuracy: 0.4256 - val_loss: 1.2455 - val_accuracy: 0.4075\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2347 - accuracy: 0.4288 - val_loss: 1.2431 - val_accuracy: 0.4075\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2321 - accuracy: 0.4319 - val_loss: 1.2408 - val_accuracy: 0.4175\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2295 - accuracy: 0.4350 - val_loss: 1.2383 - val_accuracy: 0.4200\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2268 - accuracy: 0.4369 - val_loss: 1.2360 - val_accuracy: 0.4175\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2241 - accuracy: 0.4412 - val_loss: 1.2335 - val_accuracy: 0.4200\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2214 - accuracy: 0.4450 - val_loss: 1.2311 - val_accuracy: 0.4250\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2187 - accuracy: 0.4469 - val_loss: 1.2286 - val_accuracy: 0.4325\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2160 - accuracy: 0.4506 - val_loss: 1.2262 - val_accuracy: 0.4325\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2133 - accuracy: 0.4556 - val_loss: 1.2237 - val_accuracy: 0.4350\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2106 - accuracy: 0.4569 - val_loss: 1.2212 - val_accuracy: 0.4400\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2079 - accuracy: 0.4575 - val_loss: 1.2187 - val_accuracy: 0.4400\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2052 - accuracy: 0.4581 - val_loss: 1.2162 - val_accuracy: 0.4450\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2025 - accuracy: 0.4631 - val_loss: 1.2137 - val_accuracy: 0.4450\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1997 - accuracy: 0.4656 - val_loss: 1.2112 - val_accuracy: 0.4525\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1969 - accuracy: 0.4656 - val_loss: 1.2085 - val_accuracy: 0.4525\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1941 - accuracy: 0.4669 - val_loss: 1.2059 - val_accuracy: 0.4500\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1913 - accuracy: 0.4719 - val_loss: 1.2032 - val_accuracy: 0.4525\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1884 - accuracy: 0.4737 - val_loss: 1.2006 - val_accuracy: 0.4525\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1856 - accuracy: 0.4769 - val_loss: 1.1979 - val_accuracy: 0.4625\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1828 - accuracy: 0.4762 - val_loss: 1.1952 - val_accuracy: 0.4625\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1800 - accuracy: 0.4775 - val_loss: 1.1925 - val_accuracy: 0.4625\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.1771 - accuracy: 0.4794 - val_loss: 1.1897 - val_accuracy: 0.4650\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.1743 - accuracy: 0.4819 - val_loss: 1.1870 - val_accuracy: 0.4725\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1714 - accuracy: 0.4844 - val_loss: 1.1843 - val_accuracy: 0.4750\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.1685 - accuracy: 0.4856 - val_loss: 1.1815 - val_accuracy: 0.4750\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1656 - accuracy: 0.4869 - val_loss: 1.1787 - val_accuracy: 0.4750\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1627 - accuracy: 0.4837 - val_loss: 1.1759 - val_accuracy: 0.4800\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1598 - accuracy: 0.4856 - val_loss: 1.1730 - val_accuracy: 0.4800\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1569 - accuracy: 0.4875 - val_loss: 1.1702 - val_accuracy: 0.4875\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1539 - accuracy: 0.4888 - val_loss: 1.1673 - val_accuracy: 0.4875\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1509 - accuracy: 0.4888 - val_loss: 1.1644 - val_accuracy: 0.4850\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1479 - accuracy: 0.4906 - val_loss: 1.1615 - val_accuracy: 0.4850\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1449 - accuracy: 0.4956 - val_loss: 1.1585 - val_accuracy: 0.4825\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1419 - accuracy: 0.4975 - val_loss: 1.1556 - val_accuracy: 0.4850\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1388 - accuracy: 0.4969 - val_loss: 1.1526 - val_accuracy: 0.4850\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1357 - accuracy: 0.4981 - val_loss: 1.1496 - val_accuracy: 0.4825\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1326 - accuracy: 0.5006 - val_loss: 1.1466 - val_accuracy: 0.4850\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1295 - accuracy: 0.5031 - val_loss: 1.1436 - val_accuracy: 0.4850\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1265 - accuracy: 0.5013 - val_loss: 1.1406 - val_accuracy: 0.4875\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1234 - accuracy: 0.5050 - val_loss: 1.1376 - val_accuracy: 0.4850\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1203 - accuracy: 0.5050 - val_loss: 1.1346 - val_accuracy: 0.4900\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1171 - accuracy: 0.5069 - val_loss: 1.1316 - val_accuracy: 0.4925\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1140 - accuracy: 0.5069 - val_loss: 1.1285 - val_accuracy: 0.4925\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1109 - accuracy: 0.5075 - val_loss: 1.1254 - val_accuracy: 0.4950\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1078 - accuracy: 0.5100 - val_loss: 1.1223 - val_accuracy: 0.4950\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1046 - accuracy: 0.5131 - val_loss: 1.1192 - val_accuracy: 0.4950\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1014 - accuracy: 0.5169 - val_loss: 1.1161 - val_accuracy: 0.4975\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0983 - accuracy: 0.5175 - val_loss: 1.1129 - val_accuracy: 0.5000\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0951 - accuracy: 0.5169 - val_loss: 1.1098 - val_accuracy: 0.5025\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.5225 - val_loss: 1.1066 - val_accuracy: 0.5025\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0887 - accuracy: 0.5256 - val_loss: 1.1035 - val_accuracy: 0.5050\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5269 - val_loss: 1.1003 - val_accuracy: 0.5050\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.5288 - val_loss: 1.0972 - val_accuracy: 0.5050\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0790 - accuracy: 0.5306 - val_loss: 1.0940 - val_accuracy: 0.5075\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0758 - accuracy: 0.5325 - val_loss: 1.0909 - val_accuracy: 0.5100\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5350 - val_loss: 1.0877 - val_accuracy: 0.5150\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.5381 - val_loss: 1.0844 - val_accuracy: 0.5175\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0661 - accuracy: 0.5400 - val_loss: 1.0812 - val_accuracy: 0.5175\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.5431 - val_loss: 1.0779 - val_accuracy: 0.5175\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.5425 - val_loss: 1.0747 - val_accuracy: 0.5200\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.5450 - val_loss: 1.0714 - val_accuracy: 0.5250\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.5462 - val_loss: 1.0682 - val_accuracy: 0.5250\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0498 - accuracy: 0.5469 - val_loss: 1.0649 - val_accuracy: 0.5250\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.5487 - val_loss: 1.0617 - val_accuracy: 0.5250\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0434 - accuracy: 0.5512 - val_loss: 1.0584 - val_accuracy: 0.5250\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0401 - accuracy: 0.5519 - val_loss: 1.0551 - val_accuracy: 0.5250\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0368 - accuracy: 0.5544 - val_loss: 1.0518 - val_accuracy: 0.5250\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0336 - accuracy: 0.5575 - val_loss: 1.0486 - val_accuracy: 0.5250\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0303 - accuracy: 0.5594 - val_loss: 1.0454 - val_accuracy: 0.5250\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0271 - accuracy: 0.5600 - val_loss: 1.0422 - val_accuracy: 0.5250\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5619 - val_loss: 1.0389 - val_accuracy: 0.5275\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0206 - accuracy: 0.5638 - val_loss: 1.0357 - val_accuracy: 0.5325\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0174 - accuracy: 0.5656 - val_loss: 1.0324 - val_accuracy: 0.5325\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0141 - accuracy: 0.5669 - val_loss: 1.0292 - val_accuracy: 0.5325\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.0109 - accuracy: 0.5669 - val_loss: 1.0260 - val_accuracy: 0.5300\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0077 - accuracy: 0.5694 - val_loss: 1.0227 - val_accuracy: 0.5300\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0044 - accuracy: 0.5706 - val_loss: 1.0195 - val_accuracy: 0.5325\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0012 - accuracy: 0.5713 - val_loss: 1.0163 - val_accuracy: 0.5400\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9980 - accuracy: 0.5700 - val_loss: 1.0130 - val_accuracy: 0.5425\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.5706 - val_loss: 1.0098 - val_accuracy: 0.5350\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9916 - accuracy: 0.5731 - val_loss: 1.0066 - val_accuracy: 0.5375\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9885 - accuracy: 0.5756 - val_loss: 1.0034 - val_accuracy: 0.5375\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9853 - accuracy: 0.5775 - val_loss: 1.0003 - val_accuracy: 0.5375\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9822 - accuracy: 0.5819 - val_loss: 0.9971 - val_accuracy: 0.5375\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9790 - accuracy: 0.5813 - val_loss: 0.9940 - val_accuracy: 0.5350\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5819 - val_loss: 0.9908 - val_accuracy: 0.5350\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.5819 - val_loss: 0.9876 - val_accuracy: 0.5375\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9695 - accuracy: 0.5825 - val_loss: 0.9845 - val_accuracy: 0.5450\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9664 - accuracy: 0.5831 - val_loss: 0.9813 - val_accuracy: 0.5550\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.5838 - val_loss: 0.9782 - val_accuracy: 0.5575\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9601 - accuracy: 0.5831 - val_loss: 0.9751 - val_accuracy: 0.5600\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5825 - val_loss: 0.9720 - val_accuracy: 0.5600\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5838 - val_loss: 0.9688 - val_accuracy: 0.5650\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.5831 - val_loss: 0.9657 - val_accuracy: 0.5675\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9478 - accuracy: 0.5850 - val_loss: 0.9626 - val_accuracy: 0.5725\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9447 - accuracy: 0.5838 - val_loss: 0.9595 - val_accuracy: 0.5725\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.5856 - val_loss: 0.9565 - val_accuracy: 0.5750\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 0.9386 - accuracy: 0.5844 - val_loss: 0.9534 - val_accuracy: 0.5800\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9356 - accuracy: 0.5875 - val_loss: 0.9503 - val_accuracy: 0.5800\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9326 - accuracy: 0.5881 - val_loss: 0.9473 - val_accuracy: 0.5800\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9296 - accuracy: 0.5894 - val_loss: 0.9443 - val_accuracy: 0.5850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam_learning_rate=1e-6"
      ],
      "metadata": {
        "id": "o_ltEaZ9kQVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_10= keras.Sequential()\n",
        "model_10.add(tf.keras.layers.Dense(units=17,input_shape=(20,),activation='relu'))\n",
        "model_10.add(tf.keras.layers.Dense(units=12,activation='relu'))\n",
        "model_10.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "model_10.add(tf.keras.layers.Dense(units=4,activation='softmax'))\n",
        "model_10.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "print(model_9.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIcLu6VrkatM",
        "outputId": "48659fdb-63f3-403a-b6ed-c8b1b39d8a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 17)                357       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 12)                216       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 7)                 91        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 696\n",
            "Trainable params: 696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_10=model_10.fit(norm_train_data,Y_train,epochs=200,batch_size=10,validation_data=(norm_test_data_arr,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I86QNNDckhTA",
        "outputId": "2ea5565e-953c-4bf4-9817-2a6feac98ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 2ms/step - loss: 1.4655 - accuracy: 0.2556 - val_loss: 1.4734 - val_accuracy: 0.2275\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4651 - accuracy: 0.2556 - val_loss: 1.4730 - val_accuracy: 0.2275\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4648 - accuracy: 0.2556 - val_loss: 1.4727 - val_accuracy: 0.2275\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4644 - accuracy: 0.2556 - val_loss: 1.4724 - val_accuracy: 0.2275\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4640 - accuracy: 0.2556 - val_loss: 1.4721 - val_accuracy: 0.2275\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4637 - accuracy: 0.2550 - val_loss: 1.4717 - val_accuracy: 0.2275\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4633 - accuracy: 0.2550 - val_loss: 1.4714 - val_accuracy: 0.2275\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4630 - accuracy: 0.2556 - val_loss: 1.4711 - val_accuracy: 0.2275\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4627 - accuracy: 0.2556 - val_loss: 1.4708 - val_accuracy: 0.2275\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4623 - accuracy: 0.2562 - val_loss: 1.4705 - val_accuracy: 0.2275\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4620 - accuracy: 0.2562 - val_loss: 1.4701 - val_accuracy: 0.2275\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4616 - accuracy: 0.2569 - val_loss: 1.4698 - val_accuracy: 0.2275\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4613 - accuracy: 0.2569 - val_loss: 1.4695 - val_accuracy: 0.2275\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4610 - accuracy: 0.2569 - val_loss: 1.4692 - val_accuracy: 0.2275\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4606 - accuracy: 0.2569 - val_loss: 1.4689 - val_accuracy: 0.2275\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4603 - accuracy: 0.2575 - val_loss: 1.4686 - val_accuracy: 0.2275\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4600 - accuracy: 0.2581 - val_loss: 1.4683 - val_accuracy: 0.2225\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4596 - accuracy: 0.2575 - val_loss: 1.4680 - val_accuracy: 0.2225\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4593 - accuracy: 0.2575 - val_loss: 1.4677 - val_accuracy: 0.2225\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4590 - accuracy: 0.2575 - val_loss: 1.4674 - val_accuracy: 0.2225\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4586 - accuracy: 0.2569 - val_loss: 1.4671 - val_accuracy: 0.2225\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4583 - accuracy: 0.2575 - val_loss: 1.4668 - val_accuracy: 0.2225\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4580 - accuracy: 0.2569 - val_loss: 1.4665 - val_accuracy: 0.2225\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4577 - accuracy: 0.2575 - val_loss: 1.4662 - val_accuracy: 0.2225\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4574 - accuracy: 0.2575 - val_loss: 1.4659 - val_accuracy: 0.2225\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4570 - accuracy: 0.2575 - val_loss: 1.4656 - val_accuracy: 0.2225\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4567 - accuracy: 0.2575 - val_loss: 1.4653 - val_accuracy: 0.2225\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4564 - accuracy: 0.2556 - val_loss: 1.4650 - val_accuracy: 0.2225\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4561 - accuracy: 0.2556 - val_loss: 1.4647 - val_accuracy: 0.2225\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4558 - accuracy: 0.2556 - val_loss: 1.4644 - val_accuracy: 0.2225\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4555 - accuracy: 0.2544 - val_loss: 1.4641 - val_accuracy: 0.2225\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4552 - accuracy: 0.2544 - val_loss: 1.4638 - val_accuracy: 0.2225\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4549 - accuracy: 0.2537 - val_loss: 1.4635 - val_accuracy: 0.2225\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4546 - accuracy: 0.2531 - val_loss: 1.4632 - val_accuracy: 0.2250\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4543 - accuracy: 0.2519 - val_loss: 1.4630 - val_accuracy: 0.2225\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4540 - accuracy: 0.2519 - val_loss: 1.4627 - val_accuracy: 0.2225\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4537 - accuracy: 0.2519 - val_loss: 1.4624 - val_accuracy: 0.2225\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4534 - accuracy: 0.2519 - val_loss: 1.4621 - val_accuracy: 0.2225\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4531 - accuracy: 0.2519 - val_loss: 1.4618 - val_accuracy: 0.2225\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4528 - accuracy: 0.2519 - val_loss: 1.4616 - val_accuracy: 0.2250\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4525 - accuracy: 0.2519 - val_loss: 1.4613 - val_accuracy: 0.2250\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4522 - accuracy: 0.2512 - val_loss: 1.4610 - val_accuracy: 0.2250\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4519 - accuracy: 0.2512 - val_loss: 1.4607 - val_accuracy: 0.2200\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4516 - accuracy: 0.2512 - val_loss: 1.4604 - val_accuracy: 0.2200\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4513 - accuracy: 0.2506 - val_loss: 1.4602 - val_accuracy: 0.2200\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4510 - accuracy: 0.2506 - val_loss: 1.4599 - val_accuracy: 0.2225\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4508 - accuracy: 0.2512 - val_loss: 1.4596 - val_accuracy: 0.2225\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4505 - accuracy: 0.2512 - val_loss: 1.4594 - val_accuracy: 0.2225\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4502 - accuracy: 0.2512 - val_loss: 1.4591 - val_accuracy: 0.2250\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4499 - accuracy: 0.2512 - val_loss: 1.4588 - val_accuracy: 0.2250\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4496 - accuracy: 0.2500 - val_loss: 1.4586 - val_accuracy: 0.2250\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4494 - accuracy: 0.2500 - val_loss: 1.4583 - val_accuracy: 0.2250\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4491 - accuracy: 0.2506 - val_loss: 1.4580 - val_accuracy: 0.2275\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4488 - accuracy: 0.2500 - val_loss: 1.4578 - val_accuracy: 0.2250\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4485 - accuracy: 0.2500 - val_loss: 1.4575 - val_accuracy: 0.2275\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4483 - accuracy: 0.2500 - val_loss: 1.4573 - val_accuracy: 0.2275\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4480 - accuracy: 0.2506 - val_loss: 1.4570 - val_accuracy: 0.2275\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4477 - accuracy: 0.2512 - val_loss: 1.4567 - val_accuracy: 0.2275\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4475 - accuracy: 0.2519 - val_loss: 1.4565 - val_accuracy: 0.2275\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4472 - accuracy: 0.2525 - val_loss: 1.4562 - val_accuracy: 0.2275\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4469 - accuracy: 0.2525 - val_loss: 1.4560 - val_accuracy: 0.2275\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4467 - accuracy: 0.2525 - val_loss: 1.4557 - val_accuracy: 0.2275\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4464 - accuracy: 0.2525 - val_loss: 1.4555 - val_accuracy: 0.2300\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4462 - accuracy: 0.2525 - val_loss: 1.4553 - val_accuracy: 0.2300\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4459 - accuracy: 0.2525 - val_loss: 1.4550 - val_accuracy: 0.2300\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4456 - accuracy: 0.2512 - val_loss: 1.4548 - val_accuracy: 0.2300\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4454 - accuracy: 0.2512 - val_loss: 1.4545 - val_accuracy: 0.2300\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4451 - accuracy: 0.2512 - val_loss: 1.4543 - val_accuracy: 0.2275\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4449 - accuracy: 0.2519 - val_loss: 1.4540 - val_accuracy: 0.2275\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4446 - accuracy: 0.2531 - val_loss: 1.4538 - val_accuracy: 0.2275\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4444 - accuracy: 0.2537 - val_loss: 1.4536 - val_accuracy: 0.2325\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.2550 - val_loss: 1.4533 - val_accuracy: 0.2325\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4439 - accuracy: 0.2537 - val_loss: 1.4531 - val_accuracy: 0.2325\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4436 - accuracy: 0.2537 - val_loss: 1.4529 - val_accuracy: 0.2350\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4434 - accuracy: 0.2537 - val_loss: 1.4526 - val_accuracy: 0.2350\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.4431 - accuracy: 0.2537 - val_loss: 1.4524 - val_accuracy: 0.2350\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4429 - accuracy: 0.2537 - val_loss: 1.4522 - val_accuracy: 0.2350\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4426 - accuracy: 0.2544 - val_loss: 1.4519 - val_accuracy: 0.2350\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4424 - accuracy: 0.2550 - val_loss: 1.4517 - val_accuracy: 0.2350\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4421 - accuracy: 0.2550 - val_loss: 1.4515 - val_accuracy: 0.2325\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4419 - accuracy: 0.2550 - val_loss: 1.4513 - val_accuracy: 0.2275\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4417 - accuracy: 0.2550 - val_loss: 1.4510 - val_accuracy: 0.2275\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4414 - accuracy: 0.2544 - val_loss: 1.4508 - val_accuracy: 0.2300\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4412 - accuracy: 0.2537 - val_loss: 1.4506 - val_accuracy: 0.2300\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4410 - accuracy: 0.2537 - val_loss: 1.4504 - val_accuracy: 0.2300\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4407 - accuracy: 0.2525 - val_loss: 1.4501 - val_accuracy: 0.2275\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4405 - accuracy: 0.2531 - val_loss: 1.4499 - val_accuracy: 0.2275\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4403 - accuracy: 0.2531 - val_loss: 1.4497 - val_accuracy: 0.2275\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4400 - accuracy: 0.2537 - val_loss: 1.4495 - val_accuracy: 0.2275\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4398 - accuracy: 0.2519 - val_loss: 1.4493 - val_accuracy: 0.2275\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4396 - accuracy: 0.2519 - val_loss: 1.4491 - val_accuracy: 0.2275\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4393 - accuracy: 0.2519 - val_loss: 1.4488 - val_accuracy: 0.2275\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4391 - accuracy: 0.2519 - val_loss: 1.4486 - val_accuracy: 0.2275\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4389 - accuracy: 0.2519 - val_loss: 1.4484 - val_accuracy: 0.2275\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4387 - accuracy: 0.2506 - val_loss: 1.4482 - val_accuracy: 0.2275\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4384 - accuracy: 0.2519 - val_loss: 1.4480 - val_accuracy: 0.2275\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4382 - accuracy: 0.2525 - val_loss: 1.4478 - val_accuracy: 0.2275\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4380 - accuracy: 0.2525 - val_loss: 1.4476 - val_accuracy: 0.2275\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4378 - accuracy: 0.2519 - val_loss: 1.4474 - val_accuracy: 0.2250\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4376 - accuracy: 0.2519 - val_loss: 1.4472 - val_accuracy: 0.2250\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4374 - accuracy: 0.2519 - val_loss: 1.4470 - val_accuracy: 0.2250\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4371 - accuracy: 0.2512 - val_loss: 1.4468 - val_accuracy: 0.2250\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4369 - accuracy: 0.2506 - val_loss: 1.4466 - val_accuracy: 0.2250\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4367 - accuracy: 0.2512 - val_loss: 1.4464 - val_accuracy: 0.2250\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4365 - accuracy: 0.2506 - val_loss: 1.4462 - val_accuracy: 0.2225\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4363 - accuracy: 0.2500 - val_loss: 1.4460 - val_accuracy: 0.2225\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4361 - accuracy: 0.2500 - val_loss: 1.4458 - val_accuracy: 0.2225\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4359 - accuracy: 0.2500 - val_loss: 1.4456 - val_accuracy: 0.2225\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4357 - accuracy: 0.2506 - val_loss: 1.4455 - val_accuracy: 0.2225\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4355 - accuracy: 0.2506 - val_loss: 1.4453 - val_accuracy: 0.2225\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4353 - accuracy: 0.2500 - val_loss: 1.4451 - val_accuracy: 0.2200\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4351 - accuracy: 0.2500 - val_loss: 1.4449 - val_accuracy: 0.2200\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4349 - accuracy: 0.2500 - val_loss: 1.4447 - val_accuracy: 0.2200\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4346 - accuracy: 0.2500 - val_loss: 1.4445 - val_accuracy: 0.2200\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4344 - accuracy: 0.2506 - val_loss: 1.4443 - val_accuracy: 0.2200\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4342 - accuracy: 0.2500 - val_loss: 1.4441 - val_accuracy: 0.2175\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4340 - accuracy: 0.2494 - val_loss: 1.4439 - val_accuracy: 0.2200\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4338 - accuracy: 0.2494 - val_loss: 1.4437 - val_accuracy: 0.2200\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4336 - accuracy: 0.2488 - val_loss: 1.4436 - val_accuracy: 0.2200\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4334 - accuracy: 0.2488 - val_loss: 1.4434 - val_accuracy: 0.2200\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4332 - accuracy: 0.2488 - val_loss: 1.4432 - val_accuracy: 0.2200\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4330 - accuracy: 0.2494 - val_loss: 1.4430 - val_accuracy: 0.2200\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4328 - accuracy: 0.2488 - val_loss: 1.4428 - val_accuracy: 0.2175\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4326 - accuracy: 0.2494 - val_loss: 1.4426 - val_accuracy: 0.2175\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4324 - accuracy: 0.2494 - val_loss: 1.4425 - val_accuracy: 0.2175\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4322 - accuracy: 0.2494 - val_loss: 1.4423 - val_accuracy: 0.2175\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4321 - accuracy: 0.2494 - val_loss: 1.4421 - val_accuracy: 0.2175\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4319 - accuracy: 0.2494 - val_loss: 1.4419 - val_accuracy: 0.2175\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4317 - accuracy: 0.2488 - val_loss: 1.4418 - val_accuracy: 0.2175\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4315 - accuracy: 0.2494 - val_loss: 1.4416 - val_accuracy: 0.2175\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4313 - accuracy: 0.2494 - val_loss: 1.4414 - val_accuracy: 0.2175\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4311 - accuracy: 0.2494 - val_loss: 1.4412 - val_accuracy: 0.2175\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4309 - accuracy: 0.2506 - val_loss: 1.4411 - val_accuracy: 0.2175\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4307 - accuracy: 0.2506 - val_loss: 1.4409 - val_accuracy: 0.2175\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4305 - accuracy: 0.2500 - val_loss: 1.4407 - val_accuracy: 0.2175\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4303 - accuracy: 0.2500 - val_loss: 1.4406 - val_accuracy: 0.2175\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4302 - accuracy: 0.2500 - val_loss: 1.4404 - val_accuracy: 0.2175\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4300 - accuracy: 0.2500 - val_loss: 1.4403 - val_accuracy: 0.2175\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4298 - accuracy: 0.2500 - val_loss: 1.4401 - val_accuracy: 0.2175\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4296 - accuracy: 0.2500 - val_loss: 1.4399 - val_accuracy: 0.2175\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4294 - accuracy: 0.2500 - val_loss: 1.4398 - val_accuracy: 0.2175\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4292 - accuracy: 0.2506 - val_loss: 1.4396 - val_accuracy: 0.2175\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4290 - accuracy: 0.2512 - val_loss: 1.4394 - val_accuracy: 0.2175\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4289 - accuracy: 0.2525 - val_loss: 1.4393 - val_accuracy: 0.2175\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4287 - accuracy: 0.2525 - val_loss: 1.4391 - val_accuracy: 0.2175\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4285 - accuracy: 0.2519 - val_loss: 1.4390 - val_accuracy: 0.2175\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4283 - accuracy: 0.2519 - val_loss: 1.4388 - val_accuracy: 0.2175\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4281 - accuracy: 0.2512 - val_loss: 1.4386 - val_accuracy: 0.2175\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4280 - accuracy: 0.2512 - val_loss: 1.4385 - val_accuracy: 0.2175\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4278 - accuracy: 0.2512 - val_loss: 1.4383 - val_accuracy: 0.2175\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4276 - accuracy: 0.2512 - val_loss: 1.4382 - val_accuracy: 0.2175\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4274 - accuracy: 0.2512 - val_loss: 1.4380 - val_accuracy: 0.2200\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4272 - accuracy: 0.2525 - val_loss: 1.4378 - val_accuracy: 0.2200\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4270 - accuracy: 0.2525 - val_loss: 1.4377 - val_accuracy: 0.2225\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4269 - accuracy: 0.2537 - val_loss: 1.4375 - val_accuracy: 0.2225\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4267 - accuracy: 0.2537 - val_loss: 1.4374 - val_accuracy: 0.2200\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4265 - accuracy: 0.2537 - val_loss: 1.4372 - val_accuracy: 0.2200\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4263 - accuracy: 0.2537 - val_loss: 1.4371 - val_accuracy: 0.2200\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4262 - accuracy: 0.2537 - val_loss: 1.4369 - val_accuracy: 0.2200\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4260 - accuracy: 0.2537 - val_loss: 1.4368 - val_accuracy: 0.2200\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.2537 - val_loss: 1.4366 - val_accuracy: 0.2200\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.2544 - val_loss: 1.4364 - val_accuracy: 0.2225\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4255 - accuracy: 0.2537 - val_loss: 1.4363 - val_accuracy: 0.2225\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4253 - accuracy: 0.2544 - val_loss: 1.4361 - val_accuracy: 0.2225\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.2544 - val_loss: 1.4360 - val_accuracy: 0.2200\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4250 - accuracy: 0.2537 - val_loss: 1.4358 - val_accuracy: 0.2200\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4248 - accuracy: 0.2550 - val_loss: 1.4357 - val_accuracy: 0.2200\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4246 - accuracy: 0.2550 - val_loss: 1.4355 - val_accuracy: 0.2200\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4245 - accuracy: 0.2556 - val_loss: 1.4354 - val_accuracy: 0.2200\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4243 - accuracy: 0.2562 - val_loss: 1.4353 - val_accuracy: 0.2200\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.2562 - val_loss: 1.4351 - val_accuracy: 0.2225\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.2562 - val_loss: 1.4350 - val_accuracy: 0.2250\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4238 - accuracy: 0.2569 - val_loss: 1.4348 - val_accuracy: 0.2275\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4237 - accuracy: 0.2575 - val_loss: 1.4347 - val_accuracy: 0.2275\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4235 - accuracy: 0.2575 - val_loss: 1.4345 - val_accuracy: 0.2275\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4233 - accuracy: 0.2562 - val_loss: 1.4344 - val_accuracy: 0.2300\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4232 - accuracy: 0.2562 - val_loss: 1.4343 - val_accuracy: 0.2300\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4230 - accuracy: 0.2569 - val_loss: 1.4341 - val_accuracy: 0.2300\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4229 - accuracy: 0.2562 - val_loss: 1.4340 - val_accuracy: 0.2300\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4227 - accuracy: 0.2562 - val_loss: 1.4338 - val_accuracy: 0.2325\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4226 - accuracy: 0.2562 - val_loss: 1.4337 - val_accuracy: 0.2325\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4224 - accuracy: 0.2562 - val_loss: 1.4336 - val_accuracy: 0.2325\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4222 - accuracy: 0.2562 - val_loss: 1.4334 - val_accuracy: 0.2325\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4221 - accuracy: 0.2562 - val_loss: 1.4333 - val_accuracy: 0.2325\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4219 - accuracy: 0.2569 - val_loss: 1.4331 - val_accuracy: 0.2325\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4218 - accuracy: 0.2569 - val_loss: 1.4330 - val_accuracy: 0.2325\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4216 - accuracy: 0.2562 - val_loss: 1.4329 - val_accuracy: 0.2325\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4215 - accuracy: 0.2556 - val_loss: 1.4327 - val_accuracy: 0.2325\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4213 - accuracy: 0.2550 - val_loss: 1.4326 - val_accuracy: 0.2325\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4212 - accuracy: 0.2556 - val_loss: 1.4325 - val_accuracy: 0.2325\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4210 - accuracy: 0.2556 - val_loss: 1.4323 - val_accuracy: 0.2325\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4209 - accuracy: 0.2556 - val_loss: 1.4322 - val_accuracy: 0.2325\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4207 - accuracy: 0.2556 - val_loss: 1.4320 - val_accuracy: 0.2325\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4206 - accuracy: 0.2556 - val_loss: 1.4319 - val_accuracy: 0.2325\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4205 - accuracy: 0.2556 - val_loss: 1.4318 - val_accuracy: 0.2325\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4203 - accuracy: 0.2556 - val_loss: 1.4316 - val_accuracy: 0.2325\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4202 - accuracy: 0.2556 - val_loss: 1.4315 - val_accuracy: 0.2325\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4200 - accuracy: 0.2556 - val_loss: 1.4314 - val_accuracy: 0.2300\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 1ms/step - loss: 1.4199 - accuracy: 0.2556 - val_loss: 1.4312 - val_accuracy: 0.2325\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4197 - accuracy: 0.2556 - val_loss: 1.4311 - val_accuracy: 0.2325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss for various learning rates of Adam optimiser"
      ],
      "metadata": {
        "id": "RLuaA_VHlVGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_3.history['loss'],label='train_loss')\n",
        "axs[0, 0].plot(history_3.history['val_loss'],label='test_loss')\n",
        "axs[0, 0].set_title('Learning reate=1e-3')\n",
        "axs[0, 1].plot(history_8.history['loss'],label='train_loss')\n",
        "axs[0, 1].plot(history_8.history['val_loss'],label='test_loss')\n",
        "axs[0, 1].set_title('Learning reate=1e-4')\n",
        "axs[1, 0].plot(history_9.history['loss'],label='train_loss')\n",
        "axs[1, 0].plot(history_9.history['val_loss'],label='test_loss')\n",
        "axs[1, 0].set_title('Learning reate=1e-5')\n",
        "axs[1, 1].plot(history_10.history['loss'],label='train_loss')\n",
        "axs[1, 1].plot(history_10.history['val_loss'],label='test_loss')\n",
        "axs[1, 1].set_title('Learning reate=1e-6')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OjwAEmBdlUwb",
        "outputId": "ca10db30-32f9-4ca5-83fd-0632b2b92b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the accuracy for various learning rates of Adam optimiser"
      ],
      "metadata": {
        "id": "fZQFMD3VldA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0, 0].plot(history_3.history['accuracy'],label='accuracy')\n",
        "axs[0, 0].plot(history_3.history['val_accuracy'],label='val_accuracy')\n",
        "axs[0, 0].set_title('Learning_rate=1e-3')\n",
        "axs[0, 1].plot(history_8.history['accuracy'],label='accuracy')\n",
        "axs[0, 1].plot(history_8.history['val_accuracy'],label='val_accuracy')\n",
        "axs[0, 1].set_title('Learning_rate=1e-4')\n",
        "axs[1, 0].plot(history_9.history['accuracy'],label='accuracy')\n",
        "axs[1, 0].plot(history_9.history['val_accuracy'],label='val_accuracy')\n",
        "axs[1, 0].set_title('Learning_rate=1e-5')\n",
        "axs[1, 1].plot(history_10.history['accuracy'],label='accuracy')\n",
        "axs[1, 1].plot(history_10.history['val_accuracy'],label='val_accuracy')\n",
        "axs[1, 1].set_title('Learning_rate=1e-6')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "z9PHkXKRlfgo",
        "outputId": "af910ba6-d5f4-4c75-8691-c32f3d9c0215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}